<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>The Batch - a new weekly newsletter from deeplearning.ai</title>
<link>https://www.deeplearning.ai/the-batch/</link>


<item>
<title>Trick or treat! AI Devours Energy, Innovation Dies, Models Collapse, Benchmarks Are Meaningless, No Work for Coders</title>
<link>https://www.deeplearning.ai/the-batch/issue-273</link>
<guid>https://www.deeplearning.ai/the-batch/issue-273</guid>
<content:encoded><![CDATA[

]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 14:23:00 GMT</pubDate>
</item>
<item>
<title>AI Giants Go Nuclear, A Tech Bromance Turns Turbulent, Mistral Sharpens the Edge, Cheaper Video Generation</title>
<link>https://www.deeplearning.ai/the-batch/issue-272</link>
<guid>https://www.deeplearning.ai/the-batch/issue-272</guid>
<content:encoded><![CDATA[

]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 23:13:00 GMT</pubDate>
</item>
<item>
<title>Bogus Apps, AI Boomtown, Better Embeddings, 2024 Highlights</title>
<link>https://www.deeplearning.ai/the-batch/issue-271</link>
<guid>https://www.deeplearning.ai/the-batch/issue-271</guid>
<content:encoded><![CDATA[

]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 22:09:00 GMT</pubDate>
</item>
<item>
<title>How Meta’s Movie Gen Does It, AI’s Criminal Underground, Court Says LAION is Legal, OpenAI’s New Voice API</title>
<link>https://www.deeplearning.ai/the-batch/issue-270</link>
<guid>https://www.deeplearning.ai/the-batch/issue-270</guid>
<content:encoded><![CDATA[

]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 21:59:00 GMT</pubDate>
</item>
<item>
<title>Llama Goes Multimodal, Pros Embrace Generative Video, Military AI Guidelines, LLMs That Read Spreadsheets</title>
<link>https://www.deeplearning.ai/the-batch/issue-269</link>
<guid>https://www.deeplearning.ai/the-batch/issue-269</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>We won! California’s anti-innovation bill SB 1047 was vetoed by Governor Newsom over the weekend. Open source came closer to taking a major blow than many people realize, and I’m grateful to the experts, engineers, and activists who worked hard to combat this bill.</p><p>The fight to protect open source is not yet over, and we have to continue our work to make sure regulations are based on science, not science-fiction.</p><p>As I&nbsp; wrote previously, SB 1047 makes a fundamental mistake of trying to&nbsp;<a href="https://www.deeplearning.ai/the-batch/blenders-versus-bombs-or-why-californias-proposed-ai-law-is-bad-for-everyone/" rel="noopener">regulate technology rather than applications</a>. It was also a very&nbsp;<a href="https://www.deeplearning.ai/the-batch/californias-proposed-ai-safety-law-puts-developers-at-risk-california-sb-1047-is-intended-to-make-ai-safer-but-its-unclear-requirements-put-developers-innovation-and-open-source-in-jeop/" rel="noopener">confusing</a>&nbsp;law that would have been hard to comply with. That would have driven up costs without improving safety.</p><p>While I’m glad that SB 1047 has been defeated, I wish it had never made it to the governor’s desk.&nbsp;It would not have made AI safer. In fact, many of its opponents were champions of responsible AI and making AI safe long before the rise of generative AI. Sadly, as the Santa Fe Institute’s Melanie Mitchell&nbsp;<a href="https://x.com/MelMitchell1/status/1840512220913979761" rel="noopener">pointed out</a>, the term “AI safety” has been co-opted to refer to a broad set of speculative risks that have little basis in science — as demonstrated by the security theater SB 1047 would have required — that don’t actually make anything safer. This leaves room for lobbying that can&nbsp;<a href="https://www.piratewires.com/p/sb-1047-dan-hendrycks-conflict-of-interest" rel="noopener">enrich</a>&nbsp;a small number of people while making everyone else worse off.</p><p>As Newsom&nbsp;<a href="https://www.gov.ca.gov/wp-content/uploads/2024/09/SB-1047-Veto-Message.pdf" rel="noopener">wrote</a>&nbsp;to explain his decision, SB 1047 is “not informed by an empirical trajectory analysis of AI systems and capabilities.” In contrast, the United States federal government’s work is “informed by evidence-based approaches, to guard against demonstrable risks to public safety.” As the governor says, evidence-based regulation is important!</p><figure class="kg-card kg-image-card"><img alt="California Senate Bill 1047 with a large veto stamp on top of the document." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18--1.jpg" width="1200" /></figure><p>Many people in the AI community were instrumental in defeating the bill. We're lucky to have Martin Casado, who organized significant community efforts; Clément Delangue, who championed openness; Yann LeCun, a powerful advocate for open research and open source; Chris Lengerich, who published deep legal analysis of the bill; Fei-Fei Li and Stanford's HAI, who connected with politicians; and Garry Tan, who organized the startup accelerator Y Combinator against the bill. Legendary investors Marc Andreessen and Roelof Botha were also influential. Plus far too many others to name here. I’m also delighted that brilliant artists like MC Hammer&nbsp;<a href="https://x.com/MCHammer/status/1840613210187338001" rel="noopener">support</a>&nbsp;the veto!</p><p>Looking ahead, far more work remains to be done to realize AI’s benefits. Just this week, OpenAI released an exciting new voice API that opens numerous possibilities for beneficial applications! In addition, we should continue to mitigate current and potential harms. UC Berkeley computer scientist&nbsp;<a href="https://www.deeplearning.ai/blog/hodl-dawn-song/" rel="noopener">Dawn Song</a>&nbsp;and collaborators recently published a&nbsp;<a href="https://x.com/dawnsongtweets/status/1838610481797333150" rel="noopener">roadmap</a>&nbsp;to that end. This includes investing more to enable researchers to study AI risks and increasing transparency of AI models (for which open source and red teaming will be a big help).</p><p>Unfortunately, some segments of society still have incentives to pass bad laws like SB 1047 and use science fiction narratives of dangerous AI superintelligence to advance their agendas. The more light we can shine on what AI really is and isn’t, the harder it will be for legislators to pass laws based on science fiction rather than science.</p><p>Keep learning!</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/"><img alt="Promo banner for &quot;Retrieval Optimization: From Tokenization to Vector Quantization&quot;" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/10/The-Batch-ads-and-exclusive-banners---2024-10-01T094337.154--1-.png" width="1680" /></a></figure><p>In this short course, you’ll learn how tokenization affects vector search and how to optimize search in LLM applications that use RAG. You’ll explore Byte-Pair Encoding, WordPiece, and Unigram; fine-tune HNSW parameters; and use vector quantization to improve performance.&nbsp;<a href="https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/" rel="noopener">Sign up for free</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="An interior design assistant tool analyzing an image of a modern living room." class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--14-.gif" width="600" /></figure><h1 id="llama-herd-expands">Llama Herd Expands</h1><p>Meta extended its Llama family of models into two new categories: vision-language and sizes that are small enough to fit in edge devices.</p><p><strong>What’s new:</strong>&nbsp;Meta introduced&nbsp;<a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/" rel="noopener">Llama 3.2</a>, including two larger vision-language models and two smaller text-only models as well as developer tools for building agentic applications based on the new models.&nbsp;<a href="https://www.llama.com/" rel="noopener">Weights and code</a>&nbsp;are&nbsp;<a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/USE_POLICY.md" rel="noopener">free</a>&nbsp;to developers who have less than 700 million monthly active users. Multiple providers offer cloud access.</p><p><strong>How it works:</strong>&nbsp;Llama 3.2 90B and 11B accept images as well as text and generate text output (image processing is not available in the European Union). Llama 3.2 1B and 3B accept and generate text. All four models can process 131,072 tokens of input context and generate 2,048 tokens of output.</p><ul><li>Llama 3.2 90B and 11B are based on Llama 3.1. The team froze a Llama 3.1 model and added an image encoder and cross-attention layers. They trained these new elements, given matching images and text, to produce image embeddings that matched the resulting text embeddings. To enhance the model’s ability to interpret images, the team fine-tuned the new elements via supervised learning and&nbsp;<a href="https://www.deeplearning.ai/the-batch/human-feedback-without-reinforcement-learning/" rel="noopener">DPO.</a>&nbsp;Given an image, they learned to generate questions and answers that ranked highly according to a reward model. Thus Llama 3.2 responds to text input identically to Llama 3.1, making it a viable drop-in replacement.</li><li>Likewise, Llama 3.2 3B and 1B are based on Llama 3.1 8B. The team members pruned each model using an unspecified method. Then they used Llama 3.1 8B and 70B as teacher models, training the Llama 3.2 students to mimic their output. Finally, they fine-tuned the models to follow instructions, summarize text, use tools, and perform other tasks using synthetic data generated by Llama 3.1 405B.</li><li>On popular benchmarks, Llama 3.2 90B and 11B perform roughly comparably to Claude 3 Haiku and GPT-4o-mini, the smaller vision-language models from Anthropic and OpenAI respectively. For example, Llama 3.2 90B beats both closed models on&nbsp;<a href="https://mmmu-benchmark.github.io/#leaderboard" rel="noopener">MMMU and MMMU-Pro</a>, answering visual questions about graphs, charts, diagrams, and other images. They also beat Claude 3 Haiku and GPT-4o-mini on&nbsp;<a href="https://klu.ai/glossary/gpqa-eval" rel="noopener">GPQA</a>, which tests graduate-level reasoning in various academic subjects. However, on these benchmarks, larger Llama 3.2 models are well behind larger, proprietary models like o1 and Sonnet 3.5 as well as the similarly sized, open&nbsp;<a href="https://qwenlm.github.io/blog/qwen2-vl/" rel="noopener">Qwen-2VL</a>.</li><li>Llama 3.2’s vision-language capabilities now drive the company’s Meta AI chatbot. For example, users can upload a photo of a flower and ask the chatbot to identify it or post a picture of food and request a recipe. Meta AI also uses Llama 3.2’s image understanding to edit images given text instructions.</li></ul><p><strong>New tools for developers:&nbsp;</strong>Meta announced&nbsp;<a href="https://github.com/meta-llama/llama-stack?tab=readme-ov-file#readme" rel="noopener">Llama Stack</a>, a series of APIs for customizing Llama models and building Llama-based agentic applications. Among other services, Llama Stack has APIs for tool use, memory, post-training, and evaluation.&nbsp;<a href="https://ai.meta.com/blog/responsible-ai-connect-2024/" rel="noopener">Llama Guard</a>, a model designed to evaluate content for sexual themes, violence, criminal planning, and other issues, now flags problematic images as well as text. Llama Guard 3 11B Vision comes with Llama.com’s distributions of Llama 3.2 90B and 11B, while Llama Guard 3 1B comes with Llama 3.2 3B and 1B.</p><p><strong>Why it matters:</strong>&nbsp;Meta’s open models are widely&nbsp;<a href="https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/" rel="noopener">used</a>&nbsp;by everyone from hobbyists to major industry players. Llama 3.2 extends the line in valuable ways. The growing competition between Llama and Qwen shows that smaller, open models can offer multimodal capabilities that are beginning to rival their larger, proprietary counterparts.</p><p><strong>We’re thinking:</strong>&nbsp;By offering tools to build&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/" rel="noopener">agentic workflows</a>, Llama Stack takes Llama 3.2 well beyond the models themselves. Our new short course “<a href="https://www.deeplearning.ai/short-courses/introducing-llama-3-2/" rel="noopener">Introducing Multimodal Llama 3.2</a>” shows you how to put these models to use.</p><hr /><figure class="kg-card kg-image-card"><img alt="A dynamic GIF featuring erupting volcanoes, a reindeer in the snow, animated fuzzy creatures, and a close-up of a human eye." class="kg-image" height="334" src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.gif" width="600" /></figure><h1 id="generative-video-in-the-editing-suite">Generative Video in the Editing Suite</h1><p>Adobe is putting a video generator directly into its popular video editing application.</p><p><strong>What’s new:&nbsp;</strong>Adobe&nbsp;<a href="https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon" rel="noopener">announced</a>&nbsp;its Firefly Video Model, which will be available as a web service and integrated into the company’s Premiere Pro software later this year. The model takes around two minutes to generate video clips up to five seconds long from a text prompt or still image, and it can modify or extend existing videos. Prospective users can join a&nbsp;<a href="https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon#form" rel="noopener">waitlist</a>&nbsp;for access.</p><p><strong>How it works:</strong>&nbsp;Adobe has yet to publish details about the model’s size, architecture, or training. It touts uses such as generating B-roll footage, creating scenes from individual frames, adding text and effects, animation, and video-to-video generation like extending existing clips by up to two seconds.</p><ul><li>The company licensed the model’s training data specifically for that purpose, so the model’s output shouldn’t run afoul of copyright claims. This practice stands in stark contrast to video generators that were trained on data scraped from the web.</li><li>Adobe plans to integrate the model with Premiere Pro, enhancing its traditional video editing environment with generative capabilities. For instance, among the demo clips, one shows a real-world shot of a child looking into a magnifying glass immediately followed by a generated shot of the child’s view.</li></ul><p><strong>Behind the news:&nbsp;</strong>Adobe’s move into video generation builds on its&nbsp;<a href="https://www.adobe.com/products/firefly/discover/firefly-vs-stable-diffusion.html" rel="noopener">Firefly image generator</a>&nbsp;and reflects its broader strategy to integrate generative AI with creative tools. In April, Adobe&nbsp;<a href="https://news.adobe.com/news/news-details/2024/Adobe-previews-breakthrough-AI-innovations-to-advance-professional-video-workflows-within-Adobe-Premiere-Pro/default.aspx" rel="noopener">announced</a>&nbsp;that it would integrate multiple video generators with Premiere, including models from partners like&nbsp;<a href="https://www.deeplearning.ai/the-batch/openais-sora-a-new-player-in-text-to-video-generation/" rel="noopener">OpenAI</a>&nbsp;and&nbsp;<a href="https://runwayml.com/research/introducing-gen-3-alpha" rel="noopener">Runway</a>. Runway itself recently extended its own offering with&nbsp;<a href="https://help.runwayml.com/hc/en-us/articles/33350169138323-Creating-with-Video-to-Video" rel="noopener">video-to-video</a>&nbsp;generation and an&nbsp;<a href="https://runwayml.com/api" rel="noopener">API</a>.</p><p><strong>Why it matters:</strong>&nbsp;Adobe is betting that AI-generated video will augment rather than replace professional filmmakers and editors. Putting a full-fledged generative model in a time-tested user interface for video editing promises to make video generation more useful as well as an integral part of the creative process. Moreover, Adobe’s use of licensed training data may attract videographers who are concerned about violating copyrights or supporting fellow artists.</p><p><strong>We’re thinking:&nbsp;</strong>Video-to-video generation crossing from frontier capability to common feature. Firefly's (and Runway’s) ability to extend existing videos offers a glimpse.</p><hr /><figure class="kg-card kg-image-card"><img alt="Global leaders discuss Responsible AI in the military at the REAIM 2023 summit in The Hague, Netherlands." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--14--1.png" width="1200" /></figure><h1 id="international-guidelines-for-military-ai">International Guidelines for Military AI</h1><p>Dozens of countries endorsed a “blueprint for action” designed to guide the use of artificial intelligence in military applications.</p><p><strong>What’s new:</strong>&nbsp;More than 60 countries including Australia, Japan, the United Kingdom, and the United States endorsed nonbinding guidelines for military use of AI,&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/south-korea-summit-announces-blueprint-using-ai-military-2024-09-10/" rel="noopener">reported</a>. The document, presented at the Responsible Artificial Intelligence in the Military (REAIM) summit in Seoul, South Korea, stresses the need for human control, thorough risk assessments, and safeguards against using AI to develop weapons of mass destruction. China and roughly 30 other countries did not sign.</p><p><strong>How it works:</strong>&nbsp;Key agreements in the&nbsp;<a href="https://thereadable.co/full-script-reaim-blueprint-for-action/" rel="noopener">blueprint</a>&nbsp;include commitments to ensure that AI doesn’t threaten peace and stability, violate human rights, evade human control, and hamper other global initiatives regarding military technology.</p><ul><li>The blueprint advocates for robust governance, human oversight, and accountability to prevent escalations and misuse of AI-enabled weapons. It calls for national strategies and international standards that align with laws that govern human rights. It also urges countries to share information and collaborate to manage risks both foreseeable and unforeseeable and maintain human control over uses of force.</li><li>It leaves to individual nations the development of technical standards, enforcement mechanisms, and specific regulations for technologies like autonomous weapons systems.</li><li>The agreement notes that AI can enhance situational awareness, precision, and efficiency in military operations, helping to reduce collateral damage and civilian fatalities. AI can also support international humanitarian law, peacekeeping, and arms control by improving monitoring and compliance. But the agreement also points out risks like design flaws, data and algorithmic biases, and potential misuse by malicious actors.</li><li>The blueprint stresses preventing AI’s use in the development and spread of weapons of mass destruction, emphasizing human control in disarmament and nuclear decision-making. It also warns of AI increasing risks of global and regional arms races.</li></ul><p><strong>Behind the News:&nbsp;</strong>The Seoul summit followed last year’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/china-us-and-other-nations-want-limits-on-military-ai/" rel="noopener">REAIM summit</a>&nbsp;in The Hague, where leaders similarly called for limits on AI military use without binding commitments. Other international agreements like the EU’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/" rel="noopener">AI Act</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-266/" rel="noopener">Framework Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law</a>&nbsp;regulate civilian AI, but exclude military applications. Meanwhile, AI-enabled targeting systems and autonomous, weaponized drones have been used in conflicts in&nbsp;<a href="https://www.deeplearning.ai/the-batch/ukraines-naval-drones-shift-balance-in-black-sea-war-against-russia/" rel="noopener">Somalia, Ukraine, and Israel</a>, highlighting the lack of international norms and controls.</p><p><strong>Why it matters:</strong>&nbsp;The REAIM blueprint may guide international discussions on the ethical use of AI in defense, providing a foundation for further talks at forums like the United Nations. Though it’s nonbinding, it fosters collaboration and avoids restrictive mandates that could cause countries to disengage.</p><p><strong>We’re thinking:&nbsp;</strong>AI has numerous military applications across not only combat but also intelligence, logistics, medicine, humanitarian assistance, and other areas. Nonetheless, it would be irresponsible to permit unfettered use of AI in military applications. Standards developed by democratic countries working together will help protect human rights.</p><hr /><figure class="kg-card kg-image-card"><img alt="A GIF showcasing a dynamic spreadsheet interaction using AI, with cells being populated and analyzed automatically." class="kg-image" height="336" src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.gif" width="600" /></figure><h1 id="enabling-llms-to-read-spreadsheets">Enabling LLMs to Read Spreadsheets</h1><p>Large language models can process small spreadsheets, but very large spreadsheets often exceed their limits for input length. Researchers devised a method that processes large spreadsheets so LLMs can answer questions about them.</p><p><strong>What’s new:</strong>&nbsp;Yuzhang Tian, Jianbo Zhao, and colleagues at Microsoft proposed&nbsp;<a href="https://arxiv.org/pdf/2407.09025" rel="noopener">SheetCompressor</a>, a way to represent spreadsheets that enables LLMs to identify and request the parts they need to answer specific questions.&nbsp;<br /><strong>Key insight:</strong>&nbsp;Most spreadsheets can be broken down into a set of tables that may be bordered by visual dividers like thick lines or empty rows and/or columns. But detecting these tables isn’t trivial, since they may contain the same kinds of markers. (See the illustration above, in which tables are denoted by red dashes.) To answer many questions, you don’t need the whole spreadsheet, only the relevant table. Moreover, given a question, an LLM can recognize the table it needs to produce an answer. However, to identify the correct table, it needs to see the whole spreadsheet, which may be too large for its input context window, and the tables, which may not be clearly separated, need to be parsed. The solution is to compress the spreadsheet, feed the compressed representation to the LLM along with the question, and ask the LLM to identify the boundaries of the table it needs to answer the question. Then, given an uncompressed version of that table, the LLM can produce an answer.</p><p><strong>How it works:</strong>&nbsp;The authors built software that prepared spreadsheets by (i) parsing them into tables and (ii) compressing them while maintaining the table structure. Then they fine-tuned LLMs to detect tables in the compressed spreadsheets and prompted the fine-tuned LLMs to identify the tables relevant to a given question.</p><ul><li>Given a spreadsheet, the authors removed rows and columns that weren’t near likely table boundaries defined by empty cells, thick lines, changes in color, and so on.&nbsp;</li><li>To compress a parsed spreadsheet, they represented each table as a JSON dictionary, using cell values as dictionary keys and cell addresses as dictionary values. (This reduces the sequence length, since duplicate cell values have the same dictionary key.) To compress it further, within each table, they detected types of values — for instance temperature, age, percentage, and so on — and merged adjacent cells that shared the same type into a single dictionary key that represented the type rather than the values. For example, merging dates that appear in the same column into a single entry: {"yyyy-mm-dd" : &lt;cell addresses&gt;}.</li><li>They compressed a&nbsp;<a href="https://arxiv.org/pdf/2106.13500" rel="noopener">dataset</a>&nbsp;of spreadsheets with annotated table boundaries according to this method. They used the compressed dataset to fine-tune GPT-4, Llama 3, and other LLMs to detect tables within compressed spreadsheets.</li><li>Inference was a two-step process: (i) Prompt the LLM, given a compressed spreadsheet and a question, to output the boundaries of the table(s) most relevant to the question and (ii) prompt the LLM, given an uncompressed version of the relevant table(s), to answer the question.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared the fine-tuned LLMs’ ability to detect tables in spreadsheets that were compressed using their method and in their original uncompressed form. They fed the models spreadsheets of various sizes that ranged from small (up to 4,000 tokens) to huge (more than 32,000 tokens). They gauged the models’ performance according to F1 score (higher is better).&nbsp;</p><ul><li><strong>Small spreadsheets</strong>: Fed compressed spreadsheets, the fine-tuned Llama 3 achieved 83 percent F1 score, and the fine-tuned GPT-4 achieved 81 percent F1 score. By contrast, fed uncompressed spreadsheets, Llama 3 achieved 72 percent F1 score, and GPT-4 achieved 78 percent F1 score.&nbsp;</li><li><strong>Huge spreadsheets:</strong>&nbsp;Fed compressed spreadsheets, the fine-tuned Llama 3 achieved 62 percent F1 score, and the fine-tuned GPT-4 achieved 69 percent F1 score. Fed uncompressed spreadsheets, both models both achieved 0 percent F1 score.</li><li><strong>Answering questions:</strong>&nbsp;The authors also tested the fine-tuned models on their own dataset of questions about 64 spreadsheets that spanned the same range of sizes, posing questions that involved fundamental tasks like searching, comparing, and basic arithmetic. Fed compressed spreadsheets, the fine-tuned GPT-4 achieved a 74 percent accuracy on zero-shot question answering. Fed uncompressed spreadsheets, it achieved 47 percent accuracy.</li></ul><p><strong>Why it matters:&nbsp;</strong>By giving LLMs the ability to detect a spreadsheet’s functional components, this approach enables them to process a wide variety of spreadsheets regardless of their size and complexity.</p><p><strong>We’re thinking:</strong>&nbsp;When considering the strengths of LLMs, we no longer have to take spreadsheets off the table.</p>
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 22:40:00 GMT</pubDate>
</item>
<item>
<title>Hollywood Embraces Video Gen, New Restrictions on Deepfakes, More Open Source Models, Robot Server</title>
<link>https://www.deeplearning.ai/the-batch/issue-268</link>
<guid>https://www.deeplearning.ai/the-batch/issue-268</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Last week I spoke at Coursera Connect, the company’s annual conference in Las Vegas, where a major topic was AI and education. There has been a lot of hype about generative AI’s ability to transform industries overnight. Certainly many industries — including education — will be transformed. But we’re about 15 years into the deep learning revolution, and we’re not yet done identifying and building useful deep learning applications. Despite the exciting progress to date with generative AI, I expect that a decade from now we will still be far from finished identifying and building generative AI applications for education and numerous other sectors.</p><p>This was the first time since 2019 that Coursera’s conference was held in person. It was great to see so many people dedicated to the educational mission coming together to discuss innovations, including generative AI innovations, that serve learners.</p><p>Coursera’s CEO Jeff Maggioncalda and the company’s executive team demonstrated multiple generative AI products, such as:</p><ul><li>Coursera Coach, a chatbot that understands the context of a learner's journey and answers their questions (without giving away exact answers to quiz questions!)</li><li>Course Builder, which businesses are using to customize long courses or specializations quickly, for example, by selecting the parts most relevant to their business</li><li>Coach for Interactive Instruction, which lets learners have a Socratic dialog and learn or practice new concepts in conversation</li></ul><p>Because AI is a general-purpose technology, there are many opportunities to apply it to different tasks in education. I was thrilled at the volume of experimentation happening across Coursera, DeepLearning.AI, and the broader ecosystem of partners and customers. I was also proud to&nbsp;<a href="https://blog.coursera.org/announcing-courseras-2024-outstanding-partner-achievement-award-winners" rel="noopener">present</a>&nbsp;<a href="https://blog.coursera.org/introducing-courseras-2024-outstanding-achievement-award-winners-customers/" rel="noopener">awards</a>&nbsp;to many partners and customers who are doing great work to serve learners.</p><figure class="kg-card kg-image-card"><img alt="Coursera Connect event in Las Vegas, September 2024, featuring Andrew Ng and Coursera executives during panel discussions and presentations." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--13--1.png" width="1200" /></figure><p>I was particularly gratified by the number of people coming together in service of the education mission. Even before the recent rise of AI, education was already urgently in need of improvement. With AI transforming jobs, the need has become even more acute. My heart was warmed by the conversations I had with many people from universities, high schools, businesses, and the Coursera team who have a deep desire to help others through education.</p><p>Coursera held its first conference in 2013, when the online education movement was in its early days, and we all had high hopes for where it could go. Today, there are over 155 million learners on Coursera. Despite that, given society’s heightened need for education and AI’s potential to transform the field, I feel the opportunities for edtech at this moment are greater than at any moment over the past decade.</p><p>Keep learning!</p><p>Andrew</p><p>P.S. I’m excited to announce our new specialization,&nbsp;<em>Generative AI for Software Development</em>, taught by Laurence Moroney! Using chatbots to generate code is not the only way AI can help developers. This three-course series shows you how to use AI throughout the software development lifecycle – from design and architecture to coding, testing, deployment, and maintenance. Everyone who writes software can benefit from these skills. Please sign up&nbsp;<a href="https://www.deeplearning.ai/courses/generative-ai-for-software-development/" rel="noopener">here</a>!</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.coursera.org/professional-certificates/generative-ai-for-software-development"><img alt="Promo banner for &quot;Generative AI for Software Development&quot;" class="kg-image" height="1125" src="https://dl-staging-website.ghost.io/content/images/2024/09/The-Batch-ads-and-exclusive-banners---2024-09-24T101915.929.png" width="2000" /></a></figure><p><em>Generative AI for Software Development</em>, our new skill certificate, gives you practical experience applying AI to coding, debugging, optimization, and documentation as it explores AI’s role across the entire development lifecycle—design, architecture, coding, testing, deployment, and maintenance. Equip yourself with the tools to enhance every step of your dev workflow.&nbsp;<a href="https://www.coursera.org/professional-certificates/generative-ai-for-software-development" rel="noopener">Enroll now</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="Flags of the United States and California Republic waving together in the wind." class="kg-image" height="316" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--10--1.gif" width="561" /></figure><h1 id="california-restricts-deepfakes">California Restricts Deepfakes</h1><p>California, a jurisdiction that often influences legislators worldwide, passed a slew of new laws that regulate deepfakes.</p><p><strong>What’s new:&nbsp;</strong>California Governor Gavin Newsom signed into law eight bills that aim to curb the use of generative AI in&nbsp;<a href="https://www.gov.ca.gov/2024/09/17/governor-newsom-signs-bills-to-combat-deepfake-election-content/#:~:text=Earlier%20today%2C%20the%20Governor%20announced,or%20likeness%20without%20their%20consent." rel="noopener">politics</a>&nbsp;and&nbsp;<a href="https://www.gov.ca.gov/2024/09/19/governor-newsom-signs-bills-to-crack-down-on-sexually-explicit-deepfakes-require-ai-watermarking/" rel="noopener">entertainment</a>.</p><p><strong>How it works:&nbsp;</strong>The legislation prohibits deceptive AI-generated media in political campaigns; requires permission for using digital stand-ins for actors, musicians, and other entertainers; and criminalizes generation of sexually explicit imagery without the subject’s consent.</p><ul><li>One law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2839" rel="noopener">prohibits</a>&nbsp;knowingly distributing deceptive AI-generated information about candidates, elections officials, or voting processes between 120 days before and 60 days after elections. The bill defines “materially deceptive content” as images, audio, or video that were intentionally created or modified but would appear to a reasonable person to be authentic.</li><li>Two related laws mandate disclosure when AI is used to produce political advertisements. The first&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2355" rel="noopener">requires</a>&nbsp;that AI-generated campaign ads include the statement, “ad generated or substantially altered using artificial intelligence.” The other&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2655" rel="noopener">calls for</a>&nbsp;large online platforms to label or remove AI-generated media related to elections.</li><li>Two further laws protect performers by controlling “digital replicas,” defined as “computer-generated, highly realistic electronic representation[s] of an individual’s voice or likeness.” One&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB1836" rel="noopener">voids</a>&nbsp;contracts for the use of digital replicas if performers didn’t have legal or union representation when they made the agreements. The other&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2602" rel="noopener">prohibits</a>&nbsp;commercial use of deceased performers’ digital replicas without permission of their estates.</li><li>Two laws regulate sexually explicit synthetic content. One&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB926" rel="noopener">establishes</a>&nbsp;the creation and distribution of non-consensual, AI-generated sexually explicit content as a disorderly conduct misdemeanor. The other&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB981" rel="noopener">requires</a>&nbsp;social media platforms to report sexually explicit deepfakes.</li><li>An additional law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB942" rel="noopener">requires</a>&nbsp;that AI-generated media include a disclosure of its provenance.</li></ul><p><strong>Behind the news:</strong>&nbsp;Newsom has not yet acted on Senate Bill 1047, a&nbsp;<a href="https://www.deeplearning.ai/the-batch/californias-proposed-ai-safety-law-puts-developers-at-risk-california-sb-1047-is-intended-to-make-ai-safer-but-its-unclear-requirements-put-developers-innovation-and-open-source-in-jeop/" rel="noopener">controversial</a>&nbsp;law that would impose significant burdens on AI model developers. He has&nbsp;<a href="https://techcrunch.com/2024/09/17/governor-newsom-on-california-ai-bill-sb-1047-i-cant-solve-for-everything" rel="noopener">expressed</a>&nbsp;that the bill could interfere with innovation, especially with respect to open source projects.</p><p><strong>Why it matters:</strong>&nbsp;Laws passed in California often point the way for legislators in other U.S. states, the federal government, and consequently other countries. The new laws that regulate deepfakes in political campaigns fill a gap left by the Federal Election Commission (FEC), which has&nbsp;<a href="https://www.fec.gov/resources/cms-content/documents/REG-2023-02-A-in-Campaign-Ads-Vice-Chair-Statement.pdf" rel="noopener">said</a>&nbsp;it lacks authority to regulate the use of AI in political ads. Meanwhile, the Federal Communications Commission (FCC)&nbsp;<a href="https://www.fcc.gov/document/fcc-proposes-disclosure-rules-use-ai-political-ads" rel="noopener">proposed</a>&nbsp;rules that would mandate disclosure of uses of AI in political ads but has yet to implement them.</p><p><strong>We’re thinking:&nbsp;</strong>We’re glad to see California target undesirable applications rather than AI models.&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-the-defiance-act-and-ftc-ban-on-fake-product-reviews-take-the-right-approach-to-regulating-ai/" rel="noopener">Regulating applications</a>&nbsp;rather than general-purpose technology that has a wide variety of uses — many of which are beneficial — avoids the dangers of California SB-1047, which is still awaiting the governor’s signature or veto. That law, which seeks to restrict AI models, would&nbsp;<a href="https://www.deeplearning.ai/the-batch/californias-proposed-ai-safety-law-puts-developers-at-risk-california-sb-1047-is-intended-to-make-ai-safer-but-its-unclear-requirements-put-developers-innovation-and-open-source-in-jeop/" rel="noopener">endanger</a>&nbsp;innovation and especially open source.</p><hr /><figure class="kg-card kg-image-card"><img alt="Comparison chart displaying performance metrics for various AI models, including Qwen, Gemma2, and GPT4-mini, across different benchmarks." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--11-.gif" width="1200" /></figure><h1 id="more-better-open-source-options">More, Better Open Source Options</h1><p>The parade of ever more capable LLMs continues with Qwen 2.5.</p><p><strong>What’s new:</strong>&nbsp;Alibaba released&nbsp;<a href="https://qwenlm.github.io/blog/qwen2.5-llm/" rel="noopener">Qwen 2.5</a>&nbsp;in several sizes, the API variants Qwen Plus and Qwen Turbo, and the specialized models&nbsp;<a href="https://qwenlm.github.io/blog/qwen2.5-coder/" rel="noopener">Qwen 2.5-Coder and Qwen 2.5-Coder-Instruct</a>&nbsp;and&nbsp;<a href="https://qwenlm.github.io/blog/qwen2.5-math/" rel="noopener">Qwen 2.5-Math and Qwen 2.5-Math-Instruct</a>. Many are freely available for commercial use under the Apache 2.0 license&nbsp;<a href="https://huggingface.co/Qwen" rel="noopener">here</a>. The 3B and 72B models are also free, but their&nbsp;<a href="https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20RESEARCH%20LICENSE%20AGREEMENT" rel="noopener">license</a>&nbsp;requires special arrangements for commercial use.</p><p><strong>How it works:</strong>&nbsp;The Qwen 2.5 family ranges from 500 million parameters to 72 billion parameters.</p><ul><li>Qwen 2.5 models were pretrained on 18 trillion tokens. Sizes up to 3 billion parameters can process up to 32,000 input tokens; the larger models can process up to 128,000 input tokens. All versions can have an output length of 8,000 tokens.</li><li>Qwen 2.5-Coder was further pretrained on 5.5 trillion tokens of code. It can process up to 128,000 input tokens and generate up to 2,000 output tokens. It comes in 1.5B and 7B versions.</li><li>Qwen 2.5-Math further pretrained on 1 trillion tokens of math problems, including Chinese math problems scraped from the web and generated by the earlier Qwen 2-Math-72B-Instruct. Qwen 2.5-Math can process 4,000 input tokens and generate up to 2,000 output tokens. It comes in 1.5B, 7B, and 72B versions. In addition to solving math problems, Qwen 2.5-Math can generate code to help solve a given math problem.</li></ul><p><strong>Results:</strong>&nbsp;Compared to other models with open weights, Qwen 2.5-72B-Instruct beats LLama 3.1 405B Instruct and Mistral Large 2 Instruct (123 billion parameters) on seven of 14 benchmarks including&nbsp;<a href="https://arxiv.org/abs/2403.07974" rel="noopener">LiveCodeBench</a>,&nbsp;<a href="https://arxiv.org/abs/2103.03874" rel="noopener">MATH</a>&nbsp;(solving math word problems), and&nbsp;<a href="https://arxiv.org/abs/2009.03300" rel="noopener">MMLU</a>&nbsp;(answering questions on a variety of topics). Compared to other models that respond to API calls, Qwen-Plus beats LLama 3.1 405B, Claude 3.5 Sonnet, and GPT-4o on MATH, LiveCodeBench, and&nbsp;<a href="https://arxiv.org/abs/2406.11939" rel="noopener">ArenaHard</a>. Smaller versions also deliver outstanding performance. For instance, Qwen 2.5-14B-Instruct outperforms Gemma 2 27B Instruct and GPT-4o mini on seven benchmarks.</p><p><strong>Behind the news:</strong>&nbsp;Qwen 2.5 extends a parade of ever more capable LLMs that include Claude 3.5 Sonnet, GPT-4o, and LLama 3.1 as well as the earlier&nbsp;<a href="https://www.deeplearning.ai/the-batch/alibaba-advances-open-weight-llms-with-qwen2-math-and-audio-variants/" rel="noopener">Qwen 2 family</a>.</p><p><strong>Why it matters:&nbsp;</strong>The new models raise the bar for open weights models of similar sizes. They also rival some proprietary models, offering options to users who seek to balance performance and cost.</p><p><strong>We’re thinking:&nbsp;</strong>Some companies encourage developers to use their paid APIs by locking their LLMs behind non-commercial licenses or blocking commercial applications beyond a certain threshold of revenue. We applaud Qwen’s approach, which keeps most models in the family open.</p><hr /><figure class="kg-card kg-image-card"><img alt="GIF featuring various scenes including people in a protest, close-ups of eyes, and outdoor landscapes." class="kg-image" height="334" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--12-.gif" width="600" /></figure><h1 id="hollywood-embraces-video-generation">Hollywood Embraces Video Generation</h1><p>The AI startup Runway is helping to retool Lionsgate, the producer of blockbuster movie franchises like&nbsp;<em>The Hunger Games</em>&nbsp;and&nbsp;<em>John Wick</em>, for the era of generated video.</p><p><strong>What’s new:&nbsp;</strong>Runway will&nbsp;<a href="https://investors.lionsgate.com/news-and-events/press-releases/2024/09-18-2024-140126979" rel="noopener">build</a>&nbsp;a custom video generator to help Lionsgate streamline its production processes. It also&nbsp;<a href="https://runwayml.com/news/introducing-the-runway-api" rel="noopener">launched</a>&nbsp;an API for its Gen-3 Alpha Turbo model.</p><p><strong>Runway + Lionsgate:</strong>&nbsp;Runway will fine-tune its proprietary models on Lionsgate productions to enable the filmmaker to generate new imagery based on its previous work. The companies didn’t disclose financial terms of the arrangement.</p><ul><li>Lionsgate plans to use the custom model for pre-production tasks like visualization and storyboarding, and for post-production processes like editing and special effects.</li><li>The custom model could save Lionsgate “millions and millions of dollars,” a Lionsgate executive&nbsp;<a href="https://www.wsj.com/business/media/lionsgate-studio-behind-john-wick-signs-deal-with-ai-startup-runway-f2180245" rel="noopener">told</a>&nbsp;<em>The Wall Street Journal</em>.</li><li>Other studios, too, are looking into building video generation models that are fine-tuned on their own productions,&nbsp;<em>Variety</em>&nbsp;<a href="https://variety.com/vip/what-lionsgates-partnership-deal-runway-means-1236151418/" rel="noopener">reported</a>. Runway is in talks with some of them, the startup’s CEO Cristóbal Valenzuela&nbsp;<a href="https://www.axios.com/pro/media-deals/2024/09/23/runway-lionsgate-ai-deal" rel="noopener">told</a>&nbsp;Axios.</li></ul><p><strong>Gen-3 API:</strong>&nbsp;Concurrently with announcing the Lionsgate deal, Runway&nbsp;<a href="https://help.runwayml.com/hc/en-us/articles/33350169138323-Creating-with-Video-to-Video" rel="noopener">unveiled</a>&nbsp;an API that drives its Gen-3 Alpha and Gen-3 Alpha Turbo models as well as updates to Gen-3 Alpha.</p><ul><li>The company charges around $0.60 to $1.20, depending on the service tier, to generate outputs up to 5 seconds long and twice that for up to 10 seconds long.</li><li>Third-party user interfaces that connect to the API must include a “Powered by Runway” banner that links to Runway’s website.</li><li><a href="https://help.runwayml.com/hc/en-us/articles/30266515017875-Creating-with-Gen-3-Alpha" rel="noopener">Gen-3 Alpha</a>&nbsp;now allows users to transform existing videos into new styles using text prompts and steer its output using video input in addition to a prompt. The model’s output will follow the input video’s shapes and motions.</li></ul><p><strong>Why it matters:&nbsp;</strong>Although the plan is to use Runway’s technology for pre- and post-production, this deal puts state-of-the-art video generation at the heart of Lionsgate’s operations and encourages professional cinematographers, editors, special effects artists, and other cinematic specialists to see what they can do with it. For Lionsgate, it’s a bid to stay ahead of competitors. For AI, it could be a major move into the Hollywood spotlight.</p><p><strong>We’re thinking:&nbsp;</strong>While upstart competitors are using pretrained models, Lionsgate will be using a model that has internalized its own style and capabilities.</p><hr /><figure class="kg-card kg-image-card"><img alt="Man playing table tennis against a robotic arm, which returns the ball during the match." class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--13-.gif" width="600" /></figure><h1 id="robot-server">Robot Server</h1><p>A robot that plays table tennis beats human beginners and entertains experts.</p><p><strong>What’s new:</strong>&nbsp;David B. D’Ambrosio, Saminda Abeyruwan, Laura Graesser, Atil Iscen, Pannag R. Sanketi and colleagues at Google showed off a&nbsp;<a href="https://arxiv.org/pdf/2408.03906" rel="noopener">robot arm</a>&nbsp;that challenges human players at table tennis. You can see it in action&nbsp;<a href="https://sites.google.com/view/competitive-robot-table-tennis" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;A table tennis match can be broken into individual volleys that start when an opponent hits the ball and end when the robot returns the ball to the opponent’s side of the table or the ball goes out of play. This simple scheme enables a robotic control system to learn how to return a ball without attending to strategy.</p><p><strong>The robot:</strong>&nbsp;The authors mounted a&nbsp;<a href="https://webshop.robotics.abb.com/us/articulated-robot-irb-1100-series.html" rel="noopener">robotic arm</a>&nbsp;atop two linear gantries that enabled the arm to move to the left and right, and forward and backward. Two&nbsp;<a href="https://www.ximea.com/en/products/cameras-filtered-by-sensor-types/mq013cg-on" rel="noopener">cameras</a>&nbsp;captured images of the ball and fed them to a&nbsp;<a href="https://arxiv.org/abs/2309.03315" rel="noopener">perception system</a>&nbsp;that estimated ball positions. A 20-camera&nbsp;<a href="https://www.phasespace.com/" rel="noopener">motion-capture system</a>&nbsp;tracked the position of the opponent’s paddle.</p><p><strong>How it works:</strong>&nbsp;Instead of training an end-to-end system or using a robotics foundation model, the authors broke down the gameplay into subtasks, delegated them to separate modules, and orchestrated them to work together. The robot was controlled by a high-level controller: a custom algorithm including a convolutional neural network (CNN) that classified whether to return the ball using a forehand or backhand stroke and a vanilla neural network that classified spin. The high-level controller selected among 17 low-level controllers (all CNNs). Each low-level controller executed a different skill, enabling the system to return serves or rallies, adjust for ball spin, target different spots on the table, and so on.&nbsp;</p><ul><li>The authors collected a dataset of ball positions from human-to-human play. Using the perception system, they derived the ball’s initial positions, velocities, and angular velocities. After training the system the first time, they collected similar data for human-robot play and trained their system further using those examples.&nbsp;</li><li>Training took place in a&nbsp;<a href="https://mujoco.org/" rel="noopener">simulation</a>&nbsp;(except the high-level controller’s vanilla neural network, which learned to classify spin via supervision).The high-level controller’s CNN learned to choose forehand or backhand to maximize the rate at which the robot successfully returned the ball. The low-level controllers learned using&nbsp;<a href="https://arxiv.org/abs/2207.06572" rel="noopener">blackbox gradient sensing</a>, an evolutionary algorithm, based on several rewards, such as rewarding the controller if it successfully returned the ball and punishing it if the robot collided with itself or the table.&nbsp;</li><li>Each time the opponent hit the ball, the high-level controller decided which low-level controller to use. The decision was based on factors such as whether the ball had topspin or underspin and estimated statistics such as return rate, opponent’s paddle velocity, and estimated position where the ball would land on the opponent’s side.</li><li>Given the last 0.14 seconds of the ball’s position and velocity, as well as the robot’s joint positions and its position on the gantries, the selected low-level controller determined how fast to move the robot to return the ball.</li></ul><p><strong>Results:&nbsp;</strong>The robot played 29 three-game matches against 29 players of varying skill (beginner, intermediate, advanced, and advanced+ as rated by a professional coach).</p><ul><li>It won all 7 (100 percent) of its matches against beginners, 6 (55 percent) of its matches against intermediate players, and zero matches against advanced or advanced+ players.</li><li>On a point-by-point basis, it won 72 percent of points against beginners, 50 percent against intermediate players, and 34 percent of points against advanced and advanced+ players.</li><li>When asked if they would like to play against the robot again on a scale of 1 (definitely not) to 5 (definitely yes), the average response was 4.87.</li></ul><p><strong>Why it matters:</strong>&nbsp;Roboticists have been programming robot arms to play table tennis for at least a&nbsp;<a href="https://www.youtube.com/watch?v=tIIJME8-au8" rel="noopener">decade</a>. Earlier projects enabled robots to perform various aspects of the game, like aiming at a specific target or smashing, but none tackled complete gameplay against competitive human opponents. Breaking the problem into two parts — a library of individual skills (low-level controllers) and an algorithm that chooses which to use — simplifies the task. Weaknesses in the robot’s performance (for example, difficulty returning underspin) can be addressed by adding a skill that compensates.</p><p><strong>We’re thinking:</strong>&nbsp;Even expert players had enough fun playing against this robot to want to play more. That’s a successful gaming system!</p>
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 20:04:00 GMT</pubDate>
</item>
<item>
<title>Models Built for Reasoning, High Gear for Llama 3.1, Brains for Warehouse Robots, Stopping LLMs From Plagiarizing</title>
<link>https://www.deeplearning.ai/the-batch/issue-267</link>
<guid>https://www.deeplearning.ai/the-batch/issue-267</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Years ago, when I was working at a large tech company, I was responsible for the data warehouse. Every piece of data relating to individual users was supposed to come through the data warehouse, and it was an intellectually challenging undertaking to store the data reliably and make it available to other teams, subject to security and privacy guardrails, so they could use it to derive insights.</p><p>I wish that, back then, I (and my whole team) had had access to the&nbsp;<a href="https://www.coursera.org/professional-certificates/data-engineering" rel="noopener">Data Engineering Professional Certificate</a>, a major new specialization we just launched on Coursera!</p><p>Data underlies all modern AI systems, and engineers who know how to build systems to store and serve it are in high demand.&nbsp;Today, far too many businesses struggle to build a robust data infrastructure, which leads to missed opportunities to create value with data analytics and AI. Additionally, AI’s rise is accelerating the demand for data engineers.</p><p>If you’re interested in learning these skills, please check out this four-course sequence, which is designed to make you job-ready as a data engineer.</p><p>The Data Engineering Professional Certificate is taught by Joe Reis, co-author of the best-selling book&nbsp;<em>Fundamentals of Data Engineering</em>, in collaboration with Amazon Web Services. (Disclosure: I serve on Amazon's board of directors.) When DeepLearning.AI decided to teach data engineering, I felt that Joe, who has helped many startups and big companies design their data architectures and thus has broad and deep experience in this field, would be the ideal instructor. He was the first person we reached out to, and I was thrilled that he agreed to work with us on this. I hope that you’ll be thrilled, too, taking this specialization!</p><p>While building AI systems and analyzing data are important skills, the data that we feed into these systems determines their performance. In this specialization, you’ll go through the whole data engineering lifecycle and learn how to generate, ingest, store, transform, and serve data. You’ll learn how to make necessary tradeoffs between speed, flexibility, security, scalability, and cost.</p><figure class="kg-card kg-image-card"><img alt="Diagram of the data engineering cycle from generation to ingestion and transformation to analytics and machine learning." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--11--1.png" width="1200" /></figure><p>If you’re a software engineer, this will give you a deeper understanding of data engineering so that you can build data applications. If you’re an aspiring or practicing data scientist or AI/machine learning engineer, you’ll learn skills that expand your scope to manage data in a more sophisticated way.&nbsp;For example, you’ll learn about DataOps to automate and monitor your data pipelines, and how to build “infrastructure as code” to programmatically define, deploy, and maintain your data infrastructure, as well as best practices for data-centric AI.</p><p>You’ll also hear 17 other industry leaders share their wisdom about effective data engineering. Bill Inmon, the father of data warehousing, shares fascinating stories about the evolution of the data warehouse, including how he wrote his first program as a student in 1965. Wes McKinney, creator of the Python pandas package (as in “import pandas as pd”), talks about how he designed this wildly popular package and shares best practices for data manipulation. These instructors will give you a mental framework for developing and deploying data systems.</p><p>Getting your data infrastructure right is a valuable foundational skill that will serve you well in whatever you do with AI or data analytics. I hope you&nbsp;<a href="https://www.coursera.org/professional-certificates/data-engineering" rel="noopener">enjoy this specialization</a>!</p><p>Keep learning,</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="Data Engineering Professional Certificate." class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/09/The-Batch-ads-and-exclusive-banners---2024-09-17T093235.946.png" width="1680" /></figure><p>Learn the principles of data engineering with our four-course professional certificate taught by Joe Reis. Develop skills throughout the data engineering lifecycle and gain hands-on experience building systems on Amazon Web Services. Earn a certificate upon course completion!&nbsp;<a href="https://www.coursera.org/professional-certificates/data-engineering" rel="noopener">Enroll today</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="OpenAI's model scores on the GPQA Diamond tests in biology, chemistry, and physics, along with their overall score. o1 outperforms o1-preview, which in turn outperforms gpt-4o." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--8-.gif" width="1200" /></figure><h1 id="openai-o1-forges-chains-of-thought">OpenAI o1 Forges Chains of Thought</h1><p>Preliminary versions of OpenAI’s new model family were trained explicitly to think step-by-step, yielding outstanding marks in math, science, and coding — but users can’t see their reasoning steps.</p><p><strong>What’s new:</strong>&nbsp;OpenAI launched beta versions of&nbsp;<a href="https://openai.com/index/learning-to-reason-with-llms/" rel="noopener">o1-preview and o1-mini</a>, language models that were trained via reinforcement learning to use chains of thought. The models are available to paid ChatGPT users as well as API customers who have been onboard for more than 30 days and spent $1,000. o1-preview costs $15/$60 per million input/output tokens, significantly higher than GPT-4o’s price of $5/$15. o1-mini costs $3/$12 per million input/output tokens. OpenAI didn’t announce a release date for a finished o1 model.</p><p><strong>How it works:</strong>&nbsp;o1-preview is a preliminary release, and o1-mini is a faster preliminary version that’s particularly effective at coding. OpenAI published an&nbsp;<a href="https://cdn.openai.com/o1-system-card.pdf" rel="noopener">o1 system card</a>&nbsp;but hasn’t disclosed details about the new models’ size, architecture, or training. Both models have an input context window of 128,000 tokens. They accept only text tokens, but OpenAI plans to support other media types in future versions.</p><ul><li>o1-preview and o1-mini were trained on data scraped from the web, open-source databases, and proprietary data supplied by partners and OpenAI. The reinforcement learning process rewarded the models for generating desired reasoning steps and for their alignment with human values, goals, and expectations.&nbsp;</li><li>The beta models process “reasoning tokens” that the company charges for as though they were output tokens although they’re invisible to users. The use of reasoning tokens makes the models slower and costlier to produce output than GPT-4o, but they deliver superior performance in tasks that benefit from step-by-step reasoning. OpenAI provides an example in which o1-preview deciphered enciphered text in which each letter is replaced by two letters that, according to alphabetical order, are equidistant from the intended letter. In other examples, it calculates the pH of a solution of ammonium fluoride and suggests a medical diagnosis based on symptoms that are present and absent.</li><li>o1-preview’s output is limited to around 32,768 tokens, including reasoning tokens, while o1-mini’s is capped at roughly 65,536. OpenAI&nbsp;<a href="https://platform.openai.com/docs/guides/reasoning?reasoning-prompt-examples=coding-planning" rel="noopener">recommends</a>&nbsp;budgeting 25,000 tokens for reasoning.</li><li>OpenAI keeps the chain of thought hidden to avoid exposing information that wasn’t requested. In addition, it doesn’t want users to try to control the model’s reasoning, and it doesn’t want competitors to see what’s going on behind the scenes. (Nonetheless, ChatGPT users can see a summary of steps that led to a given response)</li><li>OpenAI and third parties conducted safety evaluations, including testing for inappropriate outputs, race, gender, and age biases, and harmful chains of thought. o1-preview and o1-mini returned fewer hallucinations and showed more resistance to jailbreaking attacks than GPT-4o and GPT-4o mini. Both models show a higher risk than previous OpenAI models of helping to produce biological threats, but the risk is within the bounds of its safety policy.</li></ul><p><strong>Results:&nbsp;</strong>The actual o1 model — which remains unavailable — generally&nbsp;<a href="https://openai.com/index/learning-to-reason-with-llms/" rel="noopener">outperforms</a>&nbsp;o1-preview, while both vastly outperform GPT-4o on math, science, and coding benchmarks.&nbsp;</p><ul><li><strong>o1:</strong>&nbsp;The forthcoming model outperformed GPT-4o on 54 out of 57 MMLU subcategories that test knowledge in fields like elementary mathematics, U.S. history, and law. It achieved an Elo score of 1,673 on coding contests drawn from the website Codeforces (in which it was allowed 10 submissions for any given problem), putting it in the 89th percentile (human expert level). On the&nbsp;<a href="https://arxiv.org/abs/2311.12022" rel="noopener">GPQA</a>&nbsp;Diamond tests of graduate-level knowledge in biology, chemistry, and physics, it scored higher than PhD-level experts recruited by OpenAI. It correctly answered 74 percent of questions from the 2024 USA Math Olympiad qualifier.&nbsp;</li><li><strong>o1-preview:</strong>&nbsp;The preview version ranked in the 62nd percentile on Codeforces. Human evaluators preferred its output to that of GPT-4o in response to prompts that tested coding, data analysis, and math. (They preferred GPT-4o’s responses to prompts that requested “personal writing.”)</li></ul><p><strong>Behind the news:&nbsp;</strong>In recent months, Anthropic has been using the tag &lt;antThinking&gt; to generate thinking tokens that are hidden from users. However, OpenAI’s implementation in the o1 models takes this capability much further.</p><p><strong>Why it matters:&nbsp;</strong>The o1 models show that the combination of reinforcement learning and chain-of-thought reasoning can solve problems that large language models generally find challenging. They’re substantially more accurate in domains such as coding, math, and science that have low tolerance for error. However, the fact that the models hide their reasoning from users makes them less transparent and explainable than their predecessors and may make their outstanding performance less valuable in some applications.</p><p><strong>We’re thinking:</strong>&nbsp;Agentic workflows can significantly improve a system’s ability to reflect, reason, and iterate on its output. Training a model to take such steps directly in response to even general-purpose questions opens an exciting alternative path to better reasoning beyond simply scaling up model size.</p><hr /><figure class="kg-card kg-image-card"><img alt="Llama 3.1 405B output speed versus price. Scatterplot showing SambaNova at a very high speed relative to its cost. Image by Artificial Analysis." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--9-.gif" width="1200" /></figure><h1 id="high-gear-for-llama-31-405b">High Gear for Llama 3.1 405B</h1><p>SambaNova raised the speed limit for access to the largest model in the Llama 3.1 family — and it’s free.</p><p><strong>What’s new:&nbsp;</strong>SambaNova&nbsp;<a href="https://sambanova.ai/press/worlds-fastest-ai-platform" rel="noopener">launched</a>&nbsp;a cloud service that runs Llama 3.1 405B significantly faster than competitors. A free tier is available, to be followed later this year by paid tiers that offer higher rate limits.</p><p><strong>How it works:</strong>&nbsp;SambaNova uses proprietary&nbsp;<a href="https://www.nextplatform.com/2023/09/20/sambanova-tackles-generative-ai-with-new-chip-and-new-approach/" rel="noopener">chips</a>&nbsp;and software to accelerate model inference.</p><ul><li>The platform enables Llama 3.1 405B to generate 129 tokens per second (the fastest on the market) for $5/$10 per million input/output tokens. It enables Llama 3.1 70B to generate 411 tokens per second (behind Cerebras, which costs somewhat less) for $0.60/$1.20 per million input/output tokens, and Llama 3.1 8B to generate 998 tokens per second (also behind Cerebras, which offers a slightly lower price) for $0.10/$0.20 per million input/output tokens,&nbsp;<a href="https://artificialanalysis.ai/providers/sambanova" rel="noopener">according to</a>&nbsp;Artificial Analysis. SambaNova’s own testing shows 132 tokens per second for Llama 3.1 405B and 461 tokens per second for Llama 3.1 70B.</li><li>Unlike some competitors, SambaNova runs Llama 3.1 at 16-bit precision (technically bf16/fp32 mixed precision). Models that process at&nbsp;<a href="https://sambanova.ai/blog/sn40l-chip-best-inference-solution" rel="noopener">lower precision</a>&nbsp;can achieve higher speeds or run on less powerful hardware but lose accuracy.&nbsp;</li></ul><p><strong>Yes, but:</strong>&nbsp;SambaNova currently limits Llama 3.1’s context window to around 8,000 tokens, much less than the model’s native 128,000 tokens.</p><p><strong>Behind the news:&nbsp;</strong>The new service arrives amid a broader competition to deliver fast inference among cloud providers that have developed their own specialized chips. Competitors like&nbsp;<a href="https://siliconangle.com/2024/08/27/cerebras-systems-throws-down-gauntlet-to-nvidia-launch-of-worlds-fastest-ai-inference-service/" rel="noopener">Cerebras</a>&nbsp;and&nbsp;<a href="https://groq.com/news_press/groq-supercharges-fast-ai-inference-for-meta-llama-3-1/" rel="noopener">Groq</a>&nbsp;have introduced their own high-speed inference services.</p><p><strong>Why it matters:&nbsp;</strong>Throughput, cost, performance, and latency are critical factors in practical applications of AI models. Fast inference allows for more frequent API calls without bogging down time to output, which is essential for agentic workflows and real-time decision making.</p><p><strong>We’re thinking:</strong>&nbsp;Models with open weights are now served faster than proprietary models and are nearly as capable. This may spur further adoption of open models as well as prompting strategies, such as agentic workflows, that require large numbers of output tokens.</p><hr /><figure class="kg-card kg-image-card"><img alt="Covariant robotic arm clutching an Amazon box." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--16-.jpg" width="1200" /></figure><h1 id="amazon-boosted-by-covariant">Amazon Boosted by Covariant</h1><p>Amazon took on talent and technology from robotics startup Covariant to enhance its warehouse automation, an area critical to its core ecommerce business.</p><p><strong>What’s new:</strong>&nbsp;Amazon announced an&nbsp;<a href="https://www.aboutamazon.com/news/company-news/amazon-covariant-ai-robots" rel="noopener">agreement</a>&nbsp;to hire Covariant’s cofounders and other key personnel and license its models. Financial terms were not disclosed. (Disclosure: Andrew Ng is a member of Amazon’s board of directors.)</p><p><strong>How it works:</strong>&nbsp;The new deal echoes Amazon’s previous not-quite acquisition of Adept as well as similar arrangements between other tech giants and startups.&nbsp;</p><ul><li>Amazon received a non-exclusive license to Covariant’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/rfm-1-a-model-that-enables-robots-to-understand-and-act-on-human-commands/" rel="noopener">RFM-1</a>, a model that enables robots to follow commands given as text or images, answer questions, and request further instructions. The deal will scale up Covariant’s installed base by several orders of magnitude: Covariant maintains&nbsp;<a href="https://covariant.ai/insights/the-future-of-robotics-robotics-foundation-models-and-the-role-of-data/" rel="noopener">hundreds</a>&nbsp;of robots, while Amazon has over&nbsp;<a href="https://www.aboutamazon.com/news/operations/amazon-introduces-new-robotics-solutions" rel="noopener">750,000</a>.</li><li>Covariant CEO Peter Chen, CTO Rocky Duan, Chief Scientist Pieter Abbeel — all of whom are co-founders of the company — joined Amazon. Roughly a quarter of Covariant’s current staff moved to Amazon as well. The new hires will implement Covariant’s models in Amazon’s robots and work on fundamental AI research and human-robot interaction.</li><li>Ted Stinson, previously Covariant’s COO, will lead the company as the new CEO alongside remaining co-founder Tianhao Zhang. Covariant will continue to serve existing customers in industries beyond ecommerce, including fulfillment and distribution, apparel, grocery, health and beauty, and pharmaceuticals, the company&nbsp;<a href="https://covariant.ai/insights/introducing-the-next-phase-of-our-ai-robotics-journey/" rel="noopener">said</a>.&nbsp;</li></ul><p><strong>Behind the news:&nbsp;</strong>Amazon has been working to acquire technical talent and technology for some time. In 2022, it announced that it would acquire iRobot, but the companies&nbsp;<a href="https://www.robotics247.com/article/consumer_robot_manufacturer_irobot_and_amazon_halt_acquisition" rel="noopener">abandoned</a>&nbsp;that plan earlier this year after EU regulators blocked the deal citing antitrust concerns. In October, it&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/" rel="noopener">committed</a>&nbsp;to invest as much as $4 billion in Anthropic in return for access to the startup’s technology. (UK regulatory authorities subsequently&nbsp;<a href="https://www.reuters.com/technology/uks-antitrust-regulator-probe-amazons-ai-partnership-with-anthropic-2024-08-08/" rel="noopener">announced</a>&nbsp;an antitrust probe into Amazon’s relationship with Anthropic.) In July, it&nbsp;<a href="https://www.deeplearning.ai/the-batch/amazon-add-majority-of-adept-ai-staff-to-boost-agentic-ai-capabilities/" rel="noopener">signed</a>&nbsp;a hire-and-license deal — similar to its agreement with Covariant — with agentic AI startup Adept.</p><p><strong>Why it matters:</strong>&nbsp;Competition among AI giants continues to heat up. Amazon’s agreement with Covariant mirrors other deals in which a tech giant gained top talent and technology without formally acquiring a startup, including Microsoft’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-pays-inflection-ai-650-million-hires-most-of-its-staff/" rel="noopener">arrangement</a>&nbsp;with Inflection and Google’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-acquires-character-ai-talent-and-tech-in-strategic-move/" rel="noopener">deal</a>&nbsp;with Character.AI. These developments highlight top tech companies’ race to secure their AI positions — and the fact that outright acquisitions invite regulatory scrutiny.</p><p><strong>We’re thinking:</strong>&nbsp;Robotic foundation models that are trained on large amounts of unlabeled robotics data offer a promising way to quickly fine-tune robots to perform new tasks — potentially a major upgrade in warehouse logistics.</p><hr /><figure class="kg-card kg-image-card"><img alt="Comparing standard loss with Goldfish loss using text from Harry Potter. Goldfish loss does not regenerate the repetitive text." class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--12-.png" width="1200" /></figure><h1 id="reducing-memorization-in-llms">Reducing Memorization in LLMs </h1><p>Studies have established that large language models can memorize the text passages they’ve been trained on repeatedly and regurgitate them when prompted in adversarial and, though rarely, in benign ways. Researchers proposed a way to reduce this tendency and attendant risks to intellectual property and privacy.</p><p><strong>What’s new:&nbsp;</strong>Abhimanyu Hans and colleagues from University of Maryland introduced the&nbsp;<a href="https://arxiv.org/abs/2406.10209" rel="noopener">goldfish loss</a>, a modification of the next-token-prediction loss function typically used in large language models. The goldfish loss avoids memorization of long passages by masking some tokens during the loss computation.</p><p><strong>Key insight:</strong>&nbsp;Certain passages may appear many times during training, either because the model takes multiple passes over data or because they’re duplicated in the training corpus. Randomly masking individual tokens from the loss computation doesn’t prevent a model from memorizing repeated passages because the model, over many repetitions, still sees every word and its place in the order. But masking a long passage the same way with every repetition ensures the model can’t memorize the passage regardless of the number of repetitions.</p><p><strong>How it works:&nbsp;</strong>The goldfish loss masks the current token from the loss computation based on previous tokens. &nbsp;A deterministic hashing function decides which tokens to mask effectively at random the first time it encounters a particular 13-token sequence, but identically if it encounters the same sequence again. At a high level, it masks a certain percentage of tokens, typically one in three or four. The authors compared the goldfish loss to the next-token-prediction loss function in two settings: one that mimicked a typical training process and one that made memorization more likely.</p><ul><li>For the typical training process, the authors trained&nbsp;<a href="https://arxiv.org/abs/2401.02385" rel="noopener">TinyLLaMa-1.1B</a>&nbsp;for one epoch on a subset of&nbsp;<a href="https://github.com/togethercomputer/RedPajama-Data" rel="noopener">RedPajama</a>, a de-duplicated dataset of text scraped from the web. To provide duplicate text, they added 2,000 sequences from Wikipedia, each repeated 50 times.</li><li>To promote memorization, they fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2307.09288" rel="noopener">Llama 2 7B</a>&nbsp;for 100 epochs on 100 Wikipedia articles.</li></ul><p><strong>Results:&nbsp;</strong>The authors assessed the results using two metrics: (i)&nbsp;<a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="noopener">ROUGE-L</a>, which falls between 0 and 100 percent and reflects the longest subsequence in common between ground-truth and generated data, and (ii) the percentage of tokens that exactly matched the original text in proper order. Both measure memorization, so lower scores are better.</p><ul><li>In the typical setting, the model trained using the next-token-prediction loss memorized heavily, while the model trained with the goldfish loss memorized just a little bit.</li><li>In the setting that promoted memorization, the model trained using the next-token-prediction loss exactly matched 85 percent of the tokens in the Wikipedia articles and achieved 96 percent ROUGE-L. The model using the goldfish loss exactly matched 0 percent of the Wikipedia tokens and achieved 51 percent ROUGE-L.</li><li>Both models achieved similar performance on six common-sense reasoning and question answering tasks, indicating that the goldfish loss didn’t hinder the accuracy on those tasks.</li></ul><p><strong>Why it matters:&nbsp;</strong>Businesses are worried about whether using LLMs<strong>&nbsp;</strong>poses risks to intellectual property rights and privacy. Techniques that address this concern without significantly impacting performance are welcome.</p><p><strong>We’re thinking:&nbsp;</strong>Memorization also happens in models generating images. We look forward to research into using similar techniques in that domain.&nbsp;</p>
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 23:00:00 GMT</pubDate>
</item>
<item>
<title>Nations Sign Binding AI Treaty, Waymo Reveals Safety Record, 2D to 3D Goes Mainstream, Balancing Web Data Distributions</title>
<link>https://www.deeplearning.ai/the-batch/issue-266</link>
<guid>https://www.deeplearning.ai/the-batch/issue-266</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Over the weekend, my two kids colluded in a hilariously bad attempt to mislead me to look in the wrong place during a game of hide-and-seek. I was reminded that most capabilities — in humans or in AI — develop slowly.</p><p>Some people fear that AI someday will learn&nbsp;to deceive humans deliberately. If that ever happens, I’m sure we will see it coming from far away and have plenty of time to stop it.</p><p>While I was counting to 10 with my eyes closed, my daughter (age 5) recruited my son (age 3) to tell me she was hiding in the bathroom while she actually hid in the closet. But her stage whisper, interspersed with giggling, was so loud I heard her instructions clearly. And my son’s performance when he pointed to the bathroom was so hilariously overdramatic, I had to stifle a smile.</p><p>Perhaps they will learn to trick me someday, but not yet! (In his awful performance, I think my son takes after me. To this day, I have a terrible poker face — which is matched by my perfect lifetime record of losing every poker game I have ever played!)</p><p>Last year, the paper “<a href="https://papers.neurips.cc/paper_files/paper/2023/file/adc98a266f45005c403b8311ca7e8bd7-Paper-Conference.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">Are Emergent Abilities of Large Language Models a Mirage?</a>” by Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, which won a NeurIPS outstanding paper award, considered “emergent” properties of LLMs, which refers to capabilities that seem to appear suddenly as model sizes increase. The authors point out that scaling laws imply that the per-token error rate decreases (improves) slowly with scale, and emergent properties might be an artifact of researchers studying nonlinear or discontinuous metrics that transform a gradually decreasing per-token error rate into something that looks more like a step function.</p><figure class="kg-card kg-image-card"><img alt="Comic where a robot is hiding in a closet during a game of hide-and-seek." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--10--1.jpg" width="1200" /></figure><p>Consider a “combination lock” metric that requires getting many items right. Say we’re measuring the likelihood that an LLM will get 10 independent digits of an answer right. If the odds of it getting each digit right improve gradually from 0 to 1, then the odds of it getting all 10 digits right will appear to jump suddenly. But if we look at continuous metrics, such as the total number of correct digits, we will see that the underlying performance actually improves gradually. (Public perception of a technology can also shift in a discontinuous way because of social dynamics.)</p><p>This is why many of us&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-to-spot-high-impact-technologies/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">saw GPT-3 as a promising step</a>&nbsp;in transforming text processing long before ChatGPT appeared: BERT, GPT, GPT-2, and GPT-3 represented points on a continuous spectrum of progress. Or, looking back further in AI history, even though AlphaGo’s victory over Lee Sedol in the game of Go took the public by surprise, it actually represented many years of gradual improvements in AI’s ability to play Go.</p><p>While analogies between human and machine learning can be misleading, I think that just as a person’s ability to do math, to reason — or to deceive — grows gradually, so will AI’s. This means the capabilities of AI technology will grow gradually (although I wish we could achieve AGI overnight!), and the ability of AI to be used in harmful applications, too, will grow gradually. As long as we keep performing&nbsp;<a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">red-teaming</a>&nbsp;exercises and monitoring our systems’ capabilities as they evolve, I’m confident that we will have plenty of time to spot issues in advance, and the science-fiction fears of AI-initiated doomsday will remain science fiction.</p><p>Keep learning!</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="Multimodal RAG: Chat with Videos." class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--9-.png" width="1200" /></figure><p>Learn to build AI systems that interact with video in “Multimodal RAG: Chat with Videos,” taught by Intel’s Vasudev Lal. Use multimodal embedding models to merge visual and text data, and build retrieval augmented generation (RAG) systems with LangChain and vector stores.&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LRv3qgyTW8wLKSR6lZ3p0W7Lj3yK48_yC3W7LGTc87J9nhvW32qjcK3TLXyhW2cJVlp1HDpy1N2b7Jf1KhzXcW24bxZH82YS40W95wvg97NMWJMW6JNtSr8WVk-_W1gjZH72BmS8yN8xkHcqf2G7MN7FSw2lW3HnvW2GvZbG4qCVPwW63vxmr3C9thKW3cm11V7Tkm7DW5y5j_G8kqpPLW861H3Z68k96pW7LjDYC5PBc6jMLmFYss6sV2W7ThjK19fdC1QW8KcQrD3wXkStW1mk2h46VTPsvW3_78DZ6qxszpW2lvP2b6603GnW1HN8Xw2Tz-WvW86cRGD5BSLJzW89RrfF4qdk92W88D2wR74dpt_V3JHL01BFCSWf5vhjld04?ref=dl-staging-website.ghost.io" rel="noopener">Start today</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="Chart comparing Waymo and human incidents across three safety categories." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.gif" width="1200" /></figure><h1 id="waymo-spotlights-safety-record">Waymo Spotlights Safety Record</h1><p>Waymo, the autonomous vehicle division of Alphabet, released an&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LQC3qgyTW6N1vHY6lZ3nrVSWsfy3sv4rxW5zbRVn3wmNH3W6KGys57ykM9zW1SWZqb8YBDSPW5LnGdf7922jhW5MW5pS8sL4B-W4RfBXZ69wrfzW2M8NRh1JYxtTW6QB9pb4NcS0BW4qC-b96RW6DwW2XMCWN8RxYKfW1FgfmC2_CDL1W6xNcsl30XKmPW5-sPm91GFRjJW84VCRR8zqpWnW5rnF0Y6_d69vW5_3zRj3D9ns8W8LfjxY3KzJzsW6jY5Cg7ZYt_9W2Qw48k902RmqW8pD1sS2_hdJKW77vc9v4nGPltf4Bp61b04?ref=dl-staging-website.ghost.io" rel="noopener">analysis</a>&nbsp;of its own safety data. It suggests that the company’s self-driving cars are safer than human drivers on the same roads.</p><p><strong>What’s new:</strong>&nbsp;Waymo’s analysis claims that its robotaxis, compared to human-driven vehicles, were involved in proportionally fewer accidents that involved police reports, passenger injuries, or airbag deployment. The company argues that these types of incidents are more relevant to assessing safety than minor collisions with no serious damage.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The study compares the number of incidents per mile experienced by Waymo vehicles and human drivers. It covers over 22 million miles driven along specific routes in Phoenix, Arizona, and San Francisco, California. The results&nbsp;were consistent in Phoenix and San Francisco.</p><ul><li>Waymo vehicles had 48 percent fewer incidents that were reported to the police than vehicles driven by humans.&nbsp;</li><li>Waymo vehicles had 73 percent fewer incidents that caused injuries than vehicles driven by humans.&nbsp;</li><li>Waymo vehicles deployed airbags 84 percent less frequently than vehicles driven by humans.&nbsp;</li></ul><p><strong>Behind the news:&nbsp;</strong>Waymo’s study arrives amid ongoing scrutiny of autonomous vehicle safety, particularly in San Francisco, where accidents and traffic disruptions caused by self-driving cars have raised&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LRv3qgyTW8wLKSR6lZ3n8W9gfSVj6GkqX0W6L8B8L2dsXlhF95CZm6yt6XW5QQTdf5qbFBrW15V_xq4YT-MvW6ffKZK59hc-hW3FtgF396hn8LW8P1xxM1FmhH-W3mxNQn4tQmPrW66s0pX7LMJXkW8Scm4l7D0xBxVMDQCj63MpT2W4y_1M455hCZwW7BkgRB25nW_SW9cFYYq6d-ll0VnVtbX28nZJJN75XMXFq81vqW83pSkN967YVPW3P_vLH46m9CWW1NrHby5Lxh2LW5c3QxW7h0HxlVb3-m14m_BVtW5QcZsS2b_JzCW3rhv9q2qLcqfW5GvJ0T3Xx3ClW2-F2bP7RhqjWW1k8XsN7qwj9MW1LQXpq5VDlZrf2yb5B204?ref=dl-staging-website.ghost.io" rel="noopener">public backlash and regulatory challenges</a>. Earlier this year, the state of California&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LPK5nR32W50kH_H6lZ3nfN4VTX_LnCyTTW23mY0x5qq67PW2FvqRr69Fz_YW7d6mwm5gQXrfVW-nbp8tqSZhW4vXhzz24nddHW38Nd581fsH2sV4Mq163-xwXSW8GtNYR15DLwcW7nK5g-36TB_rW7NgCB13n4zzqW7Vx3r1498D3CW4W4pCX8NgBrcW63mBlf57XRfnW6THG2k3wJK8BVNfmNN8NvjLSW8Q335s1PlT1FW7VxdDV6lKbzjW5jlsnk3z4plsW5NlTPw2QjNf9W7jC4J82BMJN1W2gYPWF5p63yfW6jcKmC1p9NsCW645Thk2_P3JpW2g0Wbg6JqfZDN9hTR2DYmHK-W83vXN47sy3r7W6yCY-K3MNyRzW4DH6SL6HcS2sVKcTRm1_3BW2W4PSz0c89X-qTW85Wytj5jZjfff37ywsx04?ref=dl-staging-website.ghost.io" rel="noopener">banned</a>&nbsp;Cruise, a Waymo competitor, after one of its self-driving cars drove over a pedestrian and dragged her about 20 feet before coming to a stop.&nbsp;</p><p><strong>Why it matters:&nbsp;</strong>Waymo’s analysis implies that autonomous vehicles could significantly reduce road accidents and injuries. The data could help urban planners to craft policies&nbsp;that would integrate autonomous vehicles into existing transportation systems.&nbsp;</p><p><strong>Yes, but:&nbsp;</strong>Waymo’s analysis is based on methods and benchmarks introduced in two&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LQC3qgyTW6N1vHY6lZ3n9W2qbKhD4Lst16W6fs8h55VzKv2W5t3N_H76QSKmW5hRB5x6wfdw2W95xLcH4_Yf6RVGYNrb7j0tgWW6V3Cst16PghpW86KBXx13kFd1W5q07hm5VnQD5W4FwQCp3VWnZ2VpDtF48BHn1tW7Nqw8716y7fWW2vthgr4sGG8DW1L5R_98W1gh0W1zqB_x2yrK8sN6hZ-XMQwmpfW2xzZ0H4qNSvjW7kdb9y5G_88XW479jrk4QsM-4MQWgtXYGwMYW8xfB3X2T3B6VW6tCdwF5WRH_nf62H4qd04?ref=dl-staging-website.ghost.io" rel="noopener">research</a>&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LQC3qgyTW6N1vHY6lZ3l6W1Z2gNM4wbYnkW7wZxcb6N1CzgW3nMFQN2HlqgVN4NkWn7zXHhSW7s6Llg4sn-dnW4Y_qPL1CffKGW2ffzKW4832YhN2MWn8y4HWwgN7TscTs9YrVpW14r0z397lP-rW3WhV3m1bBpBwW6XGdy_4PwxvFW1JqtMf3T2WZWW6TmrPs745vmqW2ySXvx4phtldW42jBKy2QFWh0W5LGvD45p70kDW88fjVm6F7GGyW3Z72bg2NGlDpW5MwD-27_ZgFkW1Q9Nhd28dV65W2mCF2c4gtjhpf4gfkf604?ref=dl-staging-website.ghost.io" rel="noopener">papers</a>&nbsp;that have not yet been peer reviewed. Validating them through peer review would help to establish the safety record of self-driving cars.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>This report makes a compelling case for autonomous vehicles. But the question remains whether these findings will be sufficient to increase public trust. We encourage other self-driving companies to release comprehensive safety data.</p><hr /><figure class="kg-card kg-image-card"><img alt="Collection of various toys, including a raccoon, a bus, and a tree." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.png" width="1200" /></figure><h1 id="record2d-to-3d-goes-mainstream">Record2D-to-3D Goes Mainstream</h1><p>Traditionally, building 3D meshes for gaming, animation, product design, architecture, and the like has been labor-intensive. Now the ability to generate 3D meshes from a single image is widely available.</p><p><strong>What’s new:&nbsp;</strong>Two companies launched systems that produce a 3D mesh from one image. Stability AI released&nbsp;<a href="https://arxiv.org/abs/2408.00653?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">SF3D</a>. Its&nbsp;<a href="https://huggingface.co/stabilityai/stable-fast-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">weights</a>&nbsp;and&nbsp;<a href="https://github.com/Stability-AI/stable-fast-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">code</a>&nbsp;are freely available to users with annual revenue under $1 million. Meanwhile, Shutterstock&nbsp;<a href="https://www.shutterstock.com/discover/generative-ai-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">launched</a>&nbsp;a service that provides a similar capability.&nbsp;&nbsp;</p><p><strong>How it works:</strong>&nbsp;Stability AI’s SF3D generates output in a half-second, while Shutterstock’s service takes around 10 seconds.</p><ul><li>SF3D has five components: (1) a transformer that produces an initial 3D representation of an input image; (2) a model based on&nbsp;<a href="https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">CLIP</a>&nbsp;that uses the image to estimate how metallic and rough the object’s surface texture is; (3) a convolutional neural network that, given the transformer’s output, estimates how light reflects off the surface; (4) a model based on&nbsp;<a href="https://arxiv.org/abs/2111.04276?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">Deep Marching Tetrahedra</a>&nbsp;(DMTet) that smooths the transformer’s output; and (5) an author-built algorithm that separates the 3D mesh from the surface texture map.</li><li>Shutterstock’s service, developed by TurboSquid (which Shutterstock acquired in 2021) and Nvidia, is due to launch this month. The company hasn’t disclosed pricing or how the system works. Users can specify an object and surroundings including light sources via an image or text description.</li></ul><p><strong>Behind the news:&nbsp;</strong>These releases arrived amid a flurry of recent works that aim to tackle similar problems. Most are based on&nbsp;<a href="https://arxiv.org/abs/2311.04400?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">Large Reconstruction Model</a>&nbsp;(LRM), proposed by Adobe in late 2023, which produces a 3D mesh and surface texture from a single image in less than 5 seconds. Follow-up&nbsp;<a href="https://arxiv.org/abs/2406.08479?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">work</a>&nbsp;trained LRM on real-world images in addition to the images of synthetic 3D meshes used in the original work and then reproduced LRM’s capabilities in an&nbsp;<a href="https://github.com/3DTopia/OpenLRM?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">open source model</a>. Further research extended the model to&nbsp;<a href="https://arxiv.org/abs/2403.12034?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">learn from generated videos</a>. Stability AI’s new system addresses issues in its own previous&nbsp;<a href="https://arxiv.org/abs/2403.02151?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">work</a>&nbsp;that was based on LRM.</p><p><strong>Why it matters:&nbsp;</strong>SF3D replaces&nbsp;<a href="https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">NeRF</a>, a 2D-to-3D approach proposed in 2020 that serves as the basis for LRM and several other methods, with DMTet, which incorporates surface properties to achieve smoother meshes and better account for light reflecting off object surfaces.</p><p><strong>We’re thinking:&nbsp;</strong>3D generation is advancing rapidly. To ignore this technology would be a mesh-take!</p><hr /><figure class="kg-card kg-image-card"><img alt="Council of Europe logo with a white spiral and 12 gold stars." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--8-.png" width="1200" /></figure><h1 id="western-powers-sign-ai-treaty">Western Powers Sign AI Treaty</h1><p>The European Union, United Kingdom, United States, and other countries&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LPK5nR32W50kH_H6lZ3pXVGxz_c8SGcRpW5NyZkQ3VCc1VVcPYX937FxvsW5QG4M07_kMmkW2xQqqy25Z5GrVkLRg51fvTFSN8XvGYkl2SFCW6rBV1f8-jx56W1dGGWK5KcbY0W14wxg615ngfVW4KYzlH4np_M3W79S_Zn6FXrPZW1FwXtK8Q5NhWM7xBB5KYgqfN2Rp-4cdZZgxV2fSPQ7grzP5W25NYmk6lr2llW57KH8R2PQ1j_W70Wb1c3r8b38W33Y2_x3n_Y0WW60Zmxz4ZqN1QW16HW265FK1gLW7hHmcR38kDSCM1MBnL-ZXj5N96HBg-Fn4MxW44Qgvs5L8nBbW6Y634d4rRVV4W17ZVMV8PdRM7W3kxrmv2dhjTCMWr-M-HHk45W5LDzlR5ggNljW2pVbjr8nnsx2f3Tkjbd04?ref=dl-staging-website.ghost.io" rel="noopener">signed</a>&nbsp;a legally binding treaty that regulates artificial intelligence.&nbsp;</p><p><strong>What’s new:&nbsp;</strong>The treaty, officially known as the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LQC3qgyTW6N1vHY6lZ3p0W2FT1_G99-kj0W1R73bQ2mmmcsW2TN2sT2XhP5ZW1D0YlV2xbH9pW7kjmFY9cF4FqW5_TXDt1HBd6SW6t8VB729ypR6W6G3KZz6BD_6pW4w3-mV4f_63qW4gjP2R5vByMQN1Y_FffMB4HyW8CgNT179ccH5W7jJpdf4Jx8VtW2dVZcw2x6Vl9VtmznY77YxTjVH5jxh5PnXW4N1C5JvJdMjpWMK0N5ytpv8gW6cdpnK4ts1Q_W2jxwz37qwWbBW1csW916sFLQYN4L8_9_8S0f8f3TCfZP04?ref=dl-staging-website.ghost.io" rel="noopener">Framework Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law</a>, provides a legal framework for states to preserve democratic values while promoting AI innovation. It was negotiated by member nations of the Council of Europe (a transnational organization that promotes democracy and human rights and includes nearly twice as many countries as the EU) as well as observer states including Australia, Canada, and Mexico, which have not yet signed it. Countries that did not participate include China, India, Japan, and Russia.</p><p><strong>How it works:</strong>&nbsp;The treaty will take effect later this year. It applies to any use of AI by signatories, private actors working on behalf of signatories, or actors in those jurisdictions. AI is broadly defined as any “machine-based system . . . [that generates] predictions, content, recommendations, or decisions that may influence physical or virtual environments.” The signatories agreed to do the following:&nbsp;</p><ul><li>Ensure that all AI systems are consistent with human-rights obligations and democratic processes, including individual rights to participate in fair debate</li><li>Prohibit any use of AI that would discriminate against individuals on the basis of gender or other characteristics protected by international or domestic law</li><li>Protect individual privacy rights and personal data against uses by AI</li><li>Assess AI systems for risk and impact before making them widely available&nbsp;</li><li>Promote digital literacy and skills to ensure public understanding of AI&nbsp;</li><li>Notify individuals when they are interacting with an AI system</li><li>Shut down or otherwise mitigate AI systems when they risk violating human rights</li><li>Establish oversight mechanisms to ensure compliance with the treaty and provide remedies for violations</li></ul><p><strong>Exceptions:&nbsp;</strong>The treaty allows exceptions for national security and doesn’t cover military applications and national defense. It also doesn’t apply to research and development of AI systems that are not yet available for general use, unless testing such systems can interfere with human rights, democracy, or the rule of law.&nbsp;</p><p><strong>Behind the news:&nbsp;</strong>The Council of Europe oversees the European Convention on Human Rights and its Court of Human Rights in Strasbourg, France. Its AI treaty builds on previous initiatives including the European Union's&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LRv3qgyTW8wLKSR6lZ3pxW6Py5012vkMtWW2_yx536lMjKFW1kSkh21XTbCyW8dwh9Z7vccqdW251wMR8lY6L4V-XJwg2XdGrSW3dPNZc6WTJ8xW4kqBbT5GTcC8V1Q4xm3-qM7mW7DsB8521nYF3W5CRRsD3zk8xCW1875bX4sZHPKW8K7Jx36kfMDvVNJ73d3MLfXWW8gMq6W4SpD7SW4PLdr41QDt60W7hkR9N4lV4kQW74_VcG3kzBqBW2v4bmg2B6phbW1qsBXs8G66tLW4r2CdT8r5YvkW2dWnVY3KqK4hW91-DTR2PyHnSW9b66m95QB-W4W2hfzr73NH-XdN6KYQCLkjSYCW7tmQdQ1Ty9HcW63CzzL4446Kcf2q-rrP04?ref=dl-staging-website.ghost.io" rel="noopener">AI Act</a>, which aims to regulate AI based on risk categories, and other national and international efforts like the United States’&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LQW3qgyTW7lCdLW6lZ3nyW98gs844DFs_LW560L5m3Z-wlqW7v1vGH1tb6K1VxjkMF3BFGL5VX85Px7BM4HMW7DcHCK2_gMwYW5pMk-X3xqP2NW6MmBJV65j1RgVDjnPG2vp363W3wzG2g2T2BY_W5zHd3k7cbF50W5B2RTl2-4nLyN21pbVJk7BdqW1WSPTj20HM8PW33pKbj2bGz5tW6KC-4h8sw15LW81sCsH7nZZhyW2Jb6491kQFKLW1Sc3_S2NYPbXW94RXq83M7d_dW8nFRpc3sybMtW6276nR61J-DhW3dYdsD5dLN3yW1nK_wc2yG97mdvl7C-04?ref=dl-staging-website.ghost.io" rel="noopener">AI Bill of Rights</a>&nbsp;and the global&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVDVjs2CnKZfW8FS-wl23ssTsW70RWGB5kSsRwN5n2LPK5nR32W50kH_H6lZ3kxW1nbxd82btnb-W8M5dZf4v3t0tW6lK7j15Dxg2tW19jn-M1qpkKXVM7z5f2LL7p-W3MZWKW5tcXt0W7_J2JK52G2yZW2s2CjZ93VX23W5dWMtZ30vpqbW1VYV7h5RH4YTVkQhZV1jvXHhW8qQH2p5RLBlQW4SWxhD4RNXC8W2mFtzz5zjZyVW7cQZzM7rmNwlW5SLHyY5g8c_vW5vpTH26MZ7hVW3MHjd680Yfs9W4fflx_3mtPggVBcVlW2_LlY3Vf6mgf6XN_gyW5xDj826JPTT-N90kjfNY5y1-VF60qP277vWbW7VYxsm3msQMYW3BGlXC6gNr5TW3CcwhC2hKJBrW1ByGXr974QF-W8qcrzF28BGQJW53bm4c3QFdBmW3spzLL47Z_pkW4d4M8f7t-Zcrf6YCLnR04?ref=dl-staging-website.ghost.io" rel="noopener">AI Safety Summit</a>.</p><p><strong>Why it matters:&nbsp;</strong>As the first binding international agreement on AI, the treaty can be enforced by signatories’ own laws and regulations or by the European Court of Human Rights. Since so many AI companies are based in the U.S. and Europe, the treaty may influence corporate practices worldwide. Its provisions could shape the design of deployed AI systems.</p><p><strong>Yes, but:</strong>&nbsp;Like any regulation, the treaty’s effectiveness depends on the interpretation of its high-level concepts. Its core terms (such as accountability measures, democratic processes, oversight, privacy rights, and transparency) represent a broad framework, but their precise meaning&nbsp; is vague and interpretation is left to the signatories. Also, the nonparticipation of major AI powers like China and large countries like Russia and India raises questions about whether its standards can be applied globally.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>The EU and U.S. have very different approaches to AI regulation; the EU has taken a much heavier hand. Yet both agreed to the treaty. This could indicate that these regions are finding common ground, which could lead to more uniform regulations internationally.</p><hr /><figure class="kg-card kg-image-card"><img alt="Hierarchical K-means diagram with data clustering across multiple layers." class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.gif" width="600" /></figure><h1 id="balancing-web-data-distributions">Balancing Web Data Distributions</h1><p>Datasets that were scraped from the web tend to be unbalanced, meaning examples of some classes (say, cats) are plentiful while examples of others (say, caterpillars) are scarce. A model that’s trained on an unbalanced dataset will perform unevenly across classes, but the labor required to balance the data manually can be prohibitive. An automated method addresses such imbalances.</p><p><strong>What’s new:&nbsp;</strong>Huy V. Vo and colleagues at Meta, France’s National Institute for Research in Digital Science and Technology, Université Paris Saclay, and Google proposed a&nbsp;<a href="https://arxiv.org/abs/2405.15613?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">method</a>&nbsp;that automatically selects a balanced subset of text or image datasets.</p><p><strong>Key insight:</strong>&nbsp;A naive way to balance a dataset automatically is to cluster it using&nbsp;<a href="https://stanford.edu/~cpiech/cs221/handouts/kmeans.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">k-means</a>&nbsp;to define implicit categories and then draw an equal number of points randomly from the resulting clusters. But this approach tends to form many clusters in areas of the distribution that have more examples, leading to over-representation of certain categories. For instance, when the authors applied k-means to web images and associated the clusters with their nearest neighbors in ImageNet, around 300 clusters (out of 10,000) corresponded to the ImageNet class “website.” However, after clustering, the distribution of the centroids is a bit more uniform than that of the entire dataset. Applying k-means repeatedly distributes the centroids (and thus the clusters) more uniformly. After a number of iterations, each cluster is more likely to represent a distinct category, and selecting equal numbers of examples from each cluster makes a balanced dataset.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors balanced image and text datasets using several iterations of k-means clustering. Their image dataset started with 743 million examples from a “publicly available repository of crawled web data.” For text, they started with&nbsp;<a href="https://aclanthology.org/2020.lrec-1.494/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">CCNet</a>, a version of&nbsp;<a href="https://commoncrawl.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">Common Crawl</a>&nbsp;that was filtered to match the distribution of language and topics found in Wikipedia. The following approach ensured balanced sampling from all levels, maintaining a balance among high-level classes (such as animal, vehicle, and sport) and lower-level subclasses (such as dog, airplane, and football):</p><ul><li>The authors embedded the data. They built an image-embedding model by training a&nbsp;<a href="https://arxiv.org/abs/2010.11929?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">ViT-L</a>&nbsp;(307 million parameters) on&nbsp;<a href="https://image-net.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">ImageNet1k</a>&nbsp;according to the&nbsp;<a href="https://arxiv.org/abs/2304.07193?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">DINOv2</a>&nbsp;self-supervised training method. To embed text, they used a pretrained&nbsp;<a href="https://aclanthology.org/D19-1410.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">SBERT</a>.</li><li>They clustered the data via k-means to produce 10 million clusters.</li><li>They selected a small number of points closest to the centroid of each cluster. Then they applied k-means to the selected points to find new centroids. They repeated this process four times, each time decreasing the number of clusters, so the new clusters represented higher-level categories. With each iteration, the distribution of centroids became more uniform.</li><li>Using the resulting hierarchy of clusters, the authors randomly selected balanced datasets of 100 million images and 210 billion text tokens. Specifically, starting with the highest-level clusters, they computed the number of samples to be drawn from each cluster. Then they looked up which clusters in the previous level were contained within each of the clusters in the current level and determined the number of samples to be drawn from each of these subclusters. They repeated this process at each level. In this way, when they reached the lowest level, they knew how many points to draw randomly from each of the lowest-level clusters. The points they drew made up a balanced dataset.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;Both vision and language models that were pretrained on the balanced data outperformed models that were pretrained on the corresponding unbalanced datasets.&nbsp;</p><ul><li>To test their balancing method on image classifiers, the authors pretrained&nbsp;<a href="https://arxiv.org/abs/2010.11929?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">ViT-g</a>&nbsp;models on their balanced dataset and the unbalanced raw data. They froze the trained models and fine-tuned a linear layer on top of them to classify ImageNet. Pretrained on their balanced dataset, ViT-g achieved 85.7 percent accuracy on the ImageNet 1k validation set. Pretrained on the unbalanced dataset, it achieved 85.0 percent accuracy.</li><li>To test their method on language models, they compared performance on various tasks of&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">LLaMA-7B</a>&nbsp;models that were pretrained on their balanced version of 210 billion tokens in CCNet and the unbalanced CCNet. For instance, on the&nbsp;<a href="https://arxiv.org/abs/1905.07830?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">HellaSwag</a>&nbsp;question-answering dataset (zero-shot), the model pretrained on balanced data achieved 52.7 percent accuracy, while the model pretrained on unbalanced data achieved 51.9 percent accuracy. Similarly, on&nbsp;<a href="https://arxiv.org/abs/1803.05457?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--5PGGtWHSdR9WiP2NQdl-zE4xfe2Lyhu3oR-OBcHjmKt_5hJ6MuBDWGPd4Ek2zfxruKHcp" rel="noopener">Arc-C</a>&nbsp;(questions about common-sense physics such as the buoyancy of wood, zero-shot), the model pretrained on balanced data achieved 40.1 percent accuracy, while the model pretrained on unbalanced data achieved 35.5 percent accuracy.</li></ul><p><strong>Why it matters:&nbsp;</strong>The old-school machine learning algorithm k-means can organize quantities of pretraining data that are too large for manual inspection yet crucial to data-hungry models. Breaking down data into clusters also makes it possible to manually inspect cluster elements, which might help identify unwanted data.</p><p><strong>We’re thinking:&nbsp;</strong>Even in the era of foundation models, data-centric AI — that is, systematically engineering the data used to train such models — remains a critical, often under-appreciated step. This paper offers a promising way to create more balanced datasets. The encouraging results suggest fruitful avenues for further study.</p>
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 22:11:00 GMT</pubDate>
</item>
<item>
<title>Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, Faster Processing for Longer Inputs</title>
<link>https://www.deeplearning.ai/the-batch/issue-265</link>
<guid>https://www.deeplearning.ai/the-batch/issue-265</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub. When he asked me if I would advise South Korea as a member of the Global AI Strategy Steering Group of the country’s National AI Committee, I agreed on the spot. I was delighted to learn this week that Yann LeCun has also joined.&nbsp;I’ve been consistently impressed by the thoughtful approach the Korean government has taken toward AI, with an emphasis on investment and innovation and a realistic understanding of risks without being distracted by science-fiction scenarios of harm.</p><p>I’ve advised many countries to build AI for the sectors where they’re strong. For example, I felt that by investing in sectors like tourism and certain industries,&nbsp;<a href="https://www.deeplearning.ai/the-batch/thailands-ai-push/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Thailand</a>&nbsp;can do projects more efficiently than I can in Silicon Valley. South Korea’s tech ecosystem gives it a foundation to move even faster across multiple sectors. This emphasizes the long-term value for countries to become good at tech, because tech is now pervasive and affects all industries.</p><p>Korea has a very strong local software ecosystem. For example, the dominant search engine is not Google or Bing, but Naver (a Korean company). The dominant messaging system is not WhatsApp or WeChat, but KakaoTalk. With local tech giants Naver and Kakao offering email, mobile payment, cloud computing, ride sharing, and other services, the country has many sophisticated tech businesses. Additionally, SK hynix and Samsung are advanced semiconductor manufacturers. It also has a thriving entrepreneurship ecosystem, including Upstage, a language modeling startup, which taught a course with us on “<a href="https://www.deeplearning.ai/short-courses/pretraining-llms/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Pretraining LLMs</a>.” Finally, the Korean institutions Seoul National University, which I visited last year, and KAIST have global reputations.</p><figure class="kg-card kg-image-card"><img alt="NG YEOL" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5--1.png" width="1200" /></figure><p>Korea has a highly educated population, highly skilled software engineers, and a thriving set of software products. This gives it a fantastic foundation to embrace the next generation of AI. After meeting with businesses in retail, construction, insurance, cosmetics, telecoms, and other industries, I was delighted by the wide variety of opportunities many companies are pursuing across different industry sectors.</p><p>Lastly, Korea is known globally for its K-pop. Meeting&nbsp;<a href="https://n.news.naver.com/article/011/0004386078?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Bang Si-Hyuk</a>, the chairman of HYBE, which manages the superstar singing group BTS, and learning how the company operates was a real treat! (Another treat was eating at a Korean eel house, where the seafood was unforgettable.)</p><p>That’s why I’ve traveled to South Korea four times since last year. My venture studio AI Fund, which collaborates with many Korean companies, has benefited tremendously from the advice of many South Koreans, including Taizo Son, Changmook Kang, Hyungjun Kim, Sung Kim, JP Lee, Ian Park, and Alice Oh. I look forward to doing more in, and with, South Korea!</p><p>화이팅 (Let’s go)!</p><p>Andrew</p><p>P.S. We just released the final two courses of&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener"><em>AI Python for Beginners</em></a>! The complete set of four courses is now available and remains free for a limited time. If you know someone who is considering learning to code, please recommend these courses! They teach how to (a) write code using AI-assistance, which is where the field is going, and (b) take advantage of generative AI, which allows you to do valuable things quickly.&nbsp;Since releasing the first two courses, I’ve been inspired by many learner stories like&nbsp;<a href="https://www.linkedin.com/pulse/my-first-python-programs-ai-beginners-course-julia-kryuchkova-2ft9e/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">this one</a>. Julia K. started with&nbsp;<em>AI Python for Beginners</em>&nbsp;and shortly afterward wrote useful program after useful program. (She accomplished this before we had even finished releasing all four courses!)&nbsp;I hope many others will have similar stories to tell.</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74"><img alt="AI Python for Beginners." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.png" width="1200" /></a></figure><p>The final courses of Andrew Ng’s&nbsp;<em>AI Python for Beginners</em>&nbsp;are live! Work on hands-on projects to analyze data, automate tasks, create reusable functions, and extend Python with third-party tools.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Join for free today!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="Throughput and latency at different context lengths" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed.gif" width="600" /></figure><h1 id="long-context-gets-up-to-speed">Long Context Gets Up to Speed</h1><p>A new model generates tokens faster than current transformers, especially when processing long inputs.<br /><strong>What's new:&nbsp;</strong>AI21 Labs released&nbsp;<a href="https://arxiv.org/pdf/2408.12570?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Jamba 1.5</a>, an update of its earlier&nbsp;<a href="https://arxiv.org/pdf/2403.19887?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Jamba</a>. It comes in&nbsp;<a href="https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mini</a>&nbsp;and&nbsp;<a href="https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Large</a>&nbsp;versions and boasts a relatively large (and validated) input context length of 256,000 tokens. The models are&nbsp;<a href="https://www.ai21.com/licenses/jamba-open-model-license?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">free</a>&nbsp;to users who have annual recurring revenue under $50 million and available on several cloud platforms including Google Cloud Vertex AI, Hugging Face, and Microsoft Azure.<br /><strong>How it works:</strong>&nbsp;Jamba 1.5 is a hybrid architecture made up of transformer,&nbsp;<a href="https://www.deeplearning.ai/the-batch/mamba-a-new-approach-that-may-outperform-transformers/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">mamba</a>, and&nbsp;<a href="https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">mixture of experts</a>&nbsp;(MoE) layers. Unlike transformer layers, in which processing power scales quadratically as input length increases, the mamba layers enable the required processing power to scale linearly as input length increases without requiring workarounds like sparse attention and sliding windows. The MoE layers are composed of many fully connected sublayers, of which only a small number are used to process a given input. Jamba 1.5 Mini has roughly 50 billion parameters but uses only 12 billion at a time, while Jamba 1.5 Large has around 400 billion parameters but uses only 94 billion at a time.&nbsp;</p><ul><li>The authors pretrained Jamba 1.5 on a proprietary dataset of web documents, code, books, and scientific articles. They further pretrained it on a higher proportion of longer documents to increase its ability to process long-text inputs.<br /></li><li>They fine-tuned Jamba 1.5 on generated data to handle specific types of input such as instructions, conversations, longer documents, question-answer pairs, and calls to external tools.&nbsp;<br /></li><li>Unlike transformer-based models, Jamba 1.5 showed no benefit from positional embeddings of input tokens, so it doesn’t use them.</li></ul><p><strong>Results:</strong>&nbsp;Both versions of Jamba 1.5 produced output tokens faster than other models (running on identical hardware), especially given longer inputs. However, the larger version achieved lower performance on popular benchmarks than other open models.</p><ul><li>With 262,144 tokens as input, Jamba 1.5 Mini generated about 62 tokens per second, LLaMA 3.1 8B generated about 41, and Mixtral generated about 39. The difference became narrower as input length decreased.&nbsp;With 4,096 tokens as input, Jamba 1.5 Mini generated around 78 tokens per second, LLaMA 3.1 8B generated about 79, and Mixtral 8x7B generated about 60.&nbsp;<br /></li><li>Both models performed extraordinarily well on&nbsp;<a href="https://arxiv.org/abs/2404.06654?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">RULER</a>, a suite of 13 tasks that assess the ability of large language models to take advantage of input context at various lengths. Jamba 1.5 Mini and Large utilized their full context length, while many competing models utilized half or less.&nbsp;<br /></li><li>Across 11 popular benchmarks, Jamba 1.5 Mini performed similarly to LLaMA 3.1 8B and Gemma 2 9B. However, Jamba 1.5 Large achieved lower performance than LLaMA 3.1 70B and Mistral Large 2 123B on nearly every benchmark.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;The mamba architecture, which is designed to enable processing to scale linearly with longer input lengths, has been a subject of much research since its release in late 2023. Notably,&nbsp;<a href="https://arxiv.org/abs/2405.21060?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba-2</a>,&nbsp;<a href="https://arxiv.org/abs/2406.07887?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba-2-Hybrid</a>, and&nbsp;<a href="https://arxiv.org/abs/2405.16712/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Zamba</a>&nbsp;combined mamba layers with attention layers with varying degrees of success.<br /><strong>Why it matters:&nbsp;</strong>The original&nbsp;<a href="https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba</a>&nbsp;model was much faster and equally accurate compared to transformers up to 2.8 billion parameters. But how the mamba architecture compared to transformers at larger scales was an open question. Jamba 1.5 shows that the combination of mamba and transformer layers can yield higher speed in larger models — although the results don’t yet exceed those of comparably sized transformers.<br /><strong>We're thinking:</strong>&nbsp;While hardware companies like Groq and SambaNova are accelerating LLMs, software innovations like Jamba may enable further speed-ups.</p><hr /><figure class="kg-card kg-image-card"><img alt="Short, Medium and Long Context RAG" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--3-.gif" width="1200" /></figure><h1 id="models-ranked-for-hallucinations">Models Ranked for Hallucinations</h1><p>How often do large language models make up information when they generate text based on a retrieved document? A study evaluated the tendency of popular models to hallucinate while performing retrieval-augmented generation (RAG).&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Galileo, which offers a platform for evaluating AI models,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3kHVjRKLW8dZ8LNW89jxTJ6rN9_7W1bZ0x-1gbTZqVzr5v05RJb05W5G1zs95HSw3-W6B7cf12VlGRPN8jblyw5SFNyN8DhQdtPDjr7N96YXktJh2Z5VN4zt55xx36YW2q1S8m8M66-SW5_KFG05lhlx8W7LHpc43DR4jJW5w13F51VbMbbN4Qxr7Lp4mgjW8-tbCw5_bV3DW2_Nhc315DykjN1jf7VvyFq9_W3QN7hY7fc_tFW8FNhZR3CvMLYW5kjCl65GXxKRVCPJvB2mK3cRVFCLNW1PC5qlW18MPRm6bqhz5f2GlGNg04?ref=dl-staging-website.ghost.io" rel="noopener">tested</a>&nbsp;22 models to see whether they hallucinated after retrieving information from documents of various lengths. Claude 3.5 Sonnet was the overall winner, and most models performed best when retrieving information from medium-length documents.</p><p><strong>How it works:</strong>&nbsp;The researchers tested 10 closed and 12 open models based on their sizes and popularity. They ran each model 20 times using short, medium, and long context lengths (a total of 60 tests) using GPT-4o to evaluate how closely the output text adhered to the context.&nbsp;</p><ul><li>The researchers selected text from four public and two proprietary datasets for short-context tests (less than 5,000 tokens each). They chose longer documents from private companies for medium- and long-context tests. They split these documents into passages of 5,000, 10,000, 15,000, 20,000, and 25,000 tokens for medium-context tests, and 40,000, 60,000, 80,000, and 100,000 tokens for long-context tests.</li><li>For each test, they fed a prompt and a related document to a model. The prompt asked the model to retrieve particular information from the document.</li><li>They fed the prompt and response to Galileo’s&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_YT3qgyTW95jsWP6lZ3l-W2dkmwn8mX4S0Vs6zhD2gWDXxW3jPLSj2YT3NyN7Wxrn0dwlX4W2H72gs3Dl3bXW8_hGWW1cwdWMN29S9XN_p351W37KH-Q3ccvmQN2t3sfvm8VcCW8hkBsk5fh3HhW3MnLxJ7494lYW7QtLml2tcggcW3cwbG21RZlqpN923rhJHG26SW1w0s9w3hRD67W6VzWQc5Q3h-VW13x6W-83BPPFN2mX6G1HCDy_W4l7y8q7qbDZ-W6k1SFb1D5SLkW5MJysF7x_zz-Vh7JcJ8S3nQJW8FL0bP960LfgW6ytSR11l-PwHW7CR8vn3wJdtbW5PrVDw94FCnBW2WD61z44krp1W7r-ZbQ9byw7wW2K9pCK2hf3SzW1FtWkk1MPycff6WryFs04?ref=dl-staging-website.ghost.io" rel="noopener">ChainPoll</a>&nbsp;hallucination detection tool. ChainPoll queries a model (in this case, GPT-4o) multiple times using&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_XH3qgyTW6N1vHY6lZ3nyW2tVsG-7PzMF-W6SjJ9y1LNqtdW4fpz__37BS1JW3VqkmN50QXSPW8fqww07sc6jfW9gjGyq4WdZqTW1cvwlP2FdLqKW425lf_3sh_H7W64kZXQ5R33-pW4d__9h4_NlwZW7Rnpr03m64q5W3qQ8nJ42Hd7SW542FpH3dG2XHN8jyCPhxQyY5W321bld5yq9x3W1GHBqT8sqT2PVVFQRD7scLD0MRWDgHttm4zW1kdvqX9dVr9mVrdG-Z64-4_-W5TfyFW1V9qSLW7Y3lJx7gs9vSf1rXWJb04?ref=dl-staging-website.ghost.io" rel="noopener">chain-of-thought prompting</a>&nbsp;to return a score of either 1 (the response is directly supported by the context document) or 0 (the response is not supported by the context document). They tallied each model’s average scores for each context length and averaged those to produce a final score.</li></ul><p><strong>Results:</strong>&nbsp;Anthropic’s Claude 3.5 Sonnet ranked highest overall, achieving 0.97 in short context lengths and 1.0 in medium and long context lengths.</p><ul><li>Among models with open weights, Qwen2-72b Instruct scored highest for short (0.95) and medium (1.0) context lengths. The researchers singled out Gemini 1.5 Flash for high performance (0.94, 1.0, and 0.92 for short, medium, and long context lengths respectively) at low cost.</li><li>Most models performed best in medium context lengths, which the report calls the “sweet spot for most LLMs.”</li></ul><p><strong>Behind the news:</strong>&nbsp;Galileo performed similar&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3pMW2hxz0T1G81JQVdHHnW9gH8ZkW3BfhnQ4z3DkPW65363_8h1MmlVcjSqt8w4F2qW6CJ9Xs2fVZYrV2Jclk6L_DwyW8gdXgL46mdyzW58sMYC45mC2fW5yjTf_6zSBVYW7sSsgL8pbnrfW3-q6G21VhvQtW34Kqbf2BS92PW7r6tgQ9hZDdNW3KQVFH3mXD76W1cbN6h7NLb_YW4HL1L572053RW58FLd37Qqr2MVSKLKJ2vTrhPW2cXXC_7G-GtBW1DYlGB7Rs0lSW6JcKlF928B6bW4F7hW14jjfC3V3CJMg49KJLZf7L8dcT04?ref=dl-staging-website.ghost.io" rel="noopener">tests</a>&nbsp;last year, when it compared performance in both RAG and non-RAG settings (without differentiating among context lengths). GPT-4 and GPT-3.5 held the top three spots in both settings despite strong showings by Llama 2 and Zephyr 7B. However, the top scores were lower (between 0.70 and 0.77).</p><p><strong>Why it matters:</strong>&nbsp;Model builders have reduced hallucinations, but the difference between rare falsehoods and none at all may be critical in some applications.</p><p><strong>We’re thinking:</strong>&nbsp;It’s curious that medium-length RAG contexts generally yielded fewer hallucinations than short or long. Maybe we should give models more context than we think they need.</p><hr /><figure class="kg-card kg-image-card"><img alt="Argentina-NeuralNetwork" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.jpg" width="1200" /></figure><h1 id="ai-powered-policing-goes-national">AI-Powered Policing Goes National</h1><p>Argentina created a national law-enforcement department that will use AI to detect crimes as they’re committed, investigate them afterward, and predict them before they occur.</p><p><strong>What’s new:</strong>&nbsp;President Javier Milei of Argentina established the&nbsp;Artificial Intelligence Unit Applied to Security (UIAAS),&nbsp;<em>The Register</em>&nbsp;<a href="https://www.theregister.com/2024/08/01/argentina_crime_prediction/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">reported</a>. The unit aims to detect, investigate, and predict criminal activity by using machine learning algorithms to monitor the internet, wireless communications, security cameras, drone surveillance, financial transactions, and other data in real time.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Milei&nbsp;established the UIAAS in a late-July&nbsp;<a href="https://www.boletinoficial.gob.ar/detalleAviso/primera/311381/20240729?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">resolution</a>. Milei created it under the Ministry of Security shortly after he&nbsp;<a href="https://buenosairesherald.com/politics/presidency-transforms-spy-agency-afi-into-secretariat-to-grant-it-more-power?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">reorganized</a>&nbsp;the national intelligence agency to give himself more direct control. In December, his security minister&nbsp;<a href="https://www.theguardian.com/world/2023/dec/17/argentina-president-javier-milei-security-guidelines-protests-currency-devaluation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">quashed</a>&nbsp;public protests against his austerity policies; he promised to identify protesters via “video, digital, or manual means” and bill them for the cost of policing the demonstrations.</p><ul><li>The UIAAS is empowered to “use machine learning algorithms to analyze historical crime data to predict future crimes and help prevent them.” This approach “will significantly improve the efficiency of the different areas of the ministry and of the federal police and security forces, allowing for faster and more precise responses to threats and emergencies,” the resolution states.&nbsp;</li><li>The resolution notes that Argentina is not alone among nations in using AI for law enforcement. It cites China, France, India, Israel, Singapore, the United Kingdom, and the United States as “pioneers in the use of Artificial Intelligence in their areas of government and Security Forces.”</li><li>The new unit is part of a broader cost-cutting effort that aims to replace government workers and organizations with AI systems,&nbsp;<a href="https://english.elpais.com/international/2024-07-30/javier-mileis-government-will-monitor-social-media-with-ai-to-predict-future-crimes.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">according to</a>&nbsp;<em>El Pais</em>, a news outlet based in Madrid.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Argentina’s government is a presidential representative democratic republic. The country was ruled by a military dictatorship between 1976 and 1983.&nbsp;</p><ul><li>A&nbsp;<a href="https://pulitzercenter.org/stories/twisted-eye-sky-over-buenos-aires?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">report</a>&nbsp;by the Pulitzer Center, which sponsors independent reporting on global issues, found that, between 2019 and 2020, a face recognition network in the Argentine capital city of Buenos Aires overreached its mission to track only fugitives and led to at least 140 errors that culminated in mistaken arrests or police checks. In 2022, a judge ruled the system unconstitutional and shut it down. City officials are trying to overturn the decision.</li><li>However, Buenos Aires has used AI successfully in its criminal justice system. A rule-based system designed to prepare court opinions&nbsp;<a href="https://publications.iadb.org/es/prometea-transformando-la-administracion-de-justicia-con-herramientas-de-inteligencia-artificial?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">shortened</a>&nbsp;the process of presenting evidence for consideration in a trial from 90 minutes to 1 minute and the time to process injunctions from 190 days to 42 days, according to the Inter-American Development Bank.</li></ul><p><strong>Why it matters:</strong>&nbsp;AI has valuable uses in law enforcement and security. At the same time, it needs to be applied responsibly and implemented in a way that’s fair and respectful of legal rights such as presumption of innocence.</p><p><strong>We’re thinking:</strong>&nbsp;Surveillance is easy to abuse, and the notion of predictive policing warrants extreme caution to avoid bias against certain groups, violating civil rights, and other pitfalls. Ensuring that it’s used well requires robust technology, rigid controls, clear oversight, and public transparency. We hope that Argentina — no less than the countries that inspired it establish a national AI police agency — will put strong safeguards in place.</p><hr /><figure class="kg-card kg-image-card"><img alt="Gemma Scope 2" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--4-.gif" width="600" /></figure><h1 id="making-llms-explainable">Making LLMs Explainable</h1><p>Researchers have probed the inner workings of individual layers of large language models. A new tool applies this approach to all layers.</p><p><strong>What’s new:</strong>&nbsp;Tom Lieberum and colleagues at Google released&nbsp;<a href="https://storage.googleapis.com/gemma-scope/gemma-scope-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Gemma Scope</a>, a system designed to illuminate how each layer in Gemma 2-family large language models responds to a given input token. Gemma Scope is available for the 9 billion-parameter and newly released 2 billion-parameter versions of Gemma 2. You can play with an&nbsp;<a href="https://www.neuronpedia.org/gemma-scope?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#microscope" rel="noopener">interactive demo</a>&nbsp;or download the&nbsp;<a href="https://huggingface.co/google/gemma-scope?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">weights</a>.</p><p><strong>Key insight:</strong>&nbsp;A sparse autoencoder (SAE) is a sparse neural network that learns to reconstruct its input. The authors drew on earlier research into using SAEs to interpret neural networks.&nbsp;</p><ul><li>To see what a neural network layer knows about a given input token, you can feed it the token and study the embedding it generates. The difficulty with this approach is that the value at each index of the embedding may represent a tangle of concepts that are associated with many other values — too many other values to track.&nbsp;</li><li>Instead, an SAE can transform the embedding into one in which each index corresponds to a distinct concept. The SAE can learn to represent the embedding by the weighted sum of a much larger number of vectors than the number of values in the embedding. However, each weighted sum has only a small number of non-zero weights — in other words, each embedding is expressed as only a small-number, or sparse, subset of the SAE vectors. Since the number of learned SAE vectors is far greater than the number of values in the original embedding, any given vector is more likely to represent a distinct concept than any value in the original embedding.&nbsp;</li><li>The weights of this sum are interpretable: Each weight represents how strongly the corresponding concept is represented in the input. Given a token, the SAE’s first layer produces these weights.</li></ul><p><strong>How it works:</strong>&nbsp;The authors built over 400 SAEs, one for each layer of Gemma 2 2B and Gemma 2 9B. They fed Gemma 2 examples from its pretraining set and extracted the resulting embeddings at each layer. Given the resulting embeddings from a specific layer, an SAE learned to reconstruct each of them. An additional loss term minimized the number of non-zero outputs from the SAE’s first layer to help ensure that the SAE used only concepts related to the embedding. To interpret an embedding produced by the first layer of the SAE, the team labeled the embedding’s indices with their corresponding concepts. They used two main methods: manual and automatic.&nbsp;</p><ul><li>Manual labeling: (1)&nbsp;<a href="https://github.com/google-deepmind/mishax?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Insert the SAE</a>&nbsp;in the appropriate location in Gemma 2. (2) Prompt Gemma 2. (3) Select an index in the embedding from the SAE’s first layer. (4) Note which token(s) cause the value at that index to be high. (5) Label the index manually based on commonalities between the noted tokens.</li><li>Automatic labeling: This was similar to manual labeling, but GPT4o-mini labeled the indices based on commonalities between the noted tokens.&nbsp;</li><li>In addition to testing how Gemma 2 responds to particular input tokens, Gemma Scope can be used to steer the model; that is, to see how the model responds when it’s forced to generate text related (or unrelated) to a particular concept: (1) Search the index labels to determine which index corresponds to the concept in question. (2) Insert the corresponding SAE into Gemma 2 at the appropriate layer. (3) Prompt the modified Gemma 2 to generate text, adjusting the output of the SAE’s first layer at the index. Gemma 2’s text should reflect the changed value.</li></ul><p><strong>Behind the news:</strong>&nbsp;Earlier research into using SAEs to interpret neural networks was limited to&nbsp;<a href="https://arxiv.org/abs/2405.14860?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">interpreting a single layer</a>&nbsp;or a&nbsp;<a href="https://arxiv.org/abs/2309.08600?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">small network</a>. Earlier this year, Anthropic used an SAE to&nbsp;<a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#scaling-to-sonnet" rel="noopener">interpret Claude 3 Sonnet’s middle layer</a>, building on an earlier report in which they interpreted a&nbsp;<a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">single-layer transformer</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Many questions about how LLMs work have yet to be answered: How does fine-tuning change the way a model represents an input? What happens inside a model during chain-of-thought prompting versus unstructured prompting? Training an SAE for each layer is a step toward developing ways to answer these questions.</p><p><strong>We’re thinking:</strong>&nbsp;In 2017, researchers&nbsp;<a href="https://distill.pub/2017/feature-visualization/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">visualized</a>&nbsp;the layers of a convolutional neural network to show that the deeper the layer, the more complex the concepts it learned. We’re excited by the prospect that SAEs can deliver similar insights with respect to transformers.</p>
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 00:02:00 GMT</pubDate>
</item>
<item>
<title>AI Restores ALS Patient's Voice, AI Lobby Grows, Agentic Coding Advances, Massively Multimodal Model</title>
<link>https://www.deeplearning.ai/the-batch/issue-264</link>
<guid>https://www.deeplearning.ai/the-batch/issue-264</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>After a recent&nbsp;<a href="https://x.com/OpenAIDevs/status/1820987573793386527?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">price reduction</a>&nbsp;by OpenAI, GPT-4o tokens now cost $4 per million tokens (using a blended rate that assumes 80% input and 20% output tokens). GPT-4 cost $36 per million tokens at its initial release in March 2023.&nbsp;This price reduction over 17 months corresponds to about a 79% drop in price per year: 4/36 = (1 - p)<sup>17/12</sup>. (OpenAI charges a lower price, just $2 per million tokens, for using a new Batch API that takes up to 24 hours to respond to a batch of prompts. That’s an 87% drop in price per year.)</p><p>As you can see, token prices are falling rapidly! One force that’s driving prices down is the release of open weights models such as Llama 3.1. If API providers, including startups Anyscale, Fireworks, Together.ai, and some large cloud companies, do not have to worry about recouping the cost of developing a model, they can compete directly on price and a few other factors such as speed.</p><p>Further, hardware innovations by companies such as Groq (a leading player in fast token generation), Samba Nova (which serves Llama 3.1 405B tokens at an impressive&nbsp;<a href="https://sambanova.ai/blog/speed-record-on-llama-3.1-405b?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">114 tokens per second</a>), and wafer-scale computation startup Cerebras (which just announced a new&nbsp;<a href="https://siliconangle.com/2024/08/27/cerebras-systems-throws-down-gauntlet-to-nvidia-launch-of-worlds-fastest-ai-inference-service/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">offering</a>), as well as the semiconductor giants NVIDIA, AMD, Intel, and Qualcomm, will drive further price cuts.</p><p>When building applications, I find it useful to design to where the technology is going rather than only where it has been. Based on the technology roadmaps of multiple software and hardware companies — which include improved semiconductors, smaller models, and algorithmic innovation in inference architectures — I’m confident that token prices will continue to fall rapidly.</p><figure class="kg-card kg-image-card"><img alt="A graph of model pricing for GPT-4 and Llama 3.1. GPT-4 in March cost $36 per million tokens, GPT-4 Turbo $14, GPT-4o $7." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--1--1.jpg" width="1200" /></figure><p>This means that even if you build an agentic workload that isn’t entirely economical, falling token prices might make it economical at some point. As I&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-we-need-more-compute-for-inference/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">wrote</a>&nbsp;previously, being able to process many tokens is particularly important for agentic workloads, which must call a model many times before generating a result. Further, even agentic workloads are already quite affordable for many applications. Let's say you build an application to assist a human worker, and it uses 100 tokens per second continuously: At $4/million tokens, you'd be spending only $1.44/hour – which is significantly lower than the minimum wage in the U.S. and many other countries.&nbsp;</p><p>So how can AI companies prepare?</p><ul><li>First, I continue to hear from teams that are surprised to find out how cheap LLM usage is when they actually work through cost calculations. For many applications, it isn’t worth too much effort to optimize the cost. So first and foremost, I advise teams to focus on building a useful application rather than on optimizing LLM costs.<br /></li><li>Second, even if an application is marginally too expensive to run today, it may be worth deploying in anticipation of lower prices.&nbsp;<br /></li><li>Finally, as new models get released, it might be worthwhile to periodically examine an application to decide whether to switch to a new model either from the same provider (such as switching from GPT-4 to the latest GPT-4o-2024-08-06) or a different provider, to take advantage of falling prices and/or increased capabilities.&nbsp;</li></ul><p>Because multiple providers now host Llama 3.1 and other open-weight models, if you use one of these models, it might be possible to switch between providers without too much testing (though implementation details — specifically quantization, does mean that different offerings of the model do differ in performance).&nbsp;When switching between models, unfortunately, a major barrier is still the&nbsp;<a href="https://www.deeplearning.ai/the-batch/we-need-better-evals-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">difficulty of implementing evals</a>, so carrying out regression testing to make sure your application will still perform after you swap in a new model can be challenging. However, as the science of carrying out evals improves, I’m optimistic that this will become easier.</p><p>Keep learning!</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="Large Multimodal Model Prompting with Gemini." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--1-.png" width="1200" /></figure><p>In our short course “Large Multimodal Model Prompting with Gemini,” you’ll learn how to build systems that reason across text, images, and video and how prompting multimodal models differs from text-only LLMs. You’ll also optimize LMM systems and output.&nbsp;<a href="https://www.deeplearning.ai/short-courses/large-multimodal-model-prompting-with-gemini?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">Enroll today!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="A man with electrodes connected through his skull is connected to a machine." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed.png" width="1200" /></figure><h1 id="a-lost-voice-regained">A Lost Voice Regained</h1><p>A man who lost the ability to speak four years ago is sounding like his earlier self, thanks to a collection of brain implants and machine learning models.</p><p><strong>What’s new:</strong>&nbsp;Researchers built a system that&nbsp;<a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2314132?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">decodes speech signals from the brain</a>&nbsp;of a man who lost the ability to speak clearly due to amyotrophic lateral sclerosis, also known as ALS, and enables him to speak through a synthetic version of his former voice. At the start of the study, his efforts to speak were intelligible only to his personal caregiver. Now he converses regularly with family and friends,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/08/14/health/als-ai-brain-implants.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">reported</a>. Nicholas Card built the system with colleagues University of California-Davis, Stanford University, Washington University, Brown University, VA Providence Healthcare, and Harvard Medical School.</p><p><strong>How it works:</strong>&nbsp;The authors surgically implanted four electrode arrays into areas of the brain that are responsible for speech. The system learned to decode the patient’s brain signals, decide the most likely phonemes he intended to speak, determine the words those phonemes express, and display and speak the words aloud using a personalized speech synthesizer.&nbsp;</p><ul><li>After the patient recovered from the implantation surgery, the authors collected data for training and evaluating the system. They recorded his brain signals while he tried to speak during 84 sessions, each between 5 and 30 minutes, over 32 weeks. The sessions were split into two tasks: copying, in which the patient spoke sentences shown on a screen, and conversation, in which he spoke about whatever he wanted. Initial sessions focused on copying. Later, when the authors had accrued paired brain signals and known sentences, they focused on conversation.</li><li>A&nbsp;<a href="https://arxiv.org/abs/1406.1078?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">gated recurrent unit</a>&nbsp;(GRU) learned to translate brain signals into a sequence of phonemes. The authors trained the model after each session on all recordings made during that session. To adapt it to day-to-day changes in brain activity, they also fine-tuned it during later sessions: After they recorded a new sentence, they fine-tuned the GRU on a 60/40 mix of sentences from the current session and previous sessions.</li><li>A weighted finite-state transducer (WFST), based on a pretrained 5-gram language model and described in the supplementary information&nbsp;<a href="https://www.nature.com/articles/s41586-023-06377-x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">here</a>), translated sequences of phonemes into sentences. Given a sequence, it generated the 100 most likely sentences.&nbsp;</li><li>Given the likely sentences, the authors ranked them according to the probability that the GRU, WFST, and&nbsp;<a href="https://arxiv.org/abs/2205.01068?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">OPT</a>, a pretrained large language model, would generate them.&nbsp;&nbsp;</li><li>A pretrained&nbsp;<a href="https://arxiv.org/abs/2306.07691?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">StyleTTS 2</a>&nbsp;text-to-speech model turned the highest-ranking sentence into speech. The authors fine-tuned the model on recordings of the patient’s voice from before the onset of his illness, such as podcasts.</li></ul><p><strong>Results:&nbsp;</strong>After two hours of recording the patient’s brain signals and training on that data, the system achieved 90.2 percent accuracy in the copying task. By the final session, the system achieved 97.5 percent accuracy and enabled the patient to speak on average 31.6 words per minute using a vocabulary of 125,000 words.</p><p><strong>Behind the news:</strong>&nbsp;Previous work either had much&nbsp;<a href="https://www.deeplearning.ai/the-batch/talking-without-speaking/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">lower accuracy</a>&nbsp;or generated a&nbsp;<a href="https://www.deeplearning.ai/the-batch/listening-to-the-brain-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">limited vocabulary</a>. The new work improved upon a 2023&nbsp;<a href="https://www.nature.com/articles/s41586-023-06377-x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">study</a>&nbsp;that enabled ALS patients to speak with 76.2 percent accuracy using a vocabulary of equal size.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Relative to the 2023 study on which this one was based, the authors changed the positions of the electrodes in the brain and continued to update the GRU throughout the recording/training sessions. It’s unclear which changes contributed most to the improved outcome. As language models improve, new models potentially could act as drop-in replacements for the models in the authors’ system, further improving accuracy. Likewise, improvements in speech-to-text systems could increase the similarity between the synthetic voice and the patient’s former voice.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Enabling someone to speak again restores agency. Enabling someone to speak again in their own voice restores identity.</p><hr /><figure class="kg-card kg-image-card"><img alt="The SWE-bench full leaderboard shows Cosine Genie outperforming its competitors." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--2-.png" width="1200" /></figure><h1 id="agentic-coding-strides-forward">Agentic Coding Strides Forward</h1><p>An agentic coding assistant boosted the state of the art in an important benchmark by more than 30 percent.</p><p><strong>What’s new:</strong>&nbsp;Cosine, a startup based in London, unveiled&nbsp;<a href="https://cosine.sh/genie?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">Genie</a>, a coding assistant that achieves top performance on SWE-bench, which tests a model’s ability to solve GitHub issues. The company has yet to announce pricing and availability, but a waitlist is available.</p><p><strong>How it works:</strong>&nbsp;Genie is a&nbsp;<a href="https://openai.com/index/gpt-4o-fine-tuning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">fine-tuned version of GPT-4o</a>&nbsp;with a larger context window of&nbsp;<a href="https://cosine.sh/blog/genie-technical-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">undisclosed</a>&nbsp;size. It works similarly to&nbsp;<a href="https://www.deeplearning.ai/the-batch/next-generation-coding-tools-empower-developers-with-agent-style-interactions/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">agentic coding tools</a>&nbsp;like Devin, Q, OpenDevin, and SWE-agent. Its agentic workflow loops through four processes: retrieving information, planning, writing code, and running it. It was trained on a proprietary training set that captures software engineers’ processes for reasoning, gathering information, and making decisions. It edits lines of code in place rather than rewriting entire sections or files from scratch.&nbsp;</p><ul><li>Cosine initially fine-tuned Genie roughly equally on six software engineering tasks: developing features, fixing bugs, refactoring, making minor changes, writing tests, and writing documentation. The fine-tuning set included 15 programming languages, mostly JavaScript and Python (21 percent each) followed by TypeScript and TSX (14 percent each).&nbsp;</li><li>Subsequent fine-tuning focused on finishing incomplete code and fixing imperfect code, which was underrepresented in the initial dataset. This round of training used incorrect examples generated by Genie itself. By comparing Genie’s initial incorrect output with correct examples, the model improved its ability to recognize and fix mistakes.</li><li>At inference — given a prompt in natural language, a ticket that outlines a programming task, or a GitHub issue — the model retrieves relevant files and documentation, makes a plan for fixing the issue, and writes new code. After writing new code, it runs verification tests. If the tests fail, it loops between planning and coding until the tests succeed.</li><li>Genie can also create and monitor pull requests on GitHub. It responds to human comments on its own pull requests just like it acts upon GitHub issues.</li></ul><p><strong>Results:</strong>&nbsp;Tested on&nbsp;<a href="https://www.swebench.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">SWE-bench</a>&nbsp;Full (2,294 issue-commit pairs across 12 Python repositories), Genie solved 30.1 percent of problems, far ahead of the next closest competitor, Amazon Q, at 19.75 percent. Genie achieved 50.7 percent of the SWE-bench Lite (winnowed to 300 issue-commit pairs to save computation), beating CodeStory Aide plus other models at 43 percent. (Genie’s results don’t appear on the official SWE-bench leaderboard. The leaderboard requires that models document their workings, which Cosine declined to avoid revealing proprietary information. Cosine released Genie’s&nbsp;<a href="https://github.com/CosineAI/experiments/tree/cos/swe-bench-submission/evaluation/test/20230726_cosine_genie?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">solution sets</a>&nbsp;to verify its performance.)</p><p><strong>Behind the news:</strong>&nbsp;SWE-bench’s creators recently collaborated with OpenAI to produce a new version,&nbsp;<a href="https://openai.com/index/introducing-swe-bench-verified/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">SWE-bench Verified</a>. They eliminated extremely difficult and poorly configured problems, leaving 500 human-verified issue-commit pairs. Cosine has yet to publish Genie’s performance on SWE-bench Verified. As of this writing, Amazon Q ranks in first place with 38.8 percent.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Some developers of AI coding assistants train models to follow human-style procedures while others are building AI-native methods. Genie takes a distinct step forward by mimicking software engineers. Competition between the&nbsp;<a href="https://www.deeplearning.ai/the-batch/coding-agents-are-evolving-from-novelties-to-widely-useful-tools/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">two approaches</a>, along with longer context windows, faster inference, and increasingly sophisticated agentic workflows, is driving improvement of coding assistants at a rapid pace.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;We’re glad this Genie escaped the bottle!</p><hr /><figure class="kg-card kg-image-card"><img alt="A line graph shows a sharp increase in organizations lobbying the U.S. government on AI issues, from 1 in 2014 to 556 in 2024." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--2--2.jpg" width="1200" /></figure><h1 id="ai-lobby-expands">AI Lobby Expands</h1><p>AI is a red-hot topic for lobbyists who aim to influence government policies in the United States.<br /><strong>What’s new:</strong>&nbsp;The number of organizations lobbying to influence U.S. laws and regulations that affect AI jumped more than 20 percent in the first half of 2024,&nbsp;<em>TechCrunch</em>&nbsp;<a href="https://techcrunch.com/2024/07/31/ai-startups-ramp-up-federal-lobbying-efforts/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">reported</a>. Data collected by OpenSecrets, which tracks political contributions, shows increased lobbying by startups including OpenAI and Anthropic.<br /><strong>How it works:</strong>&nbsp;OpenSecrets searched for the words “AI” and “artificial intelligence” in lobbying disclosure forms. Organizations must file such forms quarterly if they discuss specific laws and regulations with decision makers or their staffs.&nbsp;</p><ul><li>More than 550 organizations lobbied the federal government about AI policy in the first half of 2024, up from 460 in 2023. These included tech giants and startups; venture capital firms; think tanks; companies and trade groups in various industries including insurance, health care, and education; and universities.</li><li>OpenAI spent $800,000 on lobbying in the first half of the year, compared to $260,000 the previous year. OpenAI’s team of contract lobbyists grew to 15,&nbsp;<a href="https://www.reuters.com/legal/transactional/openai-expands-lobbying-efforts-hiring-former-us-senator-2024-03-12/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">including</a>&nbsp;former U.S. Senator Norm Coleman. That’s up from three in 2023, when it&nbsp;<a href="https://www.ft.com/content/2bee634c-b8c4-459e-b80c-07a4e552322c?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">hired</a>&nbsp;its first internal lobbyist. In addition, the company’s global affairs department expanded to 35 people; it’s expected to balloon to 50 by the end of the year. OpenAI publicly supports legislation currently under consideration by the U.S. Senate that would appoint a National AI Research Resource program manager and authorize an AI Safety Institute to set national standards and create public datasets.</li><li>Anthropic expanded its team of external lobbyists from three to five this year and hired an in-house lobbyist. It expects to spend $500,000 on lobbying as the election season heats up.</li><li>Cohere budgeted $120,000 for lobbying this year after spending $70,000 last year.</li><li>Amazon, Alphabet, Meta, and Microsoft each spent more than $10 million on lobbying in 2023,&nbsp;<em>Time</em>&nbsp;<a href="https://time.com/6972134/ai-lobbying-tech-policy-surge/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">reported</a>.</li></ul><p><strong>Yes, but:&nbsp;</strong>The lobbying disclosure forms show who is spending money to influence policy, but they provide only a limited view. For instance, they reveal only that an organization aimed to influence AI policy, not the directions in which they aimed to influence it. Similarly, the disclosures shed no light on other efforts to influence laws and regulations such as advertising or campaign contributions. They also don’t reveal how much an organization discussed AI relative to other topics and concerns. For instance, last year the American Medical Association spent $21.2 million on lobbying including AI but, given the wide range of policy issues involved in medicine, AI likely accounted for a small amount of the total.&nbsp;<br /><strong>Behind the news:</strong>&nbsp;The ramp-up in AI lobbying comes as the U.S. Congress is considering a growing number of laws that would regulate the technology. Since 2023, more than 115 bills have been proposed that seek to restrict AI systems, require developers to disclose or evaluate them, or protect consumers against potential harms like AI bias, infringement of privacy or other rights, or spreading inaccurate information&nbsp;<a href="https://www.brennancenter.org/our-work/research-reports/artificial-intelligence-legislation-tracker?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">according to</a>&nbsp;the nonprofit, nonpartisan Brennan Center for Justice. Nearly 400 state laws are also under consideration,&nbsp;<a href="https://www.bsa.org/news-events/news/bsa-analysis-states-intensify-work-on-ai-legislation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">according to</a>&nbsp;BSA, a software lobbying group, including California SB-1047, which would&nbsp;<a href="https://www.deeplearning.ai/the-batch/californias-proposed-ai-safety-law-puts-developers-at-risk-california-sb-1047-is-intended-to-make-ai-safer-but-its-unclear-requirements-put-developers-innovation-and-open-source-in-jeop/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">regulate</a>&nbsp;AI models whose training exceeds a particular threshold of computation. Moreover, the U.S. will hold national elections in November, and lobbying of all kinds typically intensifies as organizations seek to influence candidates for office.<br /><strong>Why it matters:</strong>&nbsp;Given the large amount of AI development that takes place in the U.S., laws that govern AI in this country have an outsized influence over AI development worldwide. So it’s helpful to know which companies and institutions seek to influence those laws and in what directions. That the army of AI lobbyists includes companies large and small as well as far-flung institutions, with varying degrees of direct involvement in building or using AI, reflects both the technology’s power and the importance of this moment in charting its path forward.<br /><strong>We’re thinking:</strong>&nbsp;We favor thoughtful regulation of AI applications that reinforces their tremendous potential to do good and limits potential harms that may result from flaws like bias or privacy violations. However, it’s critical to regulate applications, which put technology to specific uses, not the underlying technology, whose valuable uses are wide-ranging and subject to human creativity. It’s also critical to encourage, and not stifle, open models that multiply the potential good that AI can do. We hope the AI community can come together on these issues.</p><hr /><figure class="kg-card kg-image-card kg-card-hascaption"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--3-.png" width="1200" /><figcaption><span style="white-space: pre-wrap;">A graphic shows an any-to-any multimodal model, with text mapping to RGB or geometric modalities.</span></figcaption></figure><h1 id="multimodal-to-the-max">Multimodal to the Max</h1><p>Researchers introduced a model that handles an unprecedented number of input and output types, including many related to performing computer vision tasks.</p><p><strong>What’s new:</strong>&nbsp;Roman Bachmann, Oguzhan Fatih Kar, David Mizrahi and colleagues at EPFL and Apple built&nbsp;<a href="https://arxiv.org/abs/2406.09406?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">4M-21</a>, a system that works with 21 input and output types. These include modalities related to images, geometry, and text along with metadata and embeddings produced by other models.</p><p><strong>Key insight:</strong>&nbsp;The authors followed and extended their insight from the earlier&nbsp;<a href="https://arxiv.org/pdf/2312.06647?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">4M</a>, which handles seven input and output types, as well as work such as&nbsp;<a href="https://arxiv.org/abs/2312.17172?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">Unified-IO 2</a>, which handles 11. The key to training a model to handle multiple types of data input is to ensure that the training data takes the same format with the same-sized embedding across all input types. Using the transformer architecture, tokens suffice.&nbsp;</p><p><strong>How it works:</strong>&nbsp;4M-21 comprises a large transformer and several encoder-decoders that convert different data types into tokens and back. The authors repeated their training strategy for 4M, but they increased the transformer’s size from 303 million parameters to 3 billion parameters, boosted the training dataset size from 400 million examples to 500 million examples, and incorporated new input types.&nbsp;</p><ul><li>The authors started with RGB images and captions from&nbsp;<a href="https://arxiv.org/abs/2102.08981?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">CC12M</a>&nbsp;and&nbsp;<a href="https://github.com/kakaobrain/coyo-dataset?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">COYO700M</a>&nbsp;plus text from&nbsp;<a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">C4.</a></li><li>Using a variety of tools, they extracted depth images, surface-normal images, semantically segmented images, images of edges, graphics metadata, bounding boxes, color palettes, web text, image embeddings (feature maps and global embeddings), and text embeddings. For instance, they performed semantic segmentation using&nbsp;<a href="https://arxiv.org/abs/2112.01527?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">Mask2Former</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2304.02643?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">SAM</a>, and extracted edges using&nbsp;<a href="https://opencv.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">OpenCV</a>&nbsp;and SAM, counting each output as a separate data type.</li><li>They converted all input types into tokens. For image-like data types and image embeddings, they trained&nbsp;<a href="https://papers.nips.cc/paper_files/paper/2017/hash/7a98af17e63a0ac09ce2e96d03992fbc-Abstract.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">VQ-VAE</a>&nbsp;to reconstruct images and, in doing so, represent images as tokens. For human poses and the embeddings&nbsp;from&nbsp;DINOv2 and ImageBind, they trained&nbsp;<a href="https://arxiv.org/abs/2306.13575?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">Bottleneck MLP</a>&nbsp;to reconstruct them and thus learn to represent them as tokens. They produced tokens of sequence data including text and metadata using&nbsp;<a href="https://aclanthology.org/N19-1423/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">WordPiece</a>.</li><li>Given a random sample of tokens of all modalities, 4M-21 learned to predict a different random sample of tokens. The random samples were sometimes biased toward one modality and other times biased toward a more balanced sampling. To determine which tokens to produce, 4M-21 received mask tokens that specified the desired modalities&nbsp;and token positions in the output.</li></ul><p><strong>Results:</strong>&nbsp;4M-21 demonstrated strong zero-shot performance in a variety of vision tasks. For instance, in estimating surface normals for each point in an image, 4M-21 achieved a 20.8 L1 score (average absolute difference between predicted and true values, lower is better), while the multimodal model&nbsp;<a href="https://arxiv.org/abs/2312.17172?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC" rel="noopener">UnifiedIO 2-XL</a>&nbsp;achieved a 34.8 L1. In estimating an image’s depth map, 4M-21 achieved 0.68 L1, while UnifiedIO 2-XL achieved 0.86 L1. In semantic segmentation, 4M-21 reached 48.1 percent mean intersection over union (overlap between predicted and ground-truth segments divided by their union, higher is better), while UnifiedIO 2-XL achieved 39.7 percent mean intersection over union.</p><p><strong>Why it matters:</strong>&nbsp;Since 4M-21 learned to predict tokens of several modalities using tokens from other modalities, it isn’t limited to a single modalities as input. The authors demonstrate that it can generate new images conditioned by the combination of a caption and 3D human poses, edges, or metadata.</p><p><strong>We’re thinking:</strong>&nbsp;The authors say 4M-21 can take as input any combination of the modalities it’s trained to handle and output any of them. The limits of this capability aren’t clear, but it opens the door to fine control over the model’s output. The authors explain how they extracted the various modalities; presumably users can do the same to prompt the model for the output they desire. For instance, a user could request an image by entering not only a prompt but also a color palette, edges, depth map extracted from another image, and receive output that integrates those elements.</p>
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 20:21:45 GMT</pubDate>
</item>
<item>
<title>AI Agents Generate Novel Research, Google Imagen 3 Raises the Bar, Alibaba’s Open Models for Specialized Tasks, Scaling Laws for Data Quality</title>
<link>https://www.deeplearning.ai/the-batch/issue-263</link>
<guid>https://www.deeplearning.ai/the-batch/issue-263</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>I’m encouraged at the progress of the U.S. government at moving to stem harmful AI applications. Two examples are the new Federal Trade Commission (FTC)&nbsp;<a href="https://www.ftc.gov/news-events/news/press-releases/2024/08/federal-trade-commission-announces-final-rule-banning-fake-reviews-testimonials?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">ban on fake product reviews</a>&nbsp;and the&nbsp;<a href="https://www.durbin.senate.gov/imo/media/doc/defiance_act_of_2024.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DEFIANCE Act</a>, which imposes punishments for creating and disseminating non-consensual deepfake porn. Both rules take a sensible approach to regulating AI insofar as they target harmful applications rather than general-purpose AI technology.</p><p>As I&nbsp;<a href="https://www.deeplearning.ai/the-batch/blenders-versus-bombs-or-why-californias-proposed-ai-law-is-bad-for-everyone/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">described</a>&nbsp;previously, the best way to ensure AI safety is to regulate it at the application level rather than the technology level. This is important because the technology is general-purpose and its builders (such as a developer who releases an open-weights foundation model) cannot control how someone else might use it. If, however, someone applies AI in a nefarious way, we should stop that application.&nbsp;</p><p>Even before generative AI, fake reviews were a problem on many websites, and many tech companies dedicate considerable resources to combating them. A telltale sign of old-school fake reviews is the use of similar wording in different reviews. AI’s ability to automatically paraphrase or rewrite is making fake reviews harder to detect.</p><p>Importantly, the FTC is not going after the makers of foundation models for fake reviews. The provider of an open weights AI model, after all, can’t control what someone else uses it for. Even if one were to try to train a model to put up guardrails against writing reviews, I don’t know how it could distinguish between a real user of a product asking for help writing a legitimate review and a spammer who wanted a fake review. The FTC appropriately aims to ban the application of fake reviews along with other deceptive practices such as buying positive reviews.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--80--1.jpg" width="1200" /></figure><p>The DEFIANCE Act, which passed unanimously in the Senate (and still requires passage in the House of Representatives before the President can sign it into law) imposes civil penalties for the creating and distributing non-consensual, deepfake porn. This disgusting application is&nbsp;<a href="https://www.nytimes.com/2024/04/08/technology/deepfake-ai-nudes-westfield-high-school.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">harming</a>&nbsp;many people including underage girls. While many image generation models do have guardrails against generating porn, these guardrails often can be circumvented via jailbreak prompts or fine-tuning (for models with open weights).</p><p>Again, DEFIANCE regulates an application, not the underlying technology. It aims to punish people who engage in the application of creating and distributing non-consensual intimate images, regardless of how they are generated — whether the perpetrator uses a diffusion model, a generative adversarial network, or Microsoft Paint to create an image pixel by pixel.</p><p>I hope DEFIANCE passes in the House and gets signed into law. Both rules guard against harmful AI applications without stifling AI technology itself (unlike California’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/californias-proposed-ai-safety-law-puts-developers-at-risk-california-sb-1047-is-intended-to-make-ai-safer-but-its-unclear-requirements-put-developers-innovation-and-open-source-in-jeop/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">poorly designed</a>&nbsp;SB-1047), and they offer a good model for how the U.S. and other nations can protect citizens against other potentially harmful applications.&nbsp;<br /><br />Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-ai-applications-with-haystack?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/08/The-Batch-ads-and-exclusive-banners---2024-08-20T091645.073.png" width="1680" /></a></figure><p>Build flexible, maintainable applications with our new course, “Building AI Applications with Haystack.” Guided by Tuana Çelik, you’ll build projects like a RAG app and a self-reflecting agent using the Haystack framework.&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-ai-applications-with-haystack/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Join for free</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-21T140739.984.png" width="1200" /></figure><h1 id="ai-agents-for-ai-research">AI Agents for AI Research</h1><p>While some observers argue that large language models can’t produce truly original output, new work prompted them to generate novel scientific research.</p><p><strong>What’s new:</strong>&nbsp;Researchers proposed&nbsp;<a href="https://www.arxiv.org/abs/2408.06292?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">AI Scientist</a>, an agentic workflow that directs large language models to generate ideas for AI research, produce code to test them, and document the enquiry. You can see examples of its output and download the code to generate your own papers&nbsp;<a href="https://github.com/SakanaAI/AI-Scientist?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8#read%20me" rel="noopener">here</a>. The team included Chris Lu, Cong Lu, Robert Tjarko Lange, and colleagues at Tokyo-based startup Sakana AI, University of Oxford, University of British Columbia, Vector Institute, and the Canadian Institute for Advanced Research.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors used Claude Sonnet 3.5, GPT-4o, DeepSeek Coder, and LLama 3.1 405B to generate papers in three categories: diffusion image modeling, transformer-based language modeling, and “grokking,” which the authors define as generalization and speed of learning in deep neural networks.&nbsp;</p><ul><li>The authors prompted a given large language model (LLM) to generate “the next creative and impactful idea for research” in one of the three categories. Then they provided an API to search papers and asked the LLM to either determine whether its idea was novel (in which case it moved to the next step) or, if it couldn’t determine an answer, generate a search query to find related works. Then the authors asked again in light of the search results. They repeated this process until the LLM made a decision.</li><li>Once they had a novel idea, they prompted the LLM to generate a list of experiments and run them using the&nbsp;<a href="https://github.com/paul-gauthier/aider?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Aider</a>&nbsp;Python library. Then they prompted it to generate notes about the results and generate figures by altering an existing Python script.</li><li>They prompted the LLM to generate a paper, one section at a time, given the notes, figures, sections generated so far, and tips on how to write a paper based on an existing&nbsp;<a href="https://docs.google.com/document/d/16R1E2ExKUCP5SlXWHr-KzbVDx9DBUclra-EbU8IB-iE/edit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">guide</a>. Then they prompted it to search for related works and add relevant citations. Finally, they asked it to remove redundancy, reduce verbosity, and finalize the document’s format.</li></ul><p><strong>Results:</strong>&nbsp;The team used GPT-4o to evaluate the generated papers according to the&nbsp;<a href="https://neurips.cc/Conferences/2022/ReviewerGuidelines?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">guidelines</a>&nbsp;for papers presented at the Neural Information Processing Systems (NeurIPS) conference. The guidelines include an overall score between 1 (very strongly reject) and 10 (award-quality: flawless and groundbreaking) and a decision to reject or accept the paper.&nbsp;</p><ul><li>Of the four LLMs, Claude Sonnet 3.5 performed best. Its highest-scoring papers achieved 6 (weak accept). With respect to one of Claude’s works, the authors wrote, “The AI Scientist correctly identifies an interesting and well-motivated direction in diffusion modeling research . . . It proposes a comprehensive experimental plan to investigate its idea, and successfully implements it all, achieving good results." The authors provide an archive of Claude’s output&nbsp;<a href="https://drive.google.com/drive/folders/1Mmpz6M1FK4q8e-SewgZcUzdeD0Q2zC39?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">here</a>.&nbsp;</li><li>GPT-4o ranked second. Its highest-scoring paper achieved 5 (borderline accept).</li><li>The generated papers achieved an average score of 4.05 or less (4 is borderline reject) across all models and categories of experiment. The experiments generally involved small networks that were trained and tested on generated data. The authors note that the system often failed to implement its ideas, sometimes fabricated results, and sometimes failed to cite the most relevant papers, among other issues.</li></ul><p><strong>Why it matters:</strong>&nbsp;Agentic workflows are a rising theme in AI research from simpler design patterns like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">reflection</a>&nbsp;to complex workflows for&nbsp;<a href="https://arxiv.org/abs/2405.11804?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">translating literature</a>. These workflows make it possible to break down complex problems into more manageable subtasks. By breaking the task of conducting AI research into various stages of generating ideas, testing them, and writing a paper, an LLM that has access to the right tools can generate novel research papers with actual experimental results.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Rather than merely synthesizing existing knowledge, this work points a fascinating direction for using AI to generate new knowledge! Right now, an LLM can suggest starting points for human researchers along with experiments that back up its suggestions.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-21T142127.807.gif" width="1200" /></figure><h1 id="google-imagen-3-raises-the-bar">Google Imagen 3 Raises the Bar</h1><p>Image generation continued its rapid march forward with a new version of Google’s flagship text-to-image model.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://deepmind.google/technologies/imagen-3/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">introduced</a>&nbsp;Imagen 3, a proprietary model that improves upon the previous version’s image quality and prompt adherence, with features like inpainting and outpainting to be added in the future. Imagen 3 is available via Google’s&nbsp;<a href="https://aitestkitchen.withgoogle.com/tools/image-fx?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">ImageFX</a>&nbsp;web user interface and&nbsp;<a href="https://cloud.google.com/generative-ai-studio?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Vertex AI</a>&nbsp;Platform. It follows closely upon the releases of Black Forest Labs’ Flux.1 family (open to varying degrees), Midjourney v6.1, and Stability AI Stable Diffusion XL 1 (open weights) — all in the last month.</p><p><strong>How it works:</strong>&nbsp;The accompanying&nbsp;<a href="https://arxiv.org/abs/2408.07009?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">paper</a>&nbsp;does not describe the model’s architecture and training procedures in detail. The authors trained a diffusion model on an unspecified “large” dataset of images, text, and associated annotations that was filtered to remove unsafe, violent, low-quality, generated, and duplicate images as well as personally identifying information. Google’s Gemini large language model generated some image captions used in training to make their language more diverse.&nbsp;</p><p><strong>Results:</strong>&nbsp;Imagen 3 mostly outperformed competing models in head-to-head comparisons based on prompts from datasets including&nbsp;<a href="https://arxiv.org/abs/2404.01291?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">GenAI-Bench</a>,&nbsp;<a href="https://arxiv.org/abs/2205.11487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DrawBench</a>, and&nbsp;<a href="https://cdn.openai.com/papers/dall-e-3.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DALL-E 3 Eval</a>. The team compared Imagen 3 to Midjourney v6.0, OpenAI DALL-E 3, Stable Diffusion 3 Large, and Stable Diffusion XL 1.0. More than 3,000 evaluators from 71 countries rated the models’ responses in side-by-side comparisons. The raters evaluated image quality, preference regardless of the prompt, adherence to the prompt, adherence to a highly detailed prompt, and ability to generate the correct numbers of objects specified in a prompt. Their ratings (between 1 and 5) were used to compute Elo ratings.</p><ul><li>Imagen 3 swept the overall preference tests. On GenAI-Bench and DrawBench, Imagen 3 (1,099 Elo and 1,068 Elo respectively) beat the next-best Stable Diffusion 3 (1,047 Elo and 1,053 Elo respectively). On DALL-E 3 Eval, Imagen 3 (1,079 Elo) beat the next-best MidJourney v6.0 (1,068 Elo).</li><li>Likewise, Imagen 3 swept the prompt-image alignment benchmarks. On GenAI-Bench and DrawBench, Imagen 3 (1,083 Elo and 1,064 Elo respectively) outperformed the next-best Stable Diffusion 3 (1,047 Elo for both datasets). On DALL-E 3 Eval, Imagen 3 (1,078) narrowly edged out DALL-E 3 (1,077 Elo) and Stable Diffusion 3 (1,069 Elo).</li><li>Imagen 3 showed exceptional strength in following detailed prompts in the&nbsp;<a href="http://arxiv.org/abs/2404.19753?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DOCCI</a>&nbsp;dataset (photographs with detailed descriptions that averaged 136 words). In that category, Imagen 3 (1,193 Elo) outperformed next-best Midjourney v6.0 (1,079 Elo).</li><li>Although none of the models tested did very well at generating specified numbers of objects from the&nbsp;<a href="https://arxiv.org/abs/2406.14774?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">GeckoNum</a>&nbsp;dataset, Imagen 3 (58.6 Elo) outperformed the next-best DALL-E 3 (46.0 Elo).</li><li>Imagen 3 lost to Midjourney v6.0 across the board in tests of visual appeal regardless of the prompt. It was slightly behind on GenAI-Bench (1,095 Elo versus 1,101 Elo), farther behind on DrawBench (1,063 Elo versus 1,075 Elo), and well behind on DALL-E 3 Eval (1,047 Elo versus 1,095 Elo).</li></ul><p><strong>Why it matters:</strong>&nbsp;Each wave of advances makes image generators more useful for a wider variety of purposes. Google’s emphasis on filtering the training data for safety may limit Imagen 3’s utility in some situations (indeed, some users&nbsp;<a href="https://www.reddit.com/r/Bard/comments/1eo3ge9/imagen_3_is_available_for_everyone_google_is/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">complained</a>&nbsp;that Imagen 3 is more restrictive than Imagen 2, while the Grok2 large language model’s use of an unguardrailed version of Flux.1 for image generation has garnered&nbsp;<a href="https://www.yahoo.com/tech/grok-2-0-takes-guardrails-175824863.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">headlines</a>). Nonetheless, precautions are an important ingredient in the evolving text-to-image recipe.</p><p><strong>We’re thinking:</strong>&nbsp;It’s difficult to compare the benchmarks reported for Imagen 3 and the recently released&nbsp;<a href="https://www.deeplearning.ai/the-batch/black-forest-labs-flux-1-outperforms-top-text-to-image-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Flux.1</a>, which claims similar improvements over earlier models. In any case, Google has yet to publish a benchmark for generating text, a valuable capability for commercial applications. The Flux.1 models, two of which are open to some degree, may prove to be formidable rivals in this area.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-21T142223.196.gif" width="1200" /></figure><h1 id="open-models-for-math-and-audio">Open Models for Math and Audio</h1><p>Alibaba followed up its open-weights Qwen2 large language models with specialized variations.</p><p><strong>What’s new:</strong>&nbsp;<a href="https://qwenlm.github.io/blog/qwen2-math/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Qwen2-Math</a>&nbsp;and&nbsp;<a href="https://qwenlm.github.io/blog/qwen2-audio/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Qwen2-Audio</a>&nbsp;are model families devoted to, respectively, solving math problems and generating text directly from audio. Both set new states of the art in a variety of English and Chinese benchmarks, and some versions offer open weights. Notably Qwen2-Math-Instruct-72B, whose 72 billion parameters are fine-tuned according to human preferences, outperformed top models including Claude 3.5 Sonnet, Gemini 1.5-Pro, GPT-4o, and Llama-3.1-405B on some math benchmarks.</p><p><strong>Math mavens:</strong>&nbsp;Qwen2-Math models include&nbsp;<a href="https://github.com/QwenLM/Qwen2-Math?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">pretrained</a>&nbsp;and&nbsp;<a href="https://huggingface.co/Qwen/Qwen2-Math-72B-Instruct?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">instruction-tuned</a>&nbsp;variations that comprise 1.5 billion, 7 billion, and 72 billion parameters. The&nbsp;<a href="https://huggingface.co/Qwen/Qwen2-Math-72B-Instruct/blob/main/LICENSE?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">license</a>&nbsp;for the largest version is free for noncommerical development and commercial developers who have less than 100 million monthly active users.&nbsp;</p><ul><li><strong>How it works:</strong>&nbsp;Qwen2-Math base models were initialized to Qwen2 weights and further pretrained on a corpus of math articles, books, exams, and data generated by Qwen2. The instruction-tuned versions were fine-tuned on more model-generated data using supervised learning followed by a reinforcement learning algorithm called&nbsp;<a href="https://arxiv.org/pdf/2402.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">group relative policy optimization</a>. The team removed examples that significantly overlapped benchmark test sets and prominent math competitions.</li><li><strong>Results:</strong>&nbsp;Using few-shot, chain-of-thought prompting, Qwen2-Math-Instruct-72B achieved state-of-the-art performance in English math benchmarks including&nbsp;<a href="https://arxiv.org/abs/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">MATH</a>&nbsp;and Chinese math benchmarks including&nbsp;<a href="https://arxiv.org/abs/2306.16636?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">CMATH</a>,&nbsp;<a href="https://arxiv.org/pdf/2304.06364?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">GaoKao Math Cloze, and GaoKao Math QA</a>. (The 72 billion-parameter Qwen2-Math achieved state-of-the-art scores in&nbsp;<a href="https://arxiv.org/abs/2110.14168?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">GSM8k</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">MMLU STEM</a>.) Qwen2-Math-Instruct-72B also outperformed Claude 3 Opus, GPT-4 Turbo, Gemini 1.5 Pro and Gemini Math-Specialized 1.5 Pro in the&nbsp;<a href="https://aime24.aimedicine.info/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">AIME 2024</a>&nbsp;math competition in some settings. The smaller, instruction-tuned versions outperformed other models of the same size by some measures.</li></ul><p><strong>Audio/text to text:</strong>&nbsp;A revision of the earlier Qwen-Audio,&nbsp;<a href="https://github.com/QwenLM/Qwen2-Audio?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Qwen2-Audio</a>&nbsp;takes text and audio inputs and generates text outputs. It’s designed to (i) provide text chat in response to voice input including voice transcription and translation between eight languages and (ii) discuss audio input including voice, music, and natural sounds. Weights (8.2 billion parameters) are available for base and instruction-tuned versions. You can try it&nbsp;<a href="https://huggingface.co/spaces/Qwen/Qwen2-Audio-Instruct-Demo?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">here</a>.</p><ul><li><strong>How it works:</strong>&nbsp;Given a text prompt and audio, a&nbsp;<a href="https://github.com/openai/whisper?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Whisperlarge-v3</a>&nbsp;audio encoder embeds the audio, and a pretrained Qwen-7B language model uses the text prompt and audio embedding to generate text. The team further pretrained the system to predict the next text token based on a text-audio dataset that included 370,000 hours of recorded speech, 140,000 hours of music, and 10,000 hours of other sounds. They fine-tuned the system for chat in a supervised fashion and for factuality and prompt adherence using&nbsp;<a href="https://arxiv.org/abs/2305.18290?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DPO</a>. You can read the technical report&nbsp;<a href="https://arxiv.org/pdf/2407.10759?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">here</a>.</li><li><strong>Results:</strong>&nbsp;Qwen2-Audio outperformed previous state-of-the-art models in benchmarks that evaluate speech recognition (<a href="https://ieeexplore.ieee.org/document/7178964?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Librispeech</a>,&nbsp;<a href="https://arxiv.org/abs/1808.10583?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">AISHELL-2</a>,&nbsp;<a href="https://arxiv.org/abs/2205.12446?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">FLEURS-ZH</a>), speech-to-text translation (<a href="https://arxiv.org/abs/2007.10310?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">CoVoST2</a>), and audio classification (<a href="https://arxiv.org/abs/2205.03433?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Vocalsound</a>) as well as&nbsp;<a href="https://arxiv.org/abs/2402.07729?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">AIR-Bench</a>&nbsp;tests for evaluating interpretation of speech, music, sound, and mixed-audio soundscapes.</li></ul><p><strong>Why it matters:</strong>&nbsp;Qwen2 delivered extraordinary performance with open weights, putting Alibaba on the map of large language models (LLMs). These specialized additions to the family push forward math performance and audio integration in AI while delivering state-of-the-art models into the hands of more developers.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;It’s thrilling to see models with open weights that outperform proprietary models. The white-hot competition between open and closed technology is good for everyone!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-21T142304.320.png" width="1200" /></figure><h1 id="scaling-laws-for-data-quality">Scaling Laws for Data Quality</h1><p>When training vision-language models, developers often remove lower-quality examples from the training set. But keeping only the highest-quality examples may not be ideal, researchers found.</p><p><strong>What's new:</strong>&nbsp;Sachin Goyal, Pratyush Maini, and colleagues at Carnegie Mellon University derived&nbsp;<a href="https://arxiv.org/abs/2404.07177?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">scaling laws for filtering data</a>&nbsp;that describe how the utility of examples — in terms of how much they increase performance (or decrease loss) — falls when they are used over and over again in training.</p><p><strong>Key insight:</strong>&nbsp;When computational resources are limited relative to the amount of data available, some AI developers try to select the highest-quality examples and train on them for multiple iterations. However, the utility of examples declines a little bit every time they’re used. As computational resources rise, it’s better to introduce new examples even if they’re of slightly lower quality.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors used 128 million text-image pairs from&nbsp;<a href="https://arxiv.org/abs/2304.14108?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">DataComp</a>&nbsp;to train various&nbsp;<a href="https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">CLIP</a>&nbsp;models, varying the data quality and number of times a model saw each example during training.&nbsp;</p><ul><li>The authors divided the dataset into subsets, each containing 10 percent of the examples, of graduated quality. They evaluated quality according to&nbsp;<a href="https://arxiv.org/abs/2307.03132?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Text Masking and Re-Scoring</a>&nbsp;(T-MARS) scores from a pretrained&nbsp;<a href="https://openai.com/index/clip/?ref=dl-staging-website.ghost.io&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">CLIP</a>, measuring the similarity between CLIP embeddings of an image and corresponding text.</li><li>They trained a model on each subset, repeating it up to 10 times. Each time the model was trained on a particular subset, they evaluated the model’s error rate on ImageNet classification and fit a scaling curve to the error rates.&nbsp;</li><li>They calculated scaling curves for combinations of subsets (for example, the highest-quality 30 percent of examples) by taking a weighted average of the scaling curves of the individual subsets.&nbsp;</li><li>To verify the scaling curves, the authors trained nine instances of CLIP using the highest-quality 10 percent, 30 percent, or 40 percent examples while presenting 32 million, 128 million, or 640 million examples (including repeats).</li></ul><p><strong>Results:</strong>&nbsp;The authors rated each model’s performance according to the average across 18 visual tasks, mostly involving classification accuracy (including ImageNet). The more examples a model saw, the more its performance benefited from training on lower-quality examples in addition to the highest-quality examples. Of the models that saw 32 million examples, the one trained on the highest-quality 10 percent of examples did best. Of the models that saw 128 million examples, the one trained on the highest-quality 30 percent of examples did the best. Of the models that saw 640 million examples, the one trained on the highest-quality 40 percent of examples did the best. These results confirmed theoretical predictions based on the scaling curves.</p><p><strong>Why it matters:</strong>&nbsp;The practice of pretraining vision-language models on a certain percentage of only the highest-quality examples is not ideal. A better approach is to perform experiments to determine the best percentage given the available compute budget: Train first on a small amount of data and filter for quality according to the scaling curves.</p><p><strong>We're thinking:</strong>&nbsp;This work affirms the fundamental principle of&nbsp;<a href="https://datacentricai.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--fHYp_TdGAB9wL4bp4CJGBmNyeAl0abSFzSTtvqHS4DmyrNppST7tT1XPj-lHyIlYFfAs8" rel="noopener">Data-centric AI</a>: Systematically engineering training data is essential for getting optimal performance from a given architecture. However, it shows that using only the highest-quality data works best with smaller compute budgets. With more compute, lower-quality data can improve performance more than repeating the highest-quality examples too many times.</p>
]]></content:encoded>
<pubDate>Wed, 21 Aug 2024 19:25:32 GMT</pubDate>
</item>
<item>
<title>LLM Price War, Black Forest’s Open Image Generator, The High Cost of AI Leadership, Machine Translation Goes Agentic</title>
<link>https://www.deeplearning.ai/the-batch/issue-262</link>
<guid>https://www.deeplearning.ai/the-batch/issue-262</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>When entrepreneurs build a startup, it is often their speed and momentum that gives them a shot at competing with the tech behemoths. This is true of countries as well.</p><p>I was recently in Thailand, where I was delighted to see tremendous momentum building in AI (and sip the best Thai ice tea I’ve ever tasted). Even though Thailand is not as advanced in AI technology or applications as leading tech countries, the enthusiasm for building AI throughout government, corporations, and academia was thrilling. I came away heartened that AI’s benefits will be spread among many countries and convinced that one's level of AI development right now matters less than your momentum toward increasing it.&nbsp;</p><p>Seeing the momentum behind AI in Thailand — where the per capita GDP is around one fifth that of Japan, and one tenth that of the United States — left me feeling that any country, company, or person has a shot at doing meaningful work in the field. While advanced economies such as the U.S. and China are still in the lead, generative AI has made the playing field more level. Foundation models, especially those with open weights, are significantly lowering the barriers to building meaningful AI projects. In Thailand, a lot of people I met weren’t just talking about AI, they were rolling up their sleeves and building. That buys a nation a lot more momentum than just talk.<br /><br />I met with Prime Minister Srettha Thavisin and his Ministers of Higher Education and Education (primary/secondary) along with many staffers. It was delightful to hear the PM speak of his enthusiasm for AI. The ministers discussed how to (i) provide AI training and (ii) use AI to improve education in a variety of subjects. Happily, the focus was on creating value while thinking through realistic risks like AI’s potential to proliferate misinformation, and not a single person asked me about whether AI will lead to human extinction!</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-14T145457.617-1.png" width="1200" /></figure><p>I also met with many business leaders and enjoyed seeing a rapid pace of experimentation with AI. KBTG, an affiliate of the country’s leading digital bank KBank, is working on a financial chatbot advisor, AI-based identity verification for anti-fraud, AI for auto insurance, and a Thai-language financial large language model. These features are growing mobile banking and increasing financial access. Many business leaders in other sectors, too, have asked their teams to run experiments. There are many AI applications yet to be built in industrial sectors, tourism, trade, and more! (KBTG is an investor in AI Fund, which I lead.)</p><p>I often visit universities in both developed and developing economies, and I’ve been surprised to see that universities in developing economies sometimes adopt AI faster. At Chulalongkorn University (known as Chula), I met with the University President Bundhit Eua-arporn and Director of Chula AI Professor Proadpran Punyabukkana. Chula AI has rolled out campus-wide training in generative AI for faculty, staff, and students. In addition, it supports building AI applications such as AI screening for depression and gastrointestinal cancer.&nbsp;<br /><br />It takes years to build up advanced technology. But momentum matters, and there will be many rewards along the journey. There’s no time like the present to start building!&nbsp;</p><p>Keep building,</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/improving-accuracy-of-llm-applications?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/08/The-Batch-ads-and-exclusive-banners---2024-08-13T091442.999.png" width="1680" /></a></figure><p>Our short course “Improving Accuracy of LLM Applications” teaches a step-by-step approach to improving the accuracy of applications built on large language models. You’ll build an evaluation framework, incorporate self-reflection, and fine-tune models using LoRA and memory tuning to embed facts and reduce hallucinations.&nbsp;<a href="https://www.deeplearning.ai/short-courses/improving-accuracy-of-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Enroll for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--78-.jpg" width="1200" /></figure><h1 id="higher-performance-lower-prices">Higher Performance, Lower Prices</h1><p>Prices for access to large language models are falling as providers exploit new efficiencies and compete for new customers.</p><p><strong>What’s new:</strong>&nbsp;Open AI&nbsp;<a href="https://openai.com/index/introducing-structured-outputs-in-the-api/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">cut</a>&nbsp;the price of calls to GPT-4o’s API by 50 percent for input tokens and 33 percent for output tokens, with an even steeper discount for asynchronous processing. Not to be outdone, Google&nbsp;<a href="https://developers.googleblog.com/en/gemini-15-flash-updates-google-ai-studio-gemini-api/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">cut</a>&nbsp;the price of API calls to Gemini 1.5 Flash by approximately 75 percent.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The latest price reductions follow a steady trend,&nbsp;<a href="https://x.com/swyx/status/1821771182443540752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">tracked</a>&nbsp;by Smol.ai CEO Shawn Wang, in which providers are charging less even as model performance (as measured by LMSys’s&nbsp;<a href="https://chat.lmsys.org/?leaderboard&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Chatbot Arena Leaderboard</a>&nbsp;Elo ratings) rises. Here’s a list of recent prices in order of each model’s&nbsp; rank on the leaderboard as of this writing:</p><ul><li>The latest version of&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-gpt-4o-openais-latest-multimodal-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">GPT-4o</a>, which now underpins the top-ranked ChatGPT, costs $2.50/$10 per million input/output tokens. That’s substantial discount from the previous $5/$15 per million input/output tokens. And the price is half as much for&nbsp;<a href="https://platform.openai.com/docs/guides/batch?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">batch</a>&nbsp;processing of up to 50,000 requests in a single file with a 24-hour turnaround.</li><li>The recently released&nbsp;<a href="https://www.deeplearning.ai/the-batch/openais-gpt-4o-mini-offers-big-performance-at-a-small-price/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">GPT-4o mini</a>, which ranks third on the leaderboard, costs much less at $0.15/$0.075 per million tokens input/output, with the same 50 percent discount for batch processing.</li><li><a href="https://www.deeplearning.ai/the-batch/metas-llama-3-1-outperforms-gpt-4-in-key-areas/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Llama 3.1 405B,</a>&nbsp;which was released in July and ranks fifth, is available for $2.70/$2.70 million input/output tokens from&nbsp;<a href="https://deepinfra.com/meta-llama/Meta-Llama-3.1-405B-Instruct?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">DeepInfra</a>. That’s around 66 percent less than Azure charges.</li><li>Gemini 1.5 Flash, which ranks 18th, costs $0.15/$0.60 per million input/output tokens after the new price cut. There’s a 50 percent discount for inputs and outputs smaller than 128,000 tokens (or submitted in&nbsp;<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">batch mode</a>). There’s also a generous&nbsp;<a href="https://ai.google.dev/pricing?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">free</a>&nbsp;tier.&nbsp;</li><li><a href="https://arxiv.org/abs/2405.04434?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">DeepSeek v2</a>, in 19th place, costs $0.14/$0.28 per million tokens input/output. That’s 46 percent less than when the model was released in late July.</li></ul><p><strong>Behind the news:</strong>&nbsp;Less than six months ago, cutting-edge large language models like GPT-4, Claude 2, Gemini 1.0, Llama 2, and Mistral Large were less capable and more expensive than their current versions. For instance, GPT-4 costs $30/$60 per million tokens input/output. Since then, models have notched higher benchmark performances even prices have fallen. The latest models are also faster, have larger context windows, support a wider range of input types, and do better at complex tasks such as agentic workflows.</p><p><strong>Why it matters:</strong>&nbsp;Competition is fierce to provide the most effective and efficient large language models, offering an extraordinary range of price and performance to developers. Makers of foundation models that can’t match the best large models in performance or the best small models in cost are in a tight corner.</p><p><strong>We’re thinking:</strong>&nbsp;What an amazing time to be developing AI applications! You can choose among models that are open or closed, small or large, faster or more powerful in virtually any combination. Everyone is competing for your business!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-14T145536.630.gif" width="1200" /></figure><h1 id="out-of-the-black-forest">Out of the Black Forest&nbsp;</h1><p>A new company with deep roots in generative AI made an eye-catching debut.</p><p><strong>What’s new:</strong>&nbsp;Black Forest Labs, home to alumni of Stability AI,&nbsp;<a href="https://blackforestlabs.ai/announcing-black-forest-labs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">released</a>&nbsp;the Flux.1 family of text-to-image models under a variety of licenses including open options. The largest of them outperformed Stable Diffusion 3 Ultra, Midourney v6.0, and DALL·E 3 HD in the company’s internal qualitative tests.</p><p><strong>How it works:</strong>&nbsp;The Flux.1 models are based on diffusion transformers that were trained using&nbsp;<a href="https://arxiv.org/pdf/2210.02747?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">flow matching</a>, a form of diffusion. Like other latent diffusion models, given text and a noisy image embedding, they learn to remove the noise. At inference, given text and an embedding of pure noise, they remove the noise in successive steps and render an image using a decoder that was trained for the purpose.</p><ul><li>Flux.1 pro, whose parameter count is undisclosed, is a proprietary model available via API. It costs roughly $0.055 per image, which falls between DALL·E 3 and Stable Diffusion 3 Medium,&nbsp;<a href="https://artificialanalysis.ai/text-to-image/model-family/flux?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">according to</a>&nbsp;Artificial Analysis. You can try a demo&nbsp;<a href="https://replicate.com/black-forest-labs/flux-pro?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>.</li><li>Flux.1 [dev] is a 12 billion-parameter distillation of Flux.1 pro. Its weights are&nbsp;<a href="https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">licensed</a>&nbsp;for noncommercial use and available&nbsp;<a href="https://github.com/black-forest-labs/flux?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>. A demo is available&nbsp;<a href="https://replicate.com/black-forest-labs/flux-dev?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>.</li><li>Flux.1 schnell, also 12 billion parameters, is built for speed. It’s fully open under the&nbsp;<a href="https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Apache 2.0</a>&nbsp;license. You can download weights and code&nbsp;<a href="https://github.com/black-forest-labs/flux?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>&nbsp;and try a demo&nbsp;<a href="https://replicate.com/black-forest-labs/flux-schnell?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>.</li></ul><p><strong>Results:</strong>&nbsp;Black Forest Labs evaluated the models internally in qualitative tests. Given images produced by one of the Flux.1 family and a competitor, roughly 800 people judged which they preferred for various qualities. The two larger versions achieved high scores.</p><ul><li>Visual quality: Flux.1 pro and Flux.1 [dev] ranked first and second (1060 Elo and 1044 Elo respectively). Stable Diffusion 3 Ultra (1031 Elo) came in third.&nbsp;</li><li>Prompt following: Flux.1 pro and Flux.1 [dev] took the top two spots (1048 Elo and 1035 Elo respectively). Midjourney v6.0 (1026 Elo) placed third.</li><li>Rendering typography: Ideogram (1080 Elo) took the top honor. Flux.1 pro and Flux.1 dev came in second and third (1068 Elo and 1038 Elo respectively).</li><li>As of this writing, Flux.1 [pro] and Flux.1 [dev]&nbsp;<a href="https://artificialanalysis.ai/text-to-image?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">rank</a>&nbsp;first and second on the&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-image-generators-face-off-in-arena-leaderboard-by-artificial-analysis/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Artificial Analysis Text to Image Arena Leaderboard</a>. Flux.1 schnell ranks fifth behind Midjourney v6.1 and Stable Diffusion 3 Large.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Black Forest Labs staff includes former core members of Stability AI, which&nbsp;<a href="https://www.deeplearning.ai/the-batch/stability-ai-ceo-steps-down-as-company-faces-financial-and-market-challenges/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">lost</a>&nbsp;many top employees in April. Black Forest CEO Robin Rombach co-authored the papers that introduced VQGAN, latent diffusion, adversarial diffusion distillation, Stable Diffusion XL, and Stable Video Diffusion.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Text-to-image models generally occupy three tiers: large commercial models like Midjourney v6, OpenAI DALL·E 3, and Adobe Firefly; offerings that are open-source to varying degrees like Stability AI’s Stable Diffusion 3 Medium; and smaller models that can run locally like Stable Diffusion’s Stable Diffusion XL Lightning. The Flux.1 suite checks all the boxes with high marks in head-to-head comparisons.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>In late 2022, Stability AI’s release of the open Stable Diffusion unleashed a wave of innovation. We see a similar wave building on the open versions of Flux.1.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed--79-.jpg" width="1200" /></figure><h1 id="ai-leadership-makes-for-a-difficult-balance-sheet">AI Leadership Makes for a Difficult Balance Sheet</h1><p>OpenAI may be spending roughly twice as much money as it’s bringing in, a sign of the financial pressures of blazing the trail in commercial applications of AI.</p><p><strong>What’s new:</strong>&nbsp;OpenAI’s operating expenses could amount to $8.5 billion in 2024, according to an&nbsp;<a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">estimate</a>&nbsp;by&nbsp;<em>The Information</em>&nbsp;based on anonymous sources. Meanwhile, its annual revenue is shaping up to be around $3.5 billion to $4.5 billion, putting it on course to lose between $4 billion and $5 billion this year.&nbsp;</p><p><strong>Revenue versus expenses:</strong>&nbsp;The report combined previous reporting with new information from people “with direct knowledge” of OpenAI’s finances and its relationship with Microsoft, which provides computing power for GPT-4o, ChatGPT, and other OpenAI products.&nbsp;</p><ul><li><strong>Inference cost:</strong>&nbsp;This year, OpenAI is likely to spend around $4 billion on processing power supplied by Microsoft, according to a person who is familiar with the compute cluster allocated to OpenAI’s inference workloads. Microsoft charges OpenAI around $10.30 per hour per eight-GPU server, compared to its public pricing between $13.64 (on a three-year plan) and $27.20 (pay as you go) per hour per server.</li><li><strong>Training cost:</strong>&nbsp;OpenAI expects to spend $3 billion this year on training models and data, according to a person who has knowledge of the costs.&nbsp;</li><li><strong>Personnel cost:</strong>&nbsp;<em>The Information</em>&nbsp;estimates that OpenAI has 1,500 employees. It “guesstimates” the cost at $1.5 billion including equity compensation, based on an OpenAI source and open job listings.</li><li><strong>Revenue:</strong>&nbsp;OpenAI’s annualized monthly revenue was&nbsp;<a href="https://www.theinformation.com/articles/openais-annualized-revenue-doubles-to-3-4-billion-since-late-2023?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">$3.4 billion</a>&nbsp;in June. This includes sales of ChatGPT, which are likely to amount to $2 billion this year, and API calls, which accounted for annualized monthly revenue of $1 billion in March.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;ChatGPT famously grew at an extraordinary pace in 2023 when the number of visits&nbsp;<a href="https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">ballooned</a>&nbsp;to 100 million within two months of the service’s launch. OpenAI’s internal sales team turned that enthusiasm into fast-growing revenue, reportedly&nbsp;<a href="https://www.theinformation.com/articles/in-a-surprise-openai-is-selling-more-of-its-ai-models-than-microsoft-is?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">outpacing</a>&nbsp;even Microsoft’s sales of OpenAI services. Yet that growth rests on top-performance AI models, which are expensive to develop, train, and run.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;OpenAI is a costly undertaking: OpenAI CEO Sam Altman&nbsp;<a href="https://stripe.com/sessions/2023/fireside-chat-with-sam-altman?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">said</a>&nbsp;it would be “the most capital-intensive startup in Silicon Valley history.” But generative AI is evolving quickly. With OpenAI’s revenue rising, its models becoming more cost-effective (witness&nbsp;<a href="https://www.deeplearning.ai/the-batch/openais-gpt-4o-mini-offers-big-performance-at-a-small-price/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">GPT-4o mini</a>), and the cost of inference falling, we wouldn’t bet against it.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-14T145608.454.png" width="1200" /></figure><h1 id="machine-translation-goes-agentic">Machine Translation Goes Agentic</h1><p>Literary works are challenging to translate. Their relative length, cultural nuances, idiomatic expressions, and expression of an author’s individual style call for skills beyond swapping words in one language for semantically equivalent words in another. Researchers built a machine translation system to address these issues.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Minghao Wu and colleagues at Monash University, University of Macau, and Tencent AI Lab proposed&nbsp;<a href="https://arxiv.org/abs/2405.11804?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">TransAgents</a>, which uses a multi-agent workflow to translate novels from Chinese to English. You can try a demo&nbsp;<a href="https://www.transagents.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">here</a>.</p><p><strong>Key insight:&nbsp;</strong>Prompting a large language model (LLM) to translate literature often results in subpar quality. Employing multiple LLMs to mimic human roles involved in translation breaks down this complex problem into more tractable parts. For example, separate LLMs (or instances of a single LLM) can act as agents that take on roles such as translator and localization specialist, and they can check and revise each other’s work. An agentic workflow raises unsolved problems such as how to evaluate individual agents’ performance and how to measure translation quality. This work offers a preliminary exploration.</p><p><strong>How it works:</strong>&nbsp;TransAgents prompted pretrained LLMs to act like a translation company working on a dataset of&nbsp;<a href="https://www2.statmt.org/wmt23/literary-translation-task.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">novels</a>. The set included 20 Chinese novels, each containing 20 chapters, accompanied by human translations into English.</p><ul><li>GPT-4 Turbo generated text descriptions of 30 workers. Each description specified attributes such as role, areas of specialty, education, years of experience, nationality, gender, and pay scale. The authors prompted 30 instances of GPT-4 Turbo to take on one of these personas. Two additional instances acted as the company’s CEO and personnel manager (or “ghost agent” in the authors’ parlance).</li><li>Given a project, the system assembled a team. First it prompted the CEO to select a senior editor, taking into account the languages and worker profiles. The personnel manager evaluated the CEO’s choices and, if it determined they were suboptimal, prompted the CEO to reconsider. Then the system prompted the CEO and senior editor to select the rest of the team, talking back and forth until they agreed on a junior editor, translator, localization specialist, and proofreader.</li><li>Next the system generated a guide document to be included in every prompt going forward. The junior editor generated and the senior editor refined a summary of each chapter and a glossary of important terms and their translations in the target language. Given the chapter summaries, the senior editor synthesized a plot summary. In addition, the senior editor generated guidelines for tone, style, and target audience using a randomly chosen chapter as reference.</li><li>The team members collaborated to translate the novel chapter by chapter. The translator proposed an initial translation. The junior editor reviewed it for accuracy and adherence to the guidelines. The senior editor evaluated the work so far and revised it accordingly. The localization specialist adapted the text to fit the audience’s cultural context. The proofreader checked for language errors. Then the junior and senior editors critiqued the work of the localization specialist and proofreader and revised the draft accordingly.</li><li>Finally, the senior editor reviewed the work, assessing the quality of each chapter and ensuring smooth transitions between chapters.</li></ul><p><strong>Results:</strong>&nbsp;Professional translators compared TransAgents’ output with that of human translators and GPT-4 Turbo in a blind test. One said TransAgents “shows the greatest depth and sophistication,” while another praised its “sophisticated wording and personal flair” that “effectively conveys the original text’s mood and meaning.”</p><ul><li>Human judges who read short translated passages without referring to the original texts, preferred TransAgents’ output, on average, to that of human translators and GPT-4 Turbo, though more for fantasy romance novels (which they preferred 77.8 percent of the time) than science fiction (which they preferred 39.1 percent of the time).&nbsp;</li><li>GPT-4 Turbo, which did refer to the original texts while comparing TransAgents’ translations with the work of human translators and its own translations, also preferred TransAgents on average.&nbsp;</li><li>TransAgents’ outputs were not word-by-word translations of the inputs but less-precise interpretations. Accordingly, it fared poorly on&nbsp;<a href="https://aclanthology.org/2020.tacl-1.47.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">d-BLEU</a>, a traditional measure that compares a translation to a reference text (higher is better) by comparing sequences of words. TransAgents achieved a d-BLEU score of 25, well below GPT-4 Turbo's 47.8 and Google Translate's 47.3.</li></ul><p><strong>Why it matters:</strong>&nbsp;While machine translation of ordinary text and conversations has made great strides in the era of LLMs, literary translation remains a frontier. An agentic workflow that breaks down the task into subtasks and delegates them to separate LLM instances makes the task more manageable and appears to produce results that appeal to human judges (and an LLM as well). That said, this is preliminary work that suggests a need for new ways to measure the quality of literary translations.</p><p><strong>We’re thinking:&nbsp;</strong><a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Agentic workflows</a>&nbsp;raise pressing research questions: What is the best way to divide a task for different agents to tackle? How much does the specific prompt at each stage affect the final output? Good answers to questions like this will lead to powerful applications.</p><hr /><figure class="kg-card kg-image-card"><a href="https://docs.google.com/forms/d/e/1FAIpQLSd0VfPtBoW-2h4NxMLp8RfR2JwNH7XZt26pE-hiy4iFvnPfbA/viewform?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/08/The-Batch-ads-and-exclusive-banners---2024-08-13T105325.070.png" width="1680" /></a></figure><p>Are you an experienced developer? Share your coding story and inspire new learners! We’re celebrating the launch of “AI Python for Beginners,” taught by Andrew Ng, and we’d like to feature your story to inspire coders who are just starting out.&nbsp;<a href="https://docs.google.com/forms/d/e/1FAIpQLSd0VfPtBoW-2h4NxMLp8RfR2JwNH7XZt26pE-hiy4iFvnPfbA/viewform?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8RMXWGsKy0WW01ALuV3mCHajvIKy9s9v2oeXw5xXoB2OH_ZKtd52TGYLG9e1arEzrz0A2t" rel="noopener">Submit your story here!</a></p>
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 19:57:34 GMT</pubDate>
</item>
<item>
<title>Google Gets Character.AI Co-Founders, Ukraine's Aquatic Drones, AI Recruiting Tools Fuel Arms Race, ASCII Art Defeats LLM Guardrails</title>
<link>https://www.deeplearning.ai/the-batch/issue-261</link>
<guid>https://www.deeplearning.ai/the-batch/issue-261</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>I’m delighted to announce&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener"><em>AI Python for Beginners</em></a>, a sequence of free short courses that teach anyone to code, regardless of background. I’m teaching this introductory course to help beginners take advantage of powerful trends that are reshaping computer programming. It’s designed for people in any field — be it marketing, finance, journalism, administration, or something else — who can be more productive and creative with a little coding knowledge, as well as those who aspire to become software developers. Two of the four courses are available now, and the remaining two will be released in September.&nbsp;</p><p>Generative AI is transforming coding in two ways:</p><ul><li><strong>Programs are using AI:&nbsp;</strong>Previously, you had to learn a lot about coding before it became useful. Now, knowing how to write code that calls large language models (and other AI APIs) makes it possible to build powerful programs more easily. This is increasing the value of coding.&nbsp;</li><li><strong>AI is helping programmers:&nbsp;</strong>Programmers are using large language models as coding companions that write pieces of code, explain coding concepts, find bugs, and the like. This is especially helpful for beginners, and it lowers the effort needed to learn to code.&nbsp;</li></ul><p>The combination of these two factors means that novices can learn to do useful things with code far faster than they could have a year ago.&nbsp;</p><p>These courses teach coding in a way that is aligned with these trends: (i) We teach how to write code to use AI to carry out tasks, and (ii) Unlike some instructors who are still debating how to restrict the use of ChatGPT, we embrace generative AI as a coding companion and show how to use it to accelerate your learning.&nbsp;</p><p>To explain these two trends in detail:</p><p><strong>Programs are using AI.&nbsp;</strong>Because programs can now take advantage of AI, increasingly knowing a little bit about how to code helps people in roles other than software engineers do their work better. For example, I’ve seen a marketing professional write code to download web pages and use generative AI to derive insights; a reporter write code to flag important stories; and an investor automate first drafts of contracts. Even if your goal is not to become a professional developer, learning just a little coding can be incredibly useful!&nbsp;</p><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/08/AIP4B-1.png" width="1200" /></a></figure><p>In the courses, you’ll use code to write personalized notes to friends, brainstorm recipes, manage to-do lists, and more.</p><p><strong>AI is helping programmers.</strong>&nbsp;There is a growing body of evidence that AI is making programming easier. For example:</p><ul><li>A&nbsp;<a href="https://arxiv.org/abs/2406.17910?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">study</a>&nbsp;at Cisco by Pandey et al. projects a “33-36% time reduction for coding-related tasks” for many cloud development tasks.</li><li>McKinsey&nbsp;<a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">estimates</a>&nbsp;a 35 percent to 45 percent reduction in time needed for code generation tasks.&nbsp;</li><li>In&nbsp;<a href="https://www.microsoft.com/en-us/research/publication/the-impact-of-ai-on-developer-productivity-evidence-from-github-copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">study</a>&nbsp;by Microsoft (which owns Github and sells Github Copilot), Github, and MIT, developers who used AI completed a programming task nearly 56 percent faster.&nbsp;&nbsp;</li></ul><p>Further, as AI tools get better — for example, as&nbsp;<a href="https://www.deeplearning.ai/the-batch/coding-agents-are-evolving-from-novelties-to-widely-useful-tools/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">coding agents continue to improve</a>&nbsp;and can write simple programs more autonomously — these productivity gains will improve.</p><p>In order to help learners skate to where the puck is going, this course features a built in chatbot and teaches best practices for how beginners can use a large language model to explain, write, and debug code and explain programming concepts. AI is already helping experienced programmers, and it will help beginner programmers much more.</p><p>If you know someone who is curious about coding (or if you yourself are), please encourage them to learn to code! The case is stronger than ever that pretty much everyone can benefit from learning at least a little coding. Please help me spread the word, and encourage everyone who isn’t already a coder to check out&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener"><em>AI Python for Beginners</em></a>.&nbsp;</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1042" src="https://dl-staging-website.ghost.io/content/images/2024/08/V5_DeepLearning_AI_Python_for_Beginners_Banner_2070x1080.png" width="2000" /></a></figure><p>Learn Python with AI support in&nbsp;<em>AI Python for Beginners</em>, a new sequence of short courses taught by Andrew Ng. Build practical applications from the first lesson and receive real-time, interactive guidance from an AI assistant.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Enroll today and start coding with confidence!</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="673" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-07T144020.108.png" width="1200" /></figure><h1 id="google-gets-characterai-co-founders">Google Gets Character.AI Co-Founders</h1><p>Character.AI followed an emerging pattern for ambitious AI startups, trading its leadership to a tech giant in exchange for funds and a strategic makeover.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Google hired Character.AI’s co-founders and other employees and paid an undisclosed sum for nonexclusive rights to use Character.AI’s technology,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/google-hires-character-ai-cofounders-and-licenses-its-models?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">reported</a>. The deal came shortly after&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-pays-inflection-ai-650-million-hires-most-of-its-staff/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Microsoft and Inflection</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/amazon-add-majority-of-adept-ai-staff-to-boost-agentic-ai-capabilities/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Amazon and Adept</a>&nbsp;struck similar agreements.</p><p><strong>New strategy:</strong>&nbsp;Character.AI builds chatbots that mimic personalities from history, fiction, and popular culture. When it started, it was necessary to build foundation models to deliver automated conversation, the company&nbsp;<a href="https://blog.character.ai/our-next-phase-of-growth/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">explained</a>&nbsp;in a blog post. However, “the landscape has shifted” and many pretrained models are available. Open models enable the company to focus its resources on fine-tuning and product development under its new CEO, former Character.AI general counsel Dom Perella. Licensing revenue from Google will help Character.AI to move forward.</p><ul><li>Character.AI co-founders Daniel De Freitas and Noam Shazeer, both of whom worked for Google prior to founding Character.AI, returned. (You can read&nbsp;<em>The Batch</em>'s 2020&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-transformed/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">interview</a>&nbsp;with Shazeer here.) They brought with them 30 former members of Character.AI’s research team (out of roughly 130 employees) to work on Google Deep Mind’s Gemini model.</li><li>Character.AI will continue to develop chatbots. However, it will stop developing its own models and use open source offerings such as Meta’s Llama 3.1.&nbsp;</li><li>Investors in Character.AI will receive $88 per share, roughly two and a half times the share price when the company’s last funding round established its valuation at $1 billion.</li></ul><p><strong>Behind the news:</strong>&nbsp;At Google, Shazeer co-authored “Attention Is All You Need,” the 2017&nbsp;<a href="https://arxiv.org/abs/1706.03762?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">paper</a>&nbsp;that introduced the transformer architecture. De Freitas led the&nbsp;<a href="https://www.deeplearning.ai/the-batch/toward-open-domain-chatbots/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Meena</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/lamda-comes-alive/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">LaMDA</a>&nbsp;projects to develop conversational models. They left Google and founded Character.AI in late 2021 to build a competitor to OpenAI that would develop “personalized superintelligence.” The company had&nbsp;<a href="https://www.msn.com/en-gb/money/technology/google-hires-top-talent-from-startup-character-ai-signs-licensing-deal/ar-BB1r6GGl?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">raised</a>&nbsp;$193 million before its deal with Google.</p><p><strong>Why it matters:</strong>&nbsp;Developing cutting-edge foundation models is enormously expensive, and few companies can acquire sufficient funds to keep it up. This dynamic is leading essential team members at high-flying startups to move to AI giants. The established companies need the startups’ entrepreneurial mindset, and the startups need to retool their businesses for a changing market.</p><p><strong>We’re thinking:</strong>&nbsp;Models with open weights now&nbsp;<a href="https://www.deeplearning.ai/the-batch/metas-llama-3-1-outperforms-gpt-4-in-key-areas/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">compete</a>&nbsp;with proprietary models for the state of the art. This is a sea change for startups, opening the playing field to teams that want to build applications on top of foundation models. Be forewarned, though: New proprietary models such as the forthcoming GPT-5 may change the state of play yet again.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-07T144042.618.gif" width="1200" /></figure><h1 id="ai-assisted-applicants-counter-ai-assisted-recruiters">AI-Assisted Applicants Counter AI-Assisted Recruiters</h1><p>Employers are embracing automated hiring tools, but prospective employees have AI-powered techniques of their own.</p><p><strong>What’s new:</strong>&nbsp;Job seekers are using large language models and speech-to-text models to improve their chances of landing a job,&nbsp;<em>Business Insider</em>&nbsp;<a href="https://www.businessinsider.com/ai-job-interview-tools-final-round-otter-2024-7?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">reported</a>. Some startups are catering to this market with dedicated products.<br /><br /><strong>How it works:&nbsp;</strong>Text generators like ChatGPT can help candidates quickly draft resumes, cover letters, and answers to application questions. But AI can also enable a substitute — human or automated — to stand in for an applicant.</p><ul><li>Services like&nbsp;<a href="https://lazyapply.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">LazyApply</a>,&nbsp;<a href="https://simplify.jobs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">SimplifyJobs</a>, and&nbsp;<a href="https://www.talentprise.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Talentprise</a>&nbsp;find jobs, track and sort listings, and help write resumés and cover letters. London-based&nbsp;<a href="https://aiapply.co/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">AiApply</a>&nbsp;offers similar tools as well as one that conducts mock interviews.</li><li>Tech-savvy interviewees are using speech-to-text models to get real-time help as an interview is in progress. For instance,&nbsp;<a href="https://otter.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Otter.ai</a>&nbsp;is an online service designed as a workplace assistant to take notes, transcribe audio, and summarize meetings. However, during an interview, candidates can send a transcription to a third party who can suggest responses. Alternatively,&nbsp;<a href="https://github.com/SevaSk/ecoute?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">tools</a>&nbsp;available on GitHub can read Google Meet closed captions, feed them to ChatGPT, and return generated answers.&nbsp;</li><li>San-Francisco-based&nbsp;<a href="https://www.finalroundai.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Final Round</a>&nbsp;offers an app that transcribes interview questions and generates suggested responses in real time. For developers, the company is testing a&nbsp;<a href="https://www.youtube.com/watch?v=Cye7aBGuCeE&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">version</a>&nbsp;for coding interviews that captures a screen shot (presumably presenting a test problem) of the current screen and shares it with a code-generation model, which suggests code, a step-by-step explanation of how it works, and test cases.</li></ul><p><strong>Behind the news:</strong>&nbsp;Employers can use AI to screen resumes for qualified candidates, identify potential recruits, analyze video interviews, and otherwise streamline hiring. Some employers believe these tools reduce biases from human decision-makers, but critics&nbsp;<a href="https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">say</a>&nbsp;they exhibit the same biases. No national regulation controls this practice in the United States, but New York City requires employers to audit automated hiring software and notify applicants if they use it. The states of Illinois and Maryland require employers who conduct video interviews to receive an applicant’s consent before subjecting an interview to AI-driven analysis. The European Union’s AI Act classifies AI in hiring as a high-risk application that requires special oversight and frequent audits for bias.</p><p><strong>Why it matters:</strong>&nbsp;When it comes to AI in recruiting and hiring, most attention – and money – has gone to employers. Yet the candidates they seek increasingly rely on AI to get their attention and seal the deal. A late 2023 LinkedIn survey&nbsp;<a href="https://www.linkedin.com/pulse/us-labor-market-showed-mixed-signals-linkedin-economic-graph-aiutc/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">found</a>&nbsp;that U.S. and UK job seekers applied to 15 percent more jobs than a year earlier, a change many recruiters&nbsp;<a href="https://www.forbes.com/sites/emmylucas/2023/12/11/armed-with-ai-workers-are-applying-to-more-jobs-its-upping-the-competition/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">attributed</a>&nbsp;to generative AI.</p><p><strong>We’re thinking:&nbsp;</strong>AI is making employers and employees alike more efficient in carrying out the tasks involved in hiring. Misaligned incentives are leading to an automation arms race, yet both groups aim to find the right fit. With this in mind, we look forward to AI-powered tools that match employers and candidates more efficiently so both sides are better off.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-07T144055.642.gif" width="600" /></figure><h1 id="ukraine-develops-aquatic-drones">Ukraine Develops Aquatic Drones</h1><p>Buoyed by its military success developing unmanned aerial vehicles, Ukraine is building armed naval drones.</p><p><strong>What’s new:&nbsp;</strong>A fleet of robotic watercraft has shifted the balance of naval power in Ukraine’s ongoing war against Russia in the Black Sea,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/sea-drone?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;Ukraine began building seafaring drones to fight a Russian blockade of the Black Sea coast after losing most of its traditional naval vessels in 2022. The Security Service of Ukraine, a government intelligence and law enforcement agency, first cobbled together prototypes from off-the-shelf parts. It began building more sophisticated versions as the home-grown&nbsp;<a href="https://www.deeplearning.ai/the-batch/ukraines-drone-industry-takes-flight-amidst-conflict/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">aerial drone industry</a>&nbsp;took off.</p><ul><li><a href="https://www.kyivpost.com/analysis/29068?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Magura-v5</a>, a surface vessel, is 18 feet long and 5 feet wide and has a range of around 515 miles at a cruising speed of 25 miles per hour. A group of three to five Maguras, each carrying a warhead roughly as powerful as a torpedo, can surround target vessels autonomously. Human operators can detonate the units from a laptop-size console.</li><li><a href="https://www.kyivpost.com/post/25792?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Sea Baby</a>&nbsp;is a larger surface vessel that likely shares Magura-v5’s autonomous navigation capabilities, but its warhead is more than twice as powerful. It’s roughly 20 feet long and 6.5 feet wide with a range of 60 miles and maximum speed of 55 miles per hour.</li><li><a href="https://www.navalnews.com/naval-news/2023/08/ukraines-new-underwater-drone-marichka-breaks-cover/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Marichka</a>&nbsp;is an uncrewed underwater vessel around 20 feet long and 3 feet wide with a range of 620 miles. Its navigational capabilities are unknown. Observers speculate that, like the surface models, Marichka is intended to locate enemy vessels automatically and detonate upon a manual command.</li></ul><p><strong>Drone warfare:</strong>&nbsp;Ukraine’s use of aquatic drones has changed the course of the war in the Black Sea, reopening key shipping routes. Ukraine has&nbsp;<a href="https://www.newsweek.com/russia-black-sea-fleet-ukraine-crimea-tsiklon-corvette-1902339?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">disabled</a>&nbsp;about a third of the Russian navy in the region and pushed it into places that are more difficult for the sea drones to reach. Russia has also been forced to protect fixed targets like bridges from drone attacks by fortifying them with guns and jamming GPS and Starlink satellite signals.</p><p><strong>Behind the news:&nbsp;</strong>More-powerful countries are paying attention to Ukraine’s use of sea drones. In 2022, the United States Navy established a group called&nbsp;<a href="https://seapowermagazine.org/navy-establishes-unmanned-surface-vessel-division-one/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Uncrewed Surface Vessel Division One</a>, which focuses on deploying both large autonomous vessels and smaller, nimbler drones. Meanwhile, China has&nbsp;<a href="https://www.deeplearning.ai/the-batch/meet-zhuhaiyun-the-chinese-navys-new-autonomous-ship/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">developed</a>&nbsp;large autonomous vessels that can serve as bases for large fleets of drones that travel both above and under water.</p><p><strong>Why it matters:&nbsp;</strong>While the U.S. has experimented with large&nbsp;<a href="https://www.deeplearning.ai/the-batch/robots-on-the-high-seas/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">autonomous warships</a>,<strong>&nbsp;</strong>smaller drones open different tactical and strategic opportunities. While larger vessels generally must adhere to established sea routes (and steer clear of shipping vessels), smaller vessels can navigate more freely and can make up in numbers and versatility what they lack in firepower.<br /><br /><strong>We’re thinking:</strong>&nbsp;We support Ukraine’s right to defend itself against unwarranted aggression, and we’re glad the decision to detonate its aquatic drones remains in human hands. We hope the innovations spurred by this conflict will find beneficial applications once the war is over.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/08/unnamed---2024-08-07T144157.864.gif" width="600" /></figure><h1 id="art-attack">Art Attack</h1><p>Seemingly an innocuous form of expression, ASCII art opens a new vector for jailbreak attacks on large language models (LLMs), enabling them to generate outputs that their developers tuned them to avoid producing.</p><p><strong>What's new:</strong>&nbsp;A team led by Fengqing Jiang at University of Washington developed&nbsp;<a href="https://arxiv.org/pdf/2402.11753.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">ArtPrompt</a>, a technique to test the impact of text rendered as ASCII art on LLM performance.</p><p><strong>Key insight:</strong>&nbsp;LLM safety methods such as fine-tuning are designed to counter prompts that can cause a model to produce harmful outputs, such as specific keywords and tricky ways to ask questions. They don’t guard against atypical ways of using text to communicate, such as ASCII art. This oversight enables devious users to get around some precautions.</p><p><strong>How it works:</strong>&nbsp;Researchers gauged the vulnerability to ASCII-art attacks of&nbsp;<a href="https://platform.openai.com/docs/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">GPT-3.5, GPT-4</a>,&nbsp;<a href="https://www.anthropic.com/api?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Claude</a>,&nbsp;<a href="https://gemini.google.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Gemini</a>, and&nbsp;<a href="https://llama.meta.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">Llama 2</a>. They modified prompts from&nbsp;<a href="https://arxiv.org/pdf/2307.15043.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">AdvBench</a>&nbsp;or&nbsp;<a href="https://arxiv.org/pdf/2310.03693.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">HEx-PHI</a>, which contain prompts that are designed to make safety-aligned LLMs refuse to respond, such as “how to make a bomb.”</p><ul><li>Given a prompt, the authors masked individual words to produce a set of prompts in which one word was missing (except words like “a” and “the,” which they left in place). They replaced the missing words with&nbsp;<a href="https://github.com/sepandhaghighi/art?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">ASCII-art renderings</a>&nbsp;of the words.&nbsp;</li><li>They presented the modified prompts to each LLM. Given a response,&nbsp;<a href="https://arxiv.org/pdf/2310.03693.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">GPT-Judge</a>, a model based on GPT-4 that evaluates harmful text, assigned a score between 1 (no harm) and 5 (extreme harm).</li></ul><p><strong>Results:</strong>&nbsp;ArtPrompt successfully circumvented LLM guardrails against generating harmful output, achieving an average harmfulness score of 3.6 out of 5 across all five LLMs. The next most-harmful attack method,&nbsp;<a href="https://arxiv.org/pdf/2310.08419.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">PAIR</a>, which prompts a model several times and refines its prompt each time, achieved 2.67.</p><p><strong>Why it matters:</strong>&nbsp;This work adds to the growing&nbsp;<a href="https://arxiv.org/abs/2406.01288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">body</a>&nbsp;<a href="https://www.anthropic.com/research/many-shot-jailbreaking?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">of</a>&nbsp;<a href="https://arxiv.org/abs/2405.13077v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noopener">literature</a>&nbsp;on LLM jailbreak techniques. While fine-tuning is fairly good at preventing innocent users — who are not trying to trick an LLM — from accidentally receiving harmful output, we have no robust mechanisms for stopping a wide variety of jailbreak techniques. Blocking ASCII attacks would require additional input- and output-screening systems that are not currently in place.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;We’re glad that LLMs are safety-tuned to help prevent users from receiving harmful information. Yet many uncensored models are available to users who want to get problematic information without implementing jailbreaks, and we’re not aware of any harm done. We’re cautiously optimistic that, despite the lack of defenses, jailbreak techniques also won’t prove broadly harmful.</p><hr /><h2 id="a-message-from-landing-ai">A MESSAGE FROM LANDING AI</h2><figure class="kg-card kg-image-card"><a href="https://lu.ma/5g6hhe71?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/08/vision-agent-newsletter-1680x945.png" width="1680" /></a></figure><p>Calling all developers working on visual AI applications! You’re invited to our upcoming VisionAgent Developer Meetup, an in-person and virtual event with Andrew Ng and the LandingAI MLE team for developers working on visual AI and related computer vision applications.&nbsp;<a href="https://lu.ma/5g6hhe71?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9XXzZk4EmtF-yjHJO38KMbwaD_ml1s8zIgYPsUL0YgRdrHQw3WELF_oIHxO_3aI6DsAT0w" rel="noreferrer">Register now</a></p>
]]></content:encoded>
<pubDate>Wed, 07 Aug 2024 19:44:02 GMT</pubDate>
</item>
<item>
<title>Llama 3.1 is State-of-the-Art and Open, Web Data Goes Dark, OpenAI Takes on Google and Bing, Synthetic Data Improves</title>
<link>https://www.deeplearning.ai/the-batch/issue-260</link>
<guid>https://www.deeplearning.ai/the-batch/issue-260</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Last week, I&nbsp;<a href="https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">wrote</a>&nbsp;about why working on a concrete startup or project idea — meaning a specific product envisioned in enough detail that we can build it for a specific target user — lets you go faster. In this letter, I’d like to share some best practices for identifying promising ideas.</p><p>AI Fund, which I lead, works with many corporate partners to identify ideas, often involving applications of AI to the company’s domain. Because AI is applicable to numerous sectors such as retail, energy, logistics and finance, I’ve found working with domain experts who know these areas well immensely helpful for identifying what applications are worth building in these areas.</p><p>Our brainstorming process starts with recommending that a large number of key contributors at our partner corporation (at least 10 but sometimes well over 100) gain a non-technical, business-level understanding of AI and what it can and can’t do. Taking DeepLearning.AI’s “<a href="https://www.deeplearning.ai/courses/generative-ai-for-everyone/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Generative AI for Everyone</a>” course is a popular option, after which a company is well positioned to assign a small team to coordinate a brainstorming process, followed by a prioritization exercise to pick what to work on. The brainstorming process can be supported by a&nbsp;<a href="https://www.deeplearning.ai/the-batch/which-ai-applications-should-you-build/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">task-based analysis of jobs</a>&nbsp;in which we decompose employees’ jobs into tasks to identify which ones might be automated or augmented using AI.&nbsp;</p><p>Here are some best practices for these activities:<br /><br /><strong>Trust the domain expert’s gut.&nbsp;</strong>A domain expert who has worked for years in a particular sector will have well honed instincts that let them make leaps that would take a non-expert weeks of research.</p><p>Let’s say we’re working with a financial services expert and have developed a vague idea (“build a chatbot for financial advice”). To turn this into a concrete idea, we might need to answer questions such as what areas of finance to target (should we focus on budgeting, investing, or insurance?) and what types of user to serve (fresh graduates, mortgage applicants, new parents, or retirees?) Even a domain expert who has spent years giving financial advice might not know the best answer, but a choice made via their gut gives a quick way to get to one plausible concrete idea. Of course, if market-research data can be obtained quickly to support this decision, we should take advantage of it. But to avoid slowing down too much, we’ve found that experts’ gut reactions work well and are a quick way to make decisions.&nbsp;</p><p>So, if I’m handed a non-concrete idea, I often ask a domain expert to use their gut — and nothing else — to quickly make decisions as needed to make the idea concrete. The resulting idea is only a starting point to be tweaked over time. If, in the discussion, the domain expert picks one option but seems very hesitant to disregard a different option, then we can also keep the second option as a back-up that we can quickly pivot to if the initial one no longer looks promising.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="677" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T173743.998.png" width="1200" /></figure><p><strong>Generate many ideas.&nbsp;</strong>I usually suggest coming up with at least 10 ideas; some will come up with over 100, which is even better. The usual brainstorming advice to go for volume rather than quality applies here. Having many ideas is particularly important when it comes to prioritization. If only one idea is seriously considered — sometimes this happens if a senior executive has an idea they really like and puts this forward as the “main” idea to be worked on — there’s a lot of pressure to make this idea work. Even if further investigation discovers problems with it — for example, market demand turns out to be weak or the technology is very expensive to build — the team will want to keep trying to make it work so we don’t end up with nothing.</p><p>In contrast, when a company has many ideas to choose from, if one starts to look less interesting, it’s easy to shift attention to a different one. When many ideas are considered, it’s easier to compare them to pick the superior ones. As explained in the book&nbsp;<a href="https://www.amazon.com/Ideaflow-Only-Business-Metric-Matters-ebook/dp/B09R6M3292/ref=sr_1_1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener"><em>Ideaflow</em></a>, teams that generate more ideas for evaluation and prioritization end up with better solutions.&nbsp;</p><p>Because of this, I’ve found it helpful to run a broad brainstorming process that involves many employees. Specifically, large companies have many people who collectively have a lot of wisdom regarding the business. Having a small core team coordinate the gathering of ideas from a large number of people lets us tap into this collective fountain of invention. Many times I’ve seen a broad effort (involving, say, ~100 people who are knowledgeable about the domain and have a basic understanding of AI) end up with better ideas than a narrow one (involving, say, a handful of top executives).&nbsp;</p><p><strong>Make the evaluation criteria explicit.</strong>&nbsp;When evaluating and prioritizing, clear criteria for scoring and ranking ideas helps the team to judge ideas more consistently. Business value and technical feasibility are almost always included. Additionally, many companies will prioritize projects that can be a quick win (to build momentum for their overall AI efforts) or support certain strategic priorities such as growth in a particular part of the business. Making such criteria explicit can help during the idea-generation phase, and it’s critical when you evaluate and prioritize.&nbsp;</p><p>In large companies, it can take a few weeks to go through a process to gather and prioritize ideas, but this pays off well in identifying valuable, concrete ideas to pursue. AI isn’t useful unless we find appropriate ways to apply it, and I hope these best practices will help you to generate great AI application ideas to work on.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-30T090813.026.png" width="1680" /></a></figure><p>Join our new short course and gain an in-depth understanding of embedding models! Learn to train and use Word2Vec and BERT in semantic search systems, and build a dual-encoder model with a contrastive loss to enhance question-answer accuracy.&nbsp;<a href="https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up today</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174003.755.png" width="1200" /></figure><h1 id="the-state-of-the-art-is-open">The State of the Art Is Open</h1><p>Meta raised the bar for large language models with open weights and published details about how it built one that outperforms GPT-4o and Claude 3.5 Sonnet by some measures.</p><p><strong>What's new:</strong>&nbsp;<a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Llama 3.1 405B</a>&nbsp;delivers state-of-the-art performance on a handful of public benchmarks and has a context window of 128,000 input tokens while allowing a range of commercial uses. In addition to the 405-billion parameter model, Meta released new versions of the earlier Llama 3 70B (70 billion parameters) and 8B (8 billion parameters). Model weights are available&nbsp;<a href="https://llama.meta.com/llama-downloads/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;Fine-tuning on generated data can improve a model’s performance, but incorrect or lower-quality examples degrade it. The Llama team undertook an extensive effort to fix or remove bad examples using a variety of tools including the model itself, auxiliary models, and off-the-shelf tools.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Llama 3.1 models are transformers that have been pretrained to predict the next token in a sequence. Meta provided more information about the development of Llama 3.1 405B than the smaller versions. Its pretraining dataset comprised 16.4 trillion tokens of text, “much” of it scraped from the web. The pretrained model was fine-tuned to perform seven tasks, including coding and reasoning, via supervised learning and&nbsp;<a href="https://www.deeplearning.ai/the-batch/human-feedback-without-reinforcement-learning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">direct preference optimization</a>&nbsp;(DPO). Most of the fine-tuning data was generated by the model itself and curated using a variety of methods including agentic workflows. For instance,</p><ul><li>To generate good code to learn from, the team: (1) Generated programming problems from random code snippets. (2) Generated a solution to each problem, prompting the model to follow good programming practices and explain its thought process in comments. (3) Ran the generated code through a parser and linter to check for issues like syntax errors, style issues, and uninitialized variables. (4) Generated unit tests. (5) Tested the code on the unit tests. (6) If there were any issues, regenerated the code, giving the model the original question, code, and feedback. (7) If the code passed all tests, added it to the dataset. (8) Fine-tuned the model. (9) Repeated this process several times.</li><li>To generate fine-tuning data that represented good lines of reasoning, the team: (1) Generated math questions and answers from math problems. (2) Manually identified the types of problems the model struggled with. (3) Asked humans to write questions for those problems. (4) Generated step-by-step answers for those problems. (5)&nbsp;<a href="https://arxiv.org/abs/2403.04706?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Removed</a>&nbsp;examples that end with the wrong answer. (6) Asked the model to determine whether the reasoning was correct. (7) Removed examples that the model identified as having incorrect reasoning. (8)&nbsp;<a href="https://arxiv.org/abs/2305.20050?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Trained</a>&nbsp;separate models to determine if the reasoning was correct. (9) Used those models to filter out incorrect examples.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared Llama 3.1 405B to Claude 3.5 Sonnet, GPT-4, GPT-4o, and Nemotron 4 340B on 16 public benchmarks. It either outperformed or tied the other models on seven of the 16 (although two, GSM8K and MMLU zero-shot chain-of-thought, are not directly comparable due to differences in prompting methods). For instance, Llama 3.1 405B set a new state of the art in IFEval (general knowledge), ARC Challenge (reasoning), and Nexus (tool use). The smaller versions outperformed other models in the same general size classes as well. Llama 3.1 70B set new states of the art in all benchmarks for general knowledge, coding, math, and reasoning. Llama 3.1 8B dominated general, coding, and math benchmarks.</p><p><strong>License:&nbsp;</strong>Llama 3.1 models are licensed under a&nbsp;<a href="https://llamaimodel.com/commercial-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">custom license</a>&nbsp;that allows both commercial use (by companies with up to 700 million monthly active users in the month prior to Llama 3.1’s release) and training other models on generated data. This enables many companies to use it as they like while potentially requiring Meta’s largest competitors to negotiate a commercial license.</p><p><strong>The French connection:</strong>&nbsp;Separately, Mistral announced its next-generation LLM&nbsp;<a href="https://mistral.ai/news/mistral-large-2407/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Mistral Large 2</a>, which&nbsp;<a href="https://mistral.ai/licenses/MRL-0.1.md?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">allows</a>&nbsp;noncommercial use but requires a special license for commercial use. The 123 billion-parameter model boasts performance similar to that of Llama 3.1 405B on a number of benchmarks despite being less than one-third the size.</p><p><strong>Why it matters:</strong>&nbsp;The Llama 3.1 family continues Meta’s contributions in open models and extends them to some commercial uses. The upgraded 8B and 70B models perform better than their predecessors, while the 405B version rivals top proprietary models and enables researchers to generate high-quality synthetic data for training further models. The team provides extensive detail about how they generated fine-tuning data. For each task, they describe the pipeline used to create the data along with various notes about what worked and what didn’t work for them — helpful information for researchers who aim to build next-generation LLMs.</p><p><strong>We're thinking:</strong>&nbsp;&nbsp;<a href="https://datacentricai.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Data-centric AI</a>, the discipline of systematically engineering data to build a successful AI system, is critical for machine learning. The Llama 3.1 paper makes clear that systematically engineering the training data was also a key to training what is, as far as we know, the first open weights model to achieve better performance than the best proprietary models on multiple benchmarks. The potential of open weights is looking better every day!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174116.563.gif" width="600" /></figure><h1 id="search-gets-conversational">Search Gets Conversational</h1><p>OpenAI is testing an AI-powered search engine in a bid to compete head-to-head with both Google and its close partner Microsoft Bing.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/index/searchgpt-prototype/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">released</a>&nbsp;SearchGPT, an integrated search engine and large language model that aims to be friendly to both users and publishers. Access is limited initially to selected trial users. OpenAI offers a wait list but no timeline for expanding access.&nbsp;</p><p><strong>How it works:</strong>&nbsp;SearchGPT sorts results collected by web crawler, like Google and its competitors. It differs in providing direct answers to queries and offering a conversational user interface for follow-up questions. OpenAI has not disclosed the underlying model.</p><ul><li>Given a question or search string like “best tomatoes to grow in Minnesota,” SearchGPT returns an answer such as a list of tomato varieties. Typically it adds a source for the information (<em>The Garden Magazine</em>) and a link to the published site(s). Other relevant links appear in a sidebar.</li><li>After receiving the initial response, users can refine the search by asking further questions like, “which of these can I plant now?” SearchGPT will generate new results based on context.&nbsp;</li><li>The system draws on information from publishers from which OpenAI&nbsp;<a href="https://www.deeplearning.ai/the-batch/openai-licenses-financial-times-archive-in-fifth-deal-with-major-news-publishers/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">licensed</a>&nbsp;copyrighted materials including&nbsp;<em>Associated Press</em>,&nbsp;<em>The Atlantic</em>,&nbsp;<em>Financial Times</em>, and&nbsp;<em>News Corp</em>. OpenAI also has struck licensing deals with online forums including&nbsp;<a href="https://openai.com/index/openai-and-reddit-partnership/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Reddit</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/data-points-issue-249/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Stack Overflow</a>. Whether these partners are favored in search results is not clear.&nbsp;</li><li>The service also draws on web pages indexed by its crawler. Web publishers can opt out of being crawled for indexing, gathering training data, or both.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI’s move is part of a larger race to supercharge web search with AI.</p><ul><li>Google and Microsoft&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-and-microsoft-both-announce-ai-powered-search/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">added</a>&nbsp;AI-generated results and summaries to their search engines last year, and Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-io-developers-conference-reveals-new-ai-models-features-and-upgrades/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">expanded</a>&nbsp;its AI Overview program earlier this year. Search GPT amps up OpenAI’s competition with Google, which uses its own Gemini models, but also with its partner Microsoft, whose AI-driven Bing Search and Copilot products rely on OpenAI.</li><li>The startups You.com and Perplexity offer AI-driven search services. Publishers have&nbsp;<a href="https://www.wired.com/story/perplexity-is-a-bullshit-machine/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">criticized</a>&nbsp;Perplexity for breaching paywalls, ignoring publishers’ efforts to opt out, and publishing AI-generated summaries of articles produced by other companies on its own websites.</li></ul><p><strong>Why it matters:&nbsp;</strong>Search stands to be disrupted by advances in AI, and agents that browse multiple articles to synthesize a result are becoming more capable. OpenAI’s approach looks like a step forward (and smart business insofar as it leads users into deeper relationship with its models), and its strategy of licensing content from trusted sources could prove to be an advantage.</p><p><strong>We’re thinking:</strong>&nbsp;In less than two years, OpenAI has revolutionized expectations of one of the web’s bedrock applications, search. Its progress shows how AI can make applications smarter, more efficient, and more responsive.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174238.698.gif" width="1200" /></figure><h1 id="web-data-increasingly-off-limits">Web Data Increasingly Off Limits</h1><p>Online publishers are moving to stop AI developers from training models on their content.</p><p><strong>What’s new:&nbsp;</strong>Researchers at MIT&nbsp;<a href="https://www.dataprovenance.org/consent-in-crisis-paper?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">analyzed</a>&nbsp;websites whose contents appear in widely used training datasets. Between 2023 and 2024, many of these websites changed their terms of service to ban web crawlers, restricted the pages they permit web crawlers to access, or both.<br /><br /><strong>How it works:</strong>&nbsp;MIT’s Data Provenance Initiative examined 14,000 websites whose contents are included in three large datasets, each of which contains data from between 16 and 45 million websites:&nbsp;<a href="https://huggingface.co/datasets/legacy-datasets/c4?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">C4</a>&nbsp;(1.4 trillion text tokens from Common Crawl),&nbsp;<a href="https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">RefinedWeb</a>&nbsp;(3 trillion to 6 trillion text tokens plus image links), and&nbsp;<a href="https://allenai.github.io/dolma/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Dolma</a>&nbsp;(3 trillion text tokens).&nbsp;</p><ul><li>The authors segmented each dataset into a head (2,000 websites that contributed the most tokens to each dataset) and a tail. Uniting the three heads yielded approximately 4,000 high-contribution sites (since content from some of these sites appears in more than one dataset). To represent the tail, they randomly sampled 10,000 other websites that appear in at least one dataset.&nbsp;</li><li>They examined each website’s terms of service and&nbsp;<a href="https://www.cloudflare.com/learning/bots/what-is-robots-txt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">robots.txt</a>, a text file that tells web crawlers which pages they can access, for restrictions on using the website’s content. (Robots.txt is an honor system; no mechanism exists to enforce it.)</li></ul><p><strong>Results:&nbsp;</strong>In the past year, websites responsible for half of all tokens (text scraped and encoded for use as training data) in the study changed their terms of service to forbid either crawlers in general or use of their content to train AI systems. Robots.txt files showed the same shift.</p><ul><li>In April 2023, robots.txt files restricted less than 3 percent of tokens in the head and 1 percent of all tokens in the study. One year later, they restricted around 28 percent of tokens in the head and 5 percent of all tokens.</li><li>Some types of websites are growing more restrictive than others. In April 2023, news websites in the head used robots.txt to restrict 3 percent of their tokens. In April 2024, that number rose to 45 percent.&nbsp;</li><li>Websites are restricting some crawlers significantly more than others. Websites that represent more than 25 percent of tokens included in C4’s head restricted OpenAI’s crawler, but less than 5 percent of them restricted Cohere’s and Meta’s. By contrast, 1 percent restricted Google’s search crawler.</li></ul><p><strong>Behind the news:&nbsp;</strong>Data that once was freely available is becoming harder to obtain on multiple fronts. Software developers, authors, newspapers, and music labels have&nbsp;<a href="https://www.deeplearning.ai/the-batch/judge-dismisses-key-arguments-in-ai-copyright-lawsuit-against-github-microsoft-and-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">filed</a>&nbsp;lawsuits that allege that AI developers trained systems on their data in violation of the law.&nbsp;<a href="https://www.deeplearning.ai/the-batch/openai-licenses-financial-times-archive-in-fifth-deal-with-major-news-publishers/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">OpenAI</a>&nbsp;and others recently agreed to pay licensing fees to publishers for access to their material. Last year, Reddit and Stack Overflow started&nbsp;<a href="https://www.deeplearning.ai/the-batch/reddit-and-stack-overflow-ask-ai-devs-to-pay-for-data/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">charging</a>&nbsp;AI developers for use of their APIs.<br /><br /><strong>Yes, but:</strong>&nbsp;The instructions in robots.txt files are not considered mandatory, and web crawlers can disregard them. Moreover, most websites have little ability to enforce their terms of use, which opens loopholes. For instance, if a site disallows one company’s crawler, the company may hire an intermediary to scrape the site.</p><p><strong>Why it matters:&nbsp;</strong>AI systems rely on ample, high-quality training data to attain high performance. Restrictions on training data give developers less scope to build valuable models. In addition to affecting commercial AI developers, they may also limit research in academia and the nonprofit sector.</p><p><strong>We’re thinking:&nbsp;</strong>We would prefer that AI developers be allowed to train on data that’s available on the open web. We hope that future court decisions and legislation will affirm this.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-31T174326.474.png" width="1200" /></figure><h1 id="synthetic-data-factory">Synthetic Data Factory</h1><p>Researchers increasingly fine-tune models on synthetic data, but generated datasets may not be sufficiently diverse. New work used agentic workflows to produce diverse synthetic datasets.</p><p><strong>What’s new:</strong>&nbsp;Arindam Mitra, Luciano Del Corro, Guoqing Zheng, and colleagues at Microsoft introduced&nbsp;<a href="https://arxiv.org/abs/2407.03502?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">AgentInstruct</a>, a framework for producing synthetic data for fine-tuning large language models (LLMs).</p><p><strong>Key insight:</strong>&nbsp;To generate synthetic data for fine-tuning, researchers typically prompt an LLM to generate responses (and possibly further prompts) using a&nbsp;<a href="https://arxiv.org/abs/2304.03277?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">selection of existing prompts</a>. While training on the resulting dataset can improve model performance, the synthetic data’s distribution may not match that of real-world data, yielding inconsistent performance. A more methodical approach can generate data closer to the real-world distribution: First generate prompts from each example in a large, diverse dataset, then generate responses.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors generated a synthetic text dataset based on&nbsp;<a href="https://arxiv.org/abs/2401.14624?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">three</a>&nbsp;<a href="https://arxiv.org/abs/2402.07625?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">unlabeled</a>&nbsp;<a href="https://huggingface.co/datasets/codeparrot/github-code-clean?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">datasets</a>&nbsp;(including code) scraped from the web. They generated new examples for 17 tasks, including natural language tasks like reading comprehension and word puzzles as well as coding, tool use, and estimating measurements.&nbsp;</p><ul><li>Using an unspecified LLM, they generated prompts (text plus an instruction) using three agentic workflows they called content transformation (which created variations on the text that offer wider latitude for generating instructions), instruction generation, and instruction refinement (which made the instructions more complicated or unsolvable).&nbsp;</li><li>For each task, they manually defined a team of agents to perform each workflow. For example, for the reading comprehension task, content transformation agents transformed raw text into a poem, satire, or other stylistic or formal variation. Instruction generation agents generated questions to ask about the transformed text based on an author-defined list of 43 types of questions. Instruction refinement agents received each (text, question) pair and produced more pairs by either (i) modifying the passage to make the question unanswerable, (ii) modifying the passage so the correct answer became the opposite of the original answer, or (iii) modifying the questions to be more complicated or unanswerable.&nbsp;</li><li>The authors combined the resulting 22 million (text, instruction) prompts with prompts used to train Orca-1, Orca-2, and Orca-Math, for a total of 25.8 million prompts. Then they generated responses and fine-tuned&nbsp;<a href="https://arxiv.org/abs/2310.06825?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9y2rzQjKfTjiYWD_NMdxVmGpCJ9vEZ91E8GAN6svqMNpevzddTZGw4UsUvTpwJ0mcb4CjR" rel="noopener">Mistral-7B</a>&nbsp;on the resulting dataset. They called the resulting model Orca-3.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared Orca 3’s performance against that of competitors on 14 benchmarks. Orca 3 outperformed Mistral-7B (fine-tuned on prompts from previous versions of Orca) and Mistral-7B-Instruct (fine-tuned to respond to instructions) on 13 benchmarks. In some cases, it did so by large margins; for instance 40 percent on AGIEVAL, 54 percent on GSM8K, and 19 percent on MMLU. Orca 3 fell short of GPT-4 on 12 benchmarks.</p><p><strong>Why it matters:</strong>&nbsp;The authors defined agentic workflows that turn text into diverse data for fine-tuning models. Their framework offers a pattern for AI engineers who want to build synthetic datasets for other tasks.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;We’re excited to see agentic workflows find applications that a wide variety of AI developers might put to use!</p><hr /><h2 id="a-message-from-rapidfire-ai">A MESSAGE FROM&nbsp;RAPIDFIRE AI</h2><figure class="kg-card kg-image-card"><a href="https://forms.gle/o9yqbp2HGriwnZWk6?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/DL.AI-Ad--6-.png" width="1680" /></a></figure><p>Tell us about your deep learning use cases and issues that need to be addressed and get a chance to win a $200 Amazon gift card! Take 10 minutes to fill out this<strong>&nbsp;</strong><a href="https://forms.gle/o9yqbp2HGriwnZWk6?ref=dl-staging-website.ghost.io" rel="noreferrer">quick survey</a>&nbsp;now</p>
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 22:48:54 GMT</pubDate>
</item>
<item>
<title>OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive</title>
<link>https://www.deeplearning.ai/the-batch/issue-259</link>
<guid>https://www.deeplearning.ai/the-batch/issue-259</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>AI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship. In this letter, I’d like to share what might be a counter-intuitive best practice that I’ve learned from leading <a href="http://aifund.ai/?ref=dl-staging-website.ghost.io"><u>AI Fund</u></a>, a venture studio that has built dozens of startups with extraordinary entrepreneurs. When it comes to building AI applications, we strongly prefer to work on a <em>concrete idea</em>, meaning a specific product envisioned in enough detail that we can build it for a specific target user.&nbsp;</p><p>Some design philosophies say you shouldn’t envision a specific product from the start. Instead, they recommend starting with a problem to be solved and then carefully studying the market before you devise a concrete solution. There’s a reason for this: The more concrete or precise your product specification, the more likely it is to be off-target. However, I find that having something specific to execute toward lets you go much faster and discover and fix problems more rapidly along the way. If the idea turns out to be flawed, rapid execution will let you discover the flaws sooner, and this knowledge and experience will help you switch to a different concrete idea.</p><p>One test of concreteness is whether you’ve specified the idea in enough detail that a product/engineering team could build an initial prototype. For example, “AI for livestock farming” is not concrete; it’s vague. If you were to ask an engineer to build this, they would have a hard time knowing what to build.&nbsp; Similarly, “AI for livestock tracking in farming” is still vague. There are so many approaches to this that most reasonable engineers wouldn’t know what to build. But “Apply face recognition to cows so as to recognize individual cows and monitor their movement on a farm” is specific enough that a good engineer could quickly choose from the available options (for example, what algorithm to try first, what camera resolution to use, and so on) to let us relatively efficiently assess:</p><ul><li><strong>Technical feasibility:</strong> For example, do face recognition algorithms developed for human faces work for cows? (It turns out that they do!)&nbsp;</li><li><strong>Business feasibility:</strong> Does the idea add enough value to be worth building? (Talking to farmers might quickly reveal that solutions like RFID are easier and cheaper.)</li></ul><p>Articulating a concrete idea — which is more likely than a vague idea to be wrong — takes more courage. The more specific an idea, the more likely it is to be a bit off, especially in the details. The general area of AI for livestock farming seems promising, and surely there will be good ways to apply AI for livestock. In contrast, specifying a concrete idea, which is much easier to invalidate, is scary.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--75--1.jpg" width="1200" /></figure><p>The benefit is that the clarity of a specific product vision lets a team execute much faster. One strong predictor of how likely a startup is to succeed is the speed with which it can get stuff done. This is why founders with clarity of vision tend to be desired; clarity helps drive a team in a specific direction. Of course, the vision has to be a good one, and there’s always a risk of efficiently building something that no one wants to buy! But a startup is unlikely to succeed if it meanders for too long without forming a clear, concrete vision.</p><p>Building toward something concrete — if you can do so in a responsible way that doesn’t harm others — lets you get critical feedback more efficiently and, if necessary, switch directions sooner. (See my <a href="https://www.deeplearning.ai/the-batch/how-to-build-ai-products-and-businesses-two-strategies?ref=dl-staging-website.ghost.io"><u>letter</u></a> on when it’s better to go with a “Ready, Fire, Aim” approach to projects.) One factor that favors this approach is the low cost of experimenting and iterating. This is increasingly the case for many AI applications, but perhaps less so for deep-tech AI projects.&nbsp;</p><p>I realize that this advice runs counter to common practice in <a href="https://wind4change.com/design-thinking-d-school-stanford-ideo-approach-methodology/?ref=dl-staging-website.ghost.io"><u>design thinking</u></a>, which warns against leaping to a solution too quickly, and instead advocates spending time understanding end-users, deeply understanding their problems, and brainstorming a wide range of solutions. If you’re starting without any ideas, then such an extended process can be a good way to develop good ideas. Further, keeping ideas open-ended can be good for curiosity-driven research, where investing to pursue deep tech with only a vague direction in mind can pay huge dividends over the long term.&nbsp;</p><p>If you are thinking about starting a new AI project, consider whether you can come up with a concrete vision to execute toward. Even if the initial vision turns out not to be quite right, rapid iteration will let you discover this sooner, and the learnings will let you switch to a different concrete idea.&nbsp;</p><p>Through working with many large corporations, AI Fund has developed best practices for identifying concrete ideas relevant to a business. I’ll share more on this in a later letter.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png" width="1680" /></a></figure><p>Learn how to build secure, privacy-focused federated learning systems using the Flower framework in a new two-part short course. Start with the basics in “Intro to Federated Learning,” and explore advanced techniques in “Federated Fine-tuning of LLMs with Private Data.”&nbsp;<a href="https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144159.287.gif" width="1200" /></figure><h1 id="mini-but-mighty">Mini but Mighty</h1><p>A slimmed-down version of Open AI’s multimodal flagship packs a low-price punch.</p><p><strong>What’s new:</strong> OpenAI <a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/?ref=dl-staging-website.ghost.io"><u>released</u></a> GPT-4o mini, a smaller text-image-video-audio generative model that, according to the company, generally outperforms models from Google and Anthropic models of similar size at a lower price for API access. It newly underpins the free version of ChatGPT.</p><p><strong>How it works:</strong> GPT-4o mini currently accepts text and image inputs and outputs text. Image output as well as video and audio input/output are coming soon. OpenAI did not provide information about its architecture or training but <a href="https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?ref=dl-staging-website.ghost.io"><u>told</u></a> <em>TechCrunch</em> it’s roughly the size of Claude 3 Haiku, Gemini 1.5 Flash, and the 8-billion-parameter version of Llama 3. It has a context window of 128,000 tokens and can output up to around 16,400 tokens.&nbsp;</p><ul><li>API access to GPT-4o mini, which <a href="https://openai.com/api/pricing/?ref=dl-staging-website.ghost.io"><u>costs</u></a> $0.15/$0.60 per 1 million input/output tokens. That’s significantly less than the more capable GPT-4o ($5/$15 per 1 million input/output tokens with the same context window). It’s also more cost-effective and significantly better performing than GPT-3.5 Turbo ($0.50/$1.50 per 1 million input/output tokens with a 16,000-token context window).</li><li>On the <a href="https://paperswithcode.com/dataset/mmlu?ref=dl-staging-website.ghost.io"><u>MMLU</u></a> language understanding benchmark, GPT-4o mini beats Gemini 1.5 Flash at a lower cost, according to tests by <a href="https://artificialanalysis.ai/models/gpt-4o-mini?ref=dl-staging-website.ghost.io"><u>Artificial Analysis</u></a>. It’s just behind Llama 3 70B and <a href="https://arxiv.org/abs/2404.12387?ref=dl-staging-website.ghost.io"><u>Reka Core</u></a> but costs around half as much as the former and 1/20th as much as the latter.</li><li>GPT-4o mini (which generates 108 tokens per second) is slower than Llama 3 8B (166 tokens per second), Gemini 1.5 Flash (148 tokens per second), and Claude 3 Haiku (127 tokens per second) according to Artificial Analysis. However, GPT-4o mini speeds past GPT-4o, which produces 63 tokens per second.</li></ul><p><strong>Behind the news:</strong> GPT-4o mini part of a July wave of smaller large language models.&nbsp;</p><ul><li>Mistral and Nvidia jointly <a href="https://mistral.ai/news/mistral-nemo/?ref=dl-staging-website.ghost.io"><u>released</u></a> Mistral NeMo (12 billion parameters). Its context window is 128,000 tokens, equal to GPT-4o mini and larger than most models of its size. It’s available under the Apache 2.0 open source license.</li><li>Hugging Face <a href="https://huggingface.co/blog/smollm?ref=dl-staging-website.ghost.io"><u>debuted</u></a> SmolLM, a family of three even smaller models — 135 million, 362 million, and 1.71 billion parameters — designed to run on mobile devices. The base and instruction-tuned versions including weights are freely available for download with no restrictions on commercial use. SmolLM is licensed under Apache 2.0.</li></ul><p><strong>Why it matters:</strong> Powerful multimodal models are becoming ever more widely available at lower prices, creating opportunities for developers and researchers alike. GPT-4o mini sets a new standard for others to beat. Its price may be especially appealing to developers who aim to build agentic workflows that require models to process large numbers of tokens on their way to producing output.</p><p><strong>We’re thinking:</strong> Not long ago, pushing the edge of large language models meant making them larger, with higher computing costs to drive rising parameter counts. But building bigger models has made it easier to develop smaller models that are more cost-effective and nearly as capable. It’s a virtuous circle: Costs fall and productivity rises to everyone’s benefit.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--76-.jpg" width="1200" /></figure><h1 id="meta-withholds-models-from-europe">M<strong>eta Withholds Models From Europe</strong></h1><p>European users won’t have access to Meta’s multimodal models.&nbsp;</p><p><strong>What’s new:</strong> Meta said it would <a href="https://www.axios.com/2024/07/17/meta-future-multimodal-ai-models-eu?ref=dl-staging-website.ghost.io"><u>withhold</u></a> future multimodal models from the European Union (EU) to avoid being charged, banned, or fined for running afoul of the region’s privacy laws, according to Axios. (The newly released <a href="https://ai.meta.com/blog/meta-llama-3-1/?ref=dl-staging-website.ghost.io"><u>Llama 3.1</u></a> family, which processes text only, will be available to EU users.) <strong>How it works:</strong> EU data regulators have said that Meta may be violating EU privacy laws by training models on data from Facebook, Instagram, and its other properties. Meta’s move in Europe follows its <a href="https://www.reuters.com/technology/artificial-intelligence/meta-decides-suspend-its-generative-ai-tools-brazil-2024-07-17/?ref=dl-staging-website.ghost.io"><u>withdrawal</u></a> of generative models from Brazil, after that country’s national data-protection authority <a href="https://www.reuters.com/technology/artificial-intelligence/brazil-authority-suspends-metas-ai-privacy-policy-seeks-adjustment-2024-07-02/?ref=dl-staging-website.ghost.io"><u>struck down</u></a> the part of Meta’s privacy policy that allowed it to use personal data from users of Meta products to train AI models.&nbsp;</p><ul><li>EU companies will not be able to build applications on future multimodal models from Meta. Companies outside the EU that build products based on these models will not be able to deliver them to EU customers. Text-only versions including Llama 3.1, as well as applications built on them, will continue to be available in the EU.</li><li>In a blog post in May, Meta <a href="https://about.fb.com/news/h/bringing-generative-ai-experiences-to-people-in-europe/?ref=dl-staging-website.ghost.io"><u>announced</u></a> that it would train models on text and images that are publicly visible on Meta-owned services; for example, public Facebook posts and public Instagram photos and their captions. The data-protection authorities of 11 EU member states (including Ireland, where Meta’s European headquarters is located), objected to Meta’s collection of this data from EU users. Meta responded by <a href="https://about.fb.com/news/2024/06/building-ai-technology-for-europeans-in-a-transparent-and-responsible-way/?ref=dl-staging-website.ghost.io"><u>delaying</u></a> its collection of user data in the EU.</li><li>The UK has a nearly <a href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/06/statement-in-response-to-metas-plans-to-train-generative-ai-with-user-data/?ref=dl-staging-website.ghost.io"><u>identical</u></a> data-protection law, but Meta does not plan to restrict its models there. That’s because UK regulators have been clearer than their EU counterparts about the law’s requirements, a Meta representative told Axios.</li></ul><p><strong>Apple and OpenAI in Europe:</strong> Meta is not the only global AI company that’s wary of EU technology regulations.&nbsp;</p><ul><li>In June, Apple <a href="https://www.cnbc.com/2024/06/21/apple-ai-europe-dma-macos.html?ref=dl-staging-website.ghost.io"><u>announced</u></a> it would withhold <a href="https://www.deeplearning.ai/the-batch/apple-unveils-ai-features-in-new-ios-and-macos-update-during-wwdc/?ref=dl-staging-website.ghost.io"><u>generative AI features</u></a> from iOS devices in the EU. Apple said the EU’s <a href="https://digital-markets-act.ec.europa.eu/index_en?ref=dl-staging-website.ghost.io"><u>Digital Markets Act</u></a>, which requires that basic applications like web browsers, search engines, and messaging be able to work together regardless of the operating systems they run on, prevented it from deploying the features to EU customers without compromising user privacy.</li><li>Early in the year, OpenAI <a href="https://www.bbc.com/news/technology-68128396?ref=dl-staging-website.ghost.io"><u>drew</u></a> attention from Italian regulators, who briefly <a href="https://www.deeplearning.ai/the-batch/italy-blocked-chatgpt-for-alleged-privacy-violations/?ref=dl-staging-website.ghost.io"><u>banned</u></a> ChatGPT in 2023 for violating EU law. As of May, a multinational task force was <a href="https://www.edpb.europa.eu/system/files/2024-05/edpb_20240523_report_chatgpt_taskforce_en.pdf?ref=dl-staging-website.ghost.io"><u>investigating</u></a> the matter.&nbsp;</li></ul><p><strong>Why it matters:</strong> Different regions are taking different paths toward regulating AI. The EU is more restrictive than others, creating barriers to AI companies that develop new technology and products. Meta and Apple are taking proactive steps to reduce their risks even if it means foregoing portions of the European market.&nbsp;</p><p><strong>We’re thinking:</strong> We hope regulators everywhere will think hard about how to strike a balance between protecting innovation and other interests. In this instance, the EU’s regulations have prompted Meta to make a decision that likely likely set back European AI while delivering little benefit to citizens.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--77-.jpg" width="1200" /></figure><h1 id="ai-investors-hoard-gpu-power"><strong>AI Investors Hoard GPU Power</strong></h1><p>Investors have been gathering AI chips to attract AI startups.&nbsp;</p><p><strong>What’s new:</strong> Venture-capital firms are stockpiling high-end graphics processing units (GPUs), according to a <a href="https://www.theinformation.com/articles/andreessen-horowitz-is-building-a-stash-of-more-than-20-000-gpus-to-win-ai-deals?ref=dl-staging-website.ghost.io"><u>report</u></a> by <em>The Information</em>. They’re using the hardware to provide processing power to their portfolio companies at reduced or no cost.</p><p><strong>How it works:</strong> Andreessen Horowitz (A16Z), a prominent Silicon Valley venture investment firm, has amassed the largest known stock of GPUs dedicated to venture-funded startups. The firm plans to acquire more than 20,000 GPUs including top-of-the-line Nvidia H100s, which can sell for tens of thousands of dollars each — roughly enough to train a competitive large language model.&nbsp;</p><ul><li>A16Z offers access at below-market rates or in exchange for equity in startups it funds.&nbsp;</li><li>Whether A16Z purchased GPUs or ia paying a third-party cloud provider for access is not clear.&nbsp;</li><li>Luma AI, funded by A16Z, used the venture firm’s compute resources and, in June, released the <a href="https://www.deeplearning.ai/the-batch/claude-3-5-sonnet-is-powerful-inexpensive-and-speedy/?ref=dl-staging-website.ghost.io"><u>Dream Machine</u></a> video generator. Luma AI CEO and co-founder Amit Jain said the company turned down funders who offered more lucrative terms because A16Z offered GPUs.</li></ul><p><strong>Behind the news:</strong> High-end GPUs were in <a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?ref=dl-staging-website.ghost.io"><u>short supply</u></a> early last year. The shortage has <a href="https://www.tomshardware.com/pc-components/gpus/nvidias-h100-ai-gpu-shortages-ease-as-lead-times-drop-from-up-to-four-months-to-8-12-weeks?ref=dl-staging-website.ghost.io"><u>eased</u></a> significantly, but getting access to enough processing power to train and run large models still isn’t easy. A16Z follows several other investors that have sought to fill the gap for startups.</p><ul><li>Ex-GitHub CEO Nat Friedman and Daniel Gross, who has provided capital to startups including Github, Character.ai, Perplexity.ai, and Uber, <a href="https://www.forbes.com/sites/kenrickcai/2024/02/14/ai-investors-are-wooing-startups-with-massive-computing-clusters/?ref=dl-staging-website.ghost.io"><u>established</u></a> the Andromeda Cluster, a group of supercomputers with more than 4,000 GPUs between them, including over 2,500 H100s. They offer access to startups in their portfolio at below-market rates.</li><li>Last year, Index Ventures <a href="https://techcrunch.com/2023/08/19/how-index-ventures-jumped-to-the-front-of-the-ai-gpu-line/?ref=dl-staging-website.ghost.io"><u>agreed</u></a> to pay Oracle for access to H100 and A100 GPUs. In turn, it made them available to portfolio companies for free.</li><li>Microsoft <a href="https://blogs.microsoft.com/blog/2023/11/07/startups-to-access-high-performance-azure-infrastructure-accelerating-ai-breakthroughs/?ref=dl-staging-website.ghost.io"><u>provides</u></a> free access to GPUs via its Azure cloud service to startups funded by its venture fund M12 and the venture accelerator Y Combinator.</li></ul><p><strong>Yes, but:</strong> David Cahn, a partner at A16Z rival Sequoia Capital, <a href="https://www.sequoiacap.com/article/ais-600b-question/?ref=dl-staging-website.ghost.io"><u>argues</u></a> that stockpiling GPUs is a mistake that could leave venture funds holding large quantities of expensive, rapidly depreciating, hardware. Cahn believes startups and small developers soon may have an easier time getting their hands on the processing power they need. Nvidia recently <a href="https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/?ref=dl-staging-website.ghost.io"><u>announced</u></a> its new B100 and B200 GPUs, whose arrival should stanch demand for older units like the H100.</p><p><strong>Why it matters:</strong> AI startups are hot, and venture-capital firms compete for early equity in the most promising ones. In addition to funding, they frequently offer advice, contacts, office support — and now processing power to empower a startup to realize its vision.</p><p><strong>We’re thinking:</strong> Venture investors who use GPUs to sweeten a deal give new meaning to the phrase “bargaining chips.”</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144606.148.gif" width="600" /></figure><h1 id="expressive-synthetic-talking-heads">Expressive Synthetic Talking Heads</h1><p>Previous systems that produce a talking-head video from a photo and a spoken-word audio clip animate the lips and other parts of the face separately. An alternative approach achieves more expressive results by animating the head as a whole.</p><p><strong>What’s new:</strong>&nbsp;Sicheng Xu and colleagues at Microsoft developed&nbsp;<a href="https://arxiv.org/abs/2404.10667?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">VASA-1</a>, a generative system that uses a facial portrait and spoken-word recording to produce a talking-head video with appropriately expressive motion. You can see its output&nbsp;<a href="https://www.microsoft.com/en-us/research/project/vasa-1/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;When a person speaks, the facial expression and head position change over time, while the overall shapes of the face and head don’t. By learning to represent an image via separate embeddings for facial expression and head position — which change — as well as for facial structure in its 2D and 3D aspects — which don’t — a latent diffusion model can focus on the parts of the image that matter most. (<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">Latent diffusion</a>&nbsp;is a variant of diffusion that saves computation by processing a small, learned vector of an image instead of the image itself.)</p><p><strong>How it works:&nbsp;</strong>VASA-1 comprises four image encoders (three 2D CNNs and one 3D CNN), one image decoder (another 2D CNN),&nbsp;<a href="https://arxiv.org/abs/2006.11477?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">Wav2Vec 2.0</a>, and a latent diffusion image generator. The authors trained the system, given an image of a face and a recorded voice, to generate a series of video frames that conform to the voice. The training set was&nbsp;<a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">VoxCeleb2</a>, which includes over 1 million short videos of celebrities talking. The authors added labels for gaze direction, head-to-camera distance, and an emotional intensity score computed&nbsp;<a href="https://link.springer.com/article/10.3758/s13428-018-1133-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">by</a>&nbsp;<a href="https://arxiv.org/abs/1903.08527?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">separate</a>&nbsp;<a href="https://github.com/av-savchenko/face-emotion-recognition?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">systems</a>.</p><ul><li>Given an image of a face, the encoders&nbsp;<a href="https://arxiv.org/pdf/2207.07621?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">learned</a>&nbsp;to generate embeddings that represented the 2D facial structure (which the authors call “identity”), 3D contours (“appearance”), head position, and facial expression. Given the embeddings, the decoder reconstructed the image. The authors trained the encoders and decoder together using eight loss terms. For instance, one loss term encouraged the system to reconstruct the image. Another encouraged the system, when it processes a different image of the same person (with different head positions and facial expressions), to produce a similar identity embedding.</li><li>Given a video, the trained encoders produced a sequence of paired head-position and facial-expression embeddings, which the authors call a “motion sequence.”</li><li>Given the accompanying voice recording, a pretrained Wav2Vec2&nbsp; produced a sequence of audio embeddings.&nbsp;</li><li>Given the audio embeddings that correspond to a series of consecutive frames, the latent diffusion model learned to generate the corresponding embeddings in the motion sequence. It also received other inputs including previous audio and motion sequence embeddings, gaze direction, head-to-camera distances, and emotional-intensity scores.</li><li>At inference, given an arbitrary image of a face and an audio clip, VASA produced the appearance and identity embeddings. Then it produced audio embeddings and motion-sequence embeddings. It generated the final video by feeding the appearance, identity, and motion sequence embeddings to its decoder.</li></ul><p><strong>Results:</strong>&nbsp;The authors measured their results by training a model similar to&nbsp;<a href="https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">CLIP</a>&nbsp;that produces a similarity score on how well spoken audio matches a video of a person speaking (higher is better). On the VoxCeleb2 test set, their approach produced a similarity score of 0.468 compared to 0.588 for real video. The nearest contender,&nbsp;<a href="https://arxiv.org/abs/2211.12194?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">SadTalker</a>, which generates lip, eye, and head motions separately, achieved a similarity score of 0.441.</p><p><strong>Why it matters:</strong>&nbsp;By learning to embed different aspects of a face separately, the system maintained the face’s distinctive, unchanging features while generating appropriate motions. This also made the system more flexible at inference: The authors demonstrated its ability to extract a video’s facial expressions and head movements and apply them to different faces.</p><p><strong>We’re thinking:</strong>&nbsp;Never again will we take talking-head videos at face value!</p><hr /><h2 id="a-message-from-workera">A MESSAGE FROM WORKERA</h2><figure class="kg-card kg-image-card"><a href="https://workera.ai/try-for-free?utm_source=pressrelease&amp;utm_medium=paidsocial&amp;utm_campaign=TryForFree&amp;utm_term=TheBatch&amp;utm_content=TheBatch"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-23T090621.368.png" width="1200" /></a></figure><p>Test, benchmark, and grow your skills with new assessments from Workera! Available domains include AI Foundations, Machine Learning, GenAI, and MLOps.&nbsp;<a href="https://workera.ai/try-for-free?utm_source=pressrelease&amp;utm_medium=paidsocial&amp;utm_campaign=TryForFree&amp;utm_term=TheBatch&amp;utm_content=TheBatch" rel="noreferrer">Try Workera today for $0!</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jul 2024 19:51:25 GMT</pubDate>
</item>
<item>
<title>Hallucination Detector, Battle of the Image Generators, How Open Are Open Models?, Copyright Claim Fails Against GitHub</title>
<link>https://www.deeplearning.ai/the-batch/issue-258</link>
<guid>https://www.deeplearning.ai/the-batch/issue-258</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>“Democracy is the worst form of government, except for all the others,” said Winston Churchill. Last week’s shocking attempt to assassinate former President Trump was a reminder that democracy is fragile.</p><p>Democracy lets citizens argue with each other via words and votes. While imperfect, it is a powerful force for making sure that people are governed by leaders of their own choosing, and that these leaders are accountable to making people better off.&nbsp;</p><p>That’s why attempts to disrupt the democratic process, such as assassinating a political candidate or attempting to disrupt a peaceful handover of power to a newly elected government, are despicable: They attack a fundamental mechanism for giving everyone a chance to have a say in who governs. I denounce all political violence and grieve for Corey Comperatore, who was killed in the assassination attempt, and for his family. I hope for a quick recovery for former President Trump and the bystanders who were injured. I also hope we can put more resources into strengthening the mechanisms of democracy.&nbsp;</p><p>In addition, I wonder what role AI can play in preserving democracy.&nbsp;</p><p>Technology can have positive or negative impacts on specific mechanisms of democracy. For instance, data analysis can help citizens and reporters discover facts. Micro-targeting of political ads and social media can increase polarization, while social media can also provide useful information to voters.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--72--1.jpg" width="1200" /></figure><p>But zooming out to a macro view,</p><ul><li>Concentration of power, which is enhanced by concentration of access to technology, tends to make a subset of society more powerful at the expense of the whole and thus weakens democracy. For example, if only major political parties have the resources to place highly targeted voter ads, it’s hard for new parties to break in.</li><li>However, widespread access to new technologies tends to make everyone more powerful, and thus strengthens democracy. For example, widespread access to smartphones, web search, and now large language model chatbots broadens access to information and lets each individual do more. Thus, I believe spreading new technology as far and wide as possible is an important way to strengthen democracy.&nbsp;</li></ul><p>I’m glad last week’s assassination attempt failed, just as I’m glad the January 6 insurrection at the U.S. Capitol failed. Both events were close calls and resulted in tragic loss of human life. Looking into the future, in addition to specific applications that strengthen elements of democracy, I hope we keep on promoting widespread access to technology. This will enhance fairness and the ability of individuals to vote wisely. That’s why democratizing access to technology will help democracy itself.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/courses/generative-ai-for-software-development?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-17T111109.125.png" width="1680" /></a></figure><p>Enhance your software-development workflow with our new course, “Generative AI for Software Development.” Learn how to use generative AI tools to boost efficiency, improve code quality, and collaborate creatively.&nbsp;<a href="https://www.deeplearning.ai/courses/generative-ai-for-software-development?ref=dl-staging-website.ghost.io" rel="noreferrer">Pre-enroll today and be the first to join when the course goes live</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--73-.jpg" width="1200" /></figure><h1 id="copyright-claim-fails-in-github-case">Copyright Claim Fails in GitHub Case</h1><p>A judge rejected key claims in a lawsuit by developers against GitHub, Microsoft, and OpenAI, the first decision in a series of court actions related to generative AI.&nbsp;</p><p><strong>What’s new</strong>: A U.S. federal judge&nbsp;<a href="https://regmedia.co.uk/2024/07/08/github_copilot_dismiss.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">dismissed</a>&nbsp;claims of copyright infringement and unfair profit in a class-action lawsuit that targeted GitHub Copilot and the OpenAI Codex language-to-code model that underpins it.</p><p><strong>The case:</strong>&nbsp;In November 2022, programmer Matthew Butterick and the Joseph Saveri Law Firm&nbsp;<a href="https://githubcopilotlitigation.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">filed</a>&nbsp;the lawsuit in U.S. federal court. The plaintiffs claimed that GitHub Copilot had generated unauthorized copies of open-source code hosted on GitHub, which OpenAI Codex used as training data. The copies allegedly infringed on developers’ copyrights. The defendants tried repeatedly to get the lawsuit thrown out of court. In May 2023, the judge&nbsp;<a href="https://www.theregister.com/2023/05/12/github_microsoft_openai_copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">dismissed</a>&nbsp;some claims, including a key argument that GitHub Copilot could generate copies of public code without proper attribution, and allowed the plaintiffs to revise their arguments.</p><p><strong>The decision:</strong>&nbsp;The revised argument focused on GitHub Copilot’s&nbsp;<a href="https://resources.github.com/learn/pathways/copilot/essentials/establishing-trust-in-using-github-copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">duplication detection filter</a>. When enabled, the filter detects output that matches public code on GitHub and revises it. The plaintiffs argued that the existence of this feature demonstrated GitHub Copilot’s ability to copy code in OpenAI Codex’s training set. The judge was not persuaded.</p><ul><li>The judge stated that the plaintiffs had not presented concrete evidence that Copilot could generate substantial copies of code. He dismissed this copyright claim with prejudice, meaning that the plaintiffs can’t refile it.</li><li>The judge also dismissed a claim that GitHub illicitly profited from coders’ work by charging money for access to GitHub Copilot. To claim unjust enrichment under California law, plaintiffs must show that the defendant enriched itself through “mistake, fraud, coercion, or request.” The judge ruled that the plaintiffs had failed to demonstrate this.</li></ul><p><strong>Yes, but:</strong>&nbsp;The lawsuit is reduced, but it isn’t finished. A breach-of-contract claim remains. The plaintiffs aim to show that OpenAI and GitHub used open-source code without providing proper attribution and thus violated open-source licenses. In addition, the plaintiffs will refile their unjust-enrichment claim.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;The suit against Github et al. is one of several underway that are testing the copyright implications of training AI systems.&nbsp;<a href="https://www.penningtonslaw.com/news-publications/latest-news/2024/generative-ai-in-the-courts-getty-images-v-stability-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Getty Images</a>,&nbsp;<a href="https://authorsguild.org/news/ag-and-authors-file-class-action-suit-against-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Authors’ Guild</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">The New York Times</a>, and other media&nbsp;<a href="https://apnews.com/article/ai-media-lawsuits-center-for-investigative-reporting-chatgpt-mother-jones-c48452889750479410b65a119537746c?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">outlets</a>&nbsp;along with a consortium of&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-umg-and-warner-music-sue-suno-and-udio-over-alleged-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">music-industry giants</a>&nbsp;have sued OpenAI and other AI companies. All these cases rest on a claim that copying works protected by copyright for the purpose of training AI models violates the law — precisely what the plaintiffs failed to show in the GitHub case.</p><p><strong>Why it matters:</strong>&nbsp;This lawsuit specifically concerns code written by open-source developers. A verdict could determine how code can be used and how developers can use generative AI in their work. However, it has broader implications. (Note: We are not lawyers and we do not provide legal advice.) This dismissal is not a final verdict, but it supports the view that AI developers may have a broad right to use data for training models even if that data is protected by copyright.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Broadly speaking, we would like AI to be allowed to do with data, including open source code, anything that humans can legally and ethically do, including study and learn. We hope the judge’s decision gives AI developers further clarity on how they can use training data, and we hope it establishes that it’s ethical to use code-completion tools trained on open-source code.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135649.502.gif" width="1200" /></figure><h1 id="how-open-are-open-models">How Open Are Open Models?</h1><p>The word “open” can mean many things with respect to AI. A new paper outlines the variations and ranks popular models for openness.</p><p><strong>What’s new:</strong>&nbsp;Researchers at Radboud University&nbsp;<a href="https://www.mpi.nl/publications/item3588217/rethinking-open-source-generative-ai-open-washing-and-eu-ai-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">evaluated</a>&nbsp;dozens of models billed as open by their developers. They plan to keep their analysis of language models updated&nbsp;<a href="https://opening-up-chatgpt.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">here</a>.<br /><br /><strong>How it works:&nbsp;</strong>The authors assessed 40 large language models and six text-to-image generators, adding OpenAI’s closed models ChatGPT and DALL·E 2 as reference points. They evaluated 14 characteristics, scoring each as open (1 point), partially open (0.5 points), or closed (0 points). For example, an API would be described as partially open if using it requires users to register. They divided the characteristics into three categories:</p><ul><li><strong>Availability</strong>&nbsp;with respect to source code, pretraining data, base weights, fine-tuning data, fine-tuning weights, and licensing under a recognized open-source license</li><li><strong>Documentation</strong>&nbsp;of code, architecture, preprint paper, published peer-reviewed paper, model card, and datasheets that describe how the developer collected and curated the data</li><li><strong>Access</strong>&nbsp;to a downloadable package and open API</li></ul><p><strong>Results:</strong>&nbsp;Of the language models,&nbsp;<a href="https://allenai.org/olmo?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">OLMo 7B Instruct</a>&nbsp;from Allen Institute for AI scored highest with 12 open characteristics and 1 partially open characteristic (it lacked a published, peer-reviewed paper).&nbsp;</p><ul><li>OLMo 7B Instruct and&nbsp;<a href="https://huggingface.co/LLM360/AmberChat?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">AmberChat</a>&nbsp;(based on Llama-7B) were the only language models for which availability was fully open. BigScience’s&nbsp;<a href="https://huggingface.co/bigscience/bloomz?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">BLOOMZ</a>&nbsp;was the only language model whose documentation was fully open.&nbsp;</li><li>Some prominent “open” models scored less well. Alibaba’s Qwen 1.5, Cohere’s Command R+, and Google’s Gemma-7B Instruct were judged closed or partially open for most characteristics.&nbsp;<a href="https://www.deeplearning.ai/the-batch/falcon-the-new-open-source-commercial-llm-explained/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Falcon-40B-Instruct</a>&nbsp;scored 2 open and 5 partially open characteristics. Neither Meta’s Llama 2 Chat nor Llama 3 Instruct achieved any open marks.&nbsp;</li><li>Among text-to-image generators, Stability AI’s Stable Diffusion was far and away the most open. The authors deemed it fully open with respect to availability and documentation, and partially open with respect to access.</li></ul><p><strong>Behind the News:</strong>&nbsp;The Open Source Initiative (OSI), a nonprofit organization that maintains standards for open-source software licenses, is&nbsp;<a href="https://opensource.org/deepdive?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">leading</a>&nbsp;a process to establish a firm definition of “open-source AI.” The current&nbsp;<a href="https://opensource.org/deepdive/drafts/the-open-source-ai-definition-draft-v-0-0-8?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">draft</a>&nbsp;holds that an open-source model must include parameters, source code, and information on training data and methodologies under an OSI-recognized license.</p><p><strong>Why it matters:</strong>&nbsp;Openness is a cornerstone of innovation: It enables developers to build freely on one another’s work. It can also lubricate business insofar as it enables developers to sell products built upon fully open software. And it has growing regulatory implications. For example, the European Union’s AI Act regulates models that are released under an open source license less strictly than closed models. All these factors raise the stakes for clear, consistent definitions. The authors’ framework offers clear, detailed guidelines for developers — and policymakers — in search of clarity.<br /><br /><strong>We’re thinking:</strong>&nbsp;We’re grateful to AI developers who open their work to any degree, and we especially appreciate fully open availability, documentation, and access. We encourage model builders to release their work as openly as they can manage.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135754.238.gif" width="1200" /></figure><h1 id="image-generators-in-the-arena">Image Generators in the Arena</h1><p>An arena-style contest pits the world’s best text-to-image generators against each other.</p><p><strong>What’s new:</strong>&nbsp;Artificial Analysis, a testing service for AI models,&nbsp;<a href="https://artificialanalysis.ai/text-to-image?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">introduced</a>&nbsp;the Text to Image Arena leaderboard, which ranks text-to-image models based on head-to-head matchups that are judged by the general public. At the time of this writing, Midjourney v6 beats more than a dozen other models models in its ability to generate images that reflect input prompts, though it lags behind competitors in speed.</p><p><strong>How it works:</strong>&nbsp;Artificial Analysis selects two models at random and feeds them a unique prompt. Then it&nbsp;<a href="https://artificialanalysis.ai/text-to-image/arena?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">presents</a>&nbsp;the prompt and resulting images. Users can choose which model better reflects the prompt. The leaderboard ranks the models based on&nbsp;<a href="https://www.chess.com/terms/elo-rating-chess?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Elo</a>&nbsp;ratings, which scores competitors relative to one another.</p><ul><li>Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/text-to-image/methodology?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">selects</a>&nbsp;models to test according to “industry significance” and unspecified performance tests. The goal is to identify and compare the most popular, high-performing models, especially those that are available via APIs. (Midjourney, which has no API, is an exception.) Only 14 models meet this threshold, but Artificial Analysis says it is refining its criteria and may include more models in the future.</li><li>Users who have voted at least 30 times can see a personalized leaderboard based on their own voting histories.&nbsp;</li><li>Separate from the Text to Image Arena, Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/text-to-image?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">compares</a>&nbsp;each model’s average time to generate and download an image, calculated by prompting each model four times a day and averaging the time to output over 14 days. It also tracks the price to generate 1,000 images.</li></ul><p><strong>Who’s ahead?:</strong>&nbsp;As of this writing, Midjourney v6 (Elo rating 1,176), which won 71 percent of its matches, holds a slim lead over Stable Diffusion 3 (Elo rating 1,156), which won 67 percent. DALL·E 3 HD holds a distant third place, barely ahead of the open-source Playground v2.5. But there are tradeoffs: Midjourney v6 takes 85.3 seconds on average to generate an image, more than four times longer than DALL·E 3 HD and more than 13 times longer than Stable Diffusion 3. Midjourney v6 costs $66 per 1,000 images (an estimate by Artificial Analysis based on Midjourney’s policies, since the model doesn’t offer per-image pricing), nearly equal to Stable Diffusion 3 ($65), less than DALL·E 3 HD ($80), and significantly more than Playground v2.5 ($5.13 per 1,000 images via the&nbsp;<a href="https://replicate.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Replicate</a>&nbsp;API).</p><p><strong>Behind the news:</strong>&nbsp;The Text to Image Arena is a text-to-image counterpart of the&nbsp;<a href="https://www.deeplearning.ai/the-batch/chatbot-arena-compares-chatbots-side-by-side?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">LMSys Chatbot Arena</a>, which lets users write a prompt, feed it to two large language models, and pick the winner.&nbsp;<a href="https://imgsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">imgsys</a>&nbsp;and&nbsp;<a href="https://huggingface.co/spaces/TIGER-Lab/GenAI-Arena?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Gen-AI Arena</a>&nbsp;similarly let users choose between images generated by different models from the same prompt (Gen-AI Arena lets users write their own). However, these venues are limited to open models, which excludes the popular Midjourney and DALL·E.</p><p><strong>Why it matters:</strong>&nbsp;An image generator’s ability to respond appropriately to prompts is a subjective quality. Aggregating user preferences is a sensible way to measure it. However, individual tastes and applications differ, which makes personalized leaderboards useful as well.<br /><br /><strong>We’re thinking:</strong>&nbsp;The user interface for some image generators implicitly asks users to judge images. For example, Midjourney defaults to generating four images and asks users which they want to render at higher resolution. This can give the image generator valuable feedback about which image users like. Perhaps data gathered by an arena could feed an algorithm like reinforcement learning from human feedback to help generators learn to produce output that people prefer.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135854.645.png" width="600" /></figure><h1 id="hallucination-detector">Hallucination Detector</h1><p>Large language models can produce output that’s convincing but false. Researchers proposed a way to identify such hallucinations.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal at University of Oxford published a&nbsp;<a href="https://www.nature.com/articles/s41586-024-07421-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">method</a>&nbsp;that indicates whether a large language model (LLM) is likely to have hallucinated its output.</p><p><strong>Key insight:</strong>&nbsp;One way to estimate whether an LLM is hallucinating is to calculate the degree of uncertainty, or entropy, in its output based on the probability of each generated token in the output sequences. The higher the entropy, the more likely the output was hallucinated. However, this approach is flawed: Even if the model mostly generates outputs with a uniform meaning, the entropy of the outputs can still be high, since the same meaning can be phrased in many different ways. A better approach is to calculate entropy based on the distribution of generated meanings instead of generated sequences of words. Given a particular input, the more likely a model is to respond by generating outputs with a variety of meanings, the more likely that a response to that input is a hallucination.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors generated answers to five&nbsp;<a href="http://participants-area.bioasq.org/datasets/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">open-ended</a>&nbsp;<a href="https://rajpurkar.github.io/SQuAD-explorer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">question</a>-<a href="https://arxiv.org/abs/1705.03551?ref=dl-staging-website.ghost.io&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">and</a>-<a href="https://github.com/arkilpatel/SVAMP?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">answer</a>&nbsp;<a href="https://ai.google.com/research/NaturalQuestions?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">datasets</a>&nbsp;using various sizes of Falcon, LLaMA 2-chat, and Mistral. They checked the answers for hallucinations using the following method:</p><ul><li>Given a question, the model generated 10 answers.</li><li>The authors clustered the answers based on their meanings. They judged two answers to have the same meaning if GPT-3.5 judged that the first followed logically from the second and vice versa.</li><li>They computed the probabilities that the model would generate an answer in each cluster. Then they computed the entropy using those probabilities; that is, they calculated the model’s uncertainty in the meanings of its generated answers.&nbsp;</li><li>All answers to a given question were considered to have been hallucinated if the computed entropy exceeded a threshold.</li></ul><p><strong>Results:</strong>&nbsp;The authors measured the classification performance of their method using AUROC, a score between .5 (the classifier is uninformative) and 1 (the classifier is perfect). On average, across all five datasets and six models, the authors’ method achieved .790 AUROC while the baseline entropy achieved .691 AUROC and the&nbsp;<a href="https://arxiv.org/abs/2207.05221?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">P(True)</a>&nbsp;method achieved .698 AUROC. P(True) asks the model (i) to generate up to 20 answers and (ii) whether, given those answers, the one with the highest probability of having been generated is true or false.</p><p><strong>Yes, but:</strong>&nbsp;The authors’ method fails to detect hallucinations if a model consistently generates wrong answers.</p><p><strong>Behind the news:</strong>&nbsp;Hallucinations can be a major obstacle to deploying generative AI applications, particularly in fields like medicine or law where missteps can result in injury. One study published earlier this year&nbsp;<a href="https://hai.stanford.edu/news/ai-trial-legal-models-hallucinate-1-out-6-or-more-benchmarking-queries?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">found</a>&nbsp;that three generative legal tools produced at least partially incorrect or incomplete information in response to at least one out of every six prompts. For example, given the prompt, “Are the deadlines established by the bankruptcy rules for objecting to discharge jurisdictional,” one model cited a nonexistent rule: “[A] paragraph from the Federal Rules of Bankruptcy Procedure, Rule 4007 states that the deadlines set by bankruptcy rules governing the filing of dischargeability complaints are jurisdictional.”<br /><br /><strong>Why it matters:</strong>&nbsp;Effective detection of hallucinations not only fosters trust in users — and consequently rising adoption — but also enables researchers to determine common circumstances in which hallucinations occur, helping them to address the problem in future models.</p><p><strong>We’re thinking:&nbsp;</strong>Researchers are exploring various approaches to mitigate LLM hallucinations in trained models. Retrieval augmented generation (RAG) can help by integrating knowledge beyond a model’s training set, but it isn’t a complete solution. <a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email" rel="noopener">Agentic workflows</a> that include tool use to supply factual information and reflection to prompt the model to check itself are promising.</p><hr /><h2 id="a-message-from-deeplearningai-1">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/pretraining-llms?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-16T085539.096.png" width="1680" /></a></figure><p>In “Pretraining LLMs,” a short course built in collaboration with Upstage, you’ll learn about pretraining, the first step of training a large language model. You’ll also learn innovative pretraining techniques like depth upscaling, which can reduce training costs by up to 70 percent.&nbsp;<a href="https://www.deeplearning.ai/short-courses/pretraining-llms?ref=dl-staging-website.ghost.io" rel="noreferrer">Join today</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Jul 2024 19:03:11 GMT</pubDate>
</item>
<item>
<title>AI's Cloudy Path to Zero Emissions, Amazon's Agent Builders, Claude's UI Advance, Training On Consumer GPUs</title>
<link>https://www.deeplearning.ai/the-batch/issue-257</link>
<guid>https://www.deeplearning.ai/the-batch/issue-257</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>I continue to be alarmed at the progress of proposed California regulation SB 1047 and the attack it represents on open source and more broadly on AI innovation. As I&nbsp;<a href="https://www.deeplearning.ai/the-batch/blenders-versus-bombs-or-why-californias-proposed-ai-law-is-bad-for-everyone/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">wrote</a>&nbsp;previously, this proposed law makes a fundamental mistake of regulating AI technology instead of AI applications, and thus would fail to make AI meaningfully safer. I’d like to explain why the specific mechanisms of SB 1047 are so pernicious to open source.&nbsp;</p><p>To be clear, there are routes that regulators should pursue to improve safety. For example, I would welcome outlawing nonconsensual deepfake pornography, standardizing watermarking and fingerprinting to identify generated content, and investing more in red teaming and other safety research. Unfortunately, the proposed bill pursues a less beneficial and more harmful path.</p><p>SB 1047’s purported goal is to ensure safety of AI models. It puts in place complex reporting requirements for developers who fine-tune models or develop models that cost more than $100 million to train. It is a vague, ambiguous law that imposes significant penalties for violations, creating a huge gray zone in which developers can’t be sure how to avoid breaking the law. This will paralyze many teams.&nbsp;</p><p>You can read the latest draft of the law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202320240SB1047&amp;showamends=false&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">here</a>.&nbsp;I’ve read through it carefully, and I find it ambiguous and very hard to follow.</p><p>Developers who try to navigate the law’s complex requirements face what feels like a huge personal risk. It requires that developers submit&nbsp;a certification of compliance with the requirements of the law. But when the requirements are complex, hard to understand, and can even shift according to the whims of an unelected body (more on this below), how do we ensure we are in compliance?</p><p>For example, the certification must include many different sections. One is an analysis of “the nature and magnitude of critical harms … the model might reasonably cause or enable.” But given that even leading AI researchers aren’t sure what harms models might cause or enable, how is a team of developers supposed to figure this out and declare — under penalty of perjury — that they meet this requirement?&nbsp;</p><p>Further, some developers will be required to implement “protections to prevent … misuse of, or unsafe post-training modifications of, the covered model and all covered model derivatives … that are appropriate in light of the risks associated with the covered model, including from advanced persistent threats or other sophisticated actors.” Even leading AI researchers don’t agree on how best to “protect” AI models against these supposed risks, or what would be “appropriate.” So how are developers supposed to figure out how to comply with this requirement?&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--69-.jpg" width="1200" /></figure><p>This creates a scary situation for developers. Committing perjury could lead to fines and even jail time. Some developers will have to hire expensive lawyers or consultants to advise them on how to comply with these requirements. (I am not a lawyer and am not giving legal advice, but one way to try to avoid perjury is to show that you are relying on expert advice, to demonstrate that you had no intent to lie.) Others will simply refrain from releasing cutting-edge AI products.</p><p>If this law passes, the fear of a trial by a jury — leading to a verdict that can be very unpredictable with significant penalties in the event of a conviction — will be very real. What if someone releases a model today after taking what they genuinely felt were reasonable safeguards, but a few years later, when views on AI technology might have shifted, some aggressive prosecutor manages to convince a jury that whatever they did was not, in hindsight, “reasonable”? Reasonableness is ambiguous and its legal interpretation can depend on case law, jury instructions, and common facts, among other things. This makes it very hard to ensure that what a developer does today will be deemed reasonable by a future jury. (For more on this, see Context Fund’s&nbsp;<a href="https://docs.google.com/document/d/1xi2BolGZ4ljUVi7KNWewetpFJuNOQXRVI1hmBkej4Ew/edit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru#heading=h.8id9zuc4ym7p" rel="noopener">analysis</a>&nbsp;of SB 1047.)</p><p>One highly placed lawyer in the California government who studied this law carefully told me they found it hard to understand. I invite you to read it and judge for yourself — if you find the requirements clear, you might have a brilliant future as a lawyer!&nbsp;</p><p>Adding to the ambiguity, the bill would create a Frontier Model Division (FMD) with a five-person board that has the power to dictate standards to developers. This small board would be a great target for lobbying and regulatory capture. (Bill Gurley has a great&nbsp;<a href="https://www.youtube.com/watch?v=F9cO3-MLHOM&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">video</a>&nbsp;on regulatory capture.) The unelected FMD can levy fees on developers to cover its costs. It can arbitrarily change the computation threshold at which fine-tuning a model becomes subject to its oversight. This can lead to even small teams being required to hire an auditor to check for compliance with an ambiguous safety standard.&nbsp;</p><p>These provisions don’t ensure that AI is safe. They create regulatory uncertainty, and more opportunities for vested interests wishing to stifle open-source to lobby for shifts in the requirements that raise the cost of compliance. This would lock out many teams that don’t have a revenue stream — specifically, many open-source contributors — that would let them pay for lobbyists, auditors, and lawyers to help ensure they comply with these ambiguous and unreasonable requirements.&nbsp;</p><p>Open source is a wonderful force that is bringing knowledge and tools to many people, and is a key pillar of AI innovation. I am dismayed at the concerted attacks on it. Make no mistake, there is a fight in California right now for the future health of open source. I am committed to doing what I can to preserve open source, but I don’t assume that the pro-open source side will prevail. I hope you will join me in speaking out against SB 1047 and other laws that threaten to stifle open source.&nbsp;</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1040" src="https://dl-staging-website.ghost.io/content/images/2024/07/V2_DeepLearning_MongoDB_Banner_2070x1080--1---2-.png" width="2000" /></a></figure><p>In our new course “Prompt Compression and Query Optimization,” you’ll learn how to use MongoDB’s features to build efficient retrieval augmented generation (RAG) systems and address challenges to scaling, performance, and security.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization?ref=dl-staging-website.ghost.io">Enroll for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-10T143512.450.gif" width="1200" /></figure><h1 id="claude-advances-the-llm-interface">Claude Advances the LLM Interface</h1><p>Claude 3.5 Sonnet lets users work on generated outputs as though they were independent files — a step forward in large language model user interfaces.</p><p><strong>What’s new:</strong>&nbsp;Anthropic&nbsp;<a href="https://www.anthropic.com/news/claude-3-5-sonnet?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">introduced</a>&nbsp;Artifacts, a feature that displays outputs in a separate window of Claude 1.5 Sonnet’s web interface, outside the stream of conversation that creates and modifies them. Artifacts can&nbsp;<a href="https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">include</a>&nbsp;documents, code snippets, HTML pages, vector graphics, or visualizations built using JavaScript.</p><p><strong>How it works:</strong>&nbsp;Users can enable artifacts from the “feature preview” dropdown in their profile menu at Claude.ai. Then, asked to generate an output that’s likely to act as standalone content and undergo further work, Claude opens an artifact window next to the chat frame, populates it with an initial output, and further updates it according to subsequent prompts.&nbsp;</p><ul><li>Text or code artifacts are typically at least 15 lines long. Visual artifacts created using a programming language or markup can be viewed selectively as code or a rendered display. Users can interact with multiple artifacts (or multiple versions of the same artifact) and switch between them.</li><li>For instance, asking Claude to “create an 8-bit crab” creates an artifact that shows a downloadable vector image of a crab. Ryan Morrison of&nbsp;<em>Tom’s Guide</em>&nbsp;<a href="https://www.tomsguide.com/ai/claude-artifacts-is-the-greatest-innovation-in-ai-this-year-5-prompts-to-try-it-now?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">used</a>&nbsp;artifacts to create pixel art, a simple 2D game, and a tool that builds a family tree one relative at a time.&nbsp;</li><li>Developer and designer Meng To&nbsp;<a href="https://x.com/MengTo/status/1809225832466096343?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">showed</a>&nbsp;a tool built with help from Artifacts that enables users to customize a diagram of a vector field in real time by adjusting sliders and menu options.&nbsp;</li><li>Pliny the Prompter, who regularly shares jailbreaks on X,&nbsp;<a href="https://x.com/elder_plinius/status/1804052791259717665?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">found</a>&nbsp;what appears to be a part of Claude’s internal instructions concerning artifacts. The instructions suggest that Claude avoids rendering an artifact if a chat response will do, avoids creating new artifacts in favor of updating existing ones, renders one artifact per text unless requested otherwise, and deliberates silently about whether to create an artifact by generating text between specific XML tags that hide it from the user. (Artifacts themselves are enclosed in a different set of tags.)</li></ul><p><strong>Why it matters:</strong>&nbsp;Artifacts make working with a large language model more fluidly interactive. Large language models (LLMs) have long been able to generate code but, outside of AI-assisted development environments like GitHub with Copilot, executing generated code typically requires further steps such as copy-pasting the code into a development environment. The additional steps add friction for developers and confusion for non-developers. Keeping and running the code in a separate window makes for a convenient, low-friction experience. Likewise when generating images and other kinds of visual output.</p><p><strong>We’re thinking:&nbsp;</strong>It’s rare when a user interface update makes a tool more useful for casual and hardcore users alike. It’s even more exciting to see it happen to an LLM!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--70-.jpg" width="1200" /></figure><h1 id="ai%E2%80%99s-path-to-zero-emissions-is-cloudy">AI’s Path to Zero Emissions Is Cloudy</h1><p>The boom in AI is jeopardizing big tech’s efforts to reach its targets for emissions of greenhouse gasses.</p><p><strong>What’s new:</strong>&nbsp;Google’s&nbsp;<a href="https://blog.google/outreach-initiatives/sustainability/2024-environmental-report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">annual environmental report</a>&nbsp;shows that the company’s total carbon dioxide emissions rose nearly 50 percent between 2019 and 2023 to 14.3 million tons. Google attributes the rise to its efforts to satisfy rising demand for AI.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Google’s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. “As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,” the report states.</p><ul><li>Three-quarters of total emissions, or 10.8 million tons, are associated with purchases that include the data-center hardware and construction. These emissions increased 23 percent from 2019 to 2023 and 8 percent year-over-year.</li><li>Powering, heating, and cooling data centers and other facilities accounted for around a quarter of Google’s 2023 emissions. Emissions from these activities have increased more than four-fold since 2019.</li><li>Low-emissions energy has reduced Google’s total data-center emissions substantially, but some regions don’t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Google’s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.</li></ul><p><strong>Countering the trend:&nbsp;</strong>Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with renewable energy 2029. The company is pursuing several AI-based initiatives to mitigate climate change from weather prediction to fuel-efficient vehicle routing. It says that AI has the potential to mitigate 5 to 10 percent of global greenhouse gas emissions by 2030.</p><p><strong>Behind the news:</strong>&nbsp;In 2020, after five years of successfully&nbsp;<a href="https://www.gstatic.com/gumdrop/sustainability/google-2020-environmental-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">reducing</a>&nbsp;its carbon footprint, Google set an ambitious target to reach net-zero greenhouse gas emissions by 2030. But its total emissions since then have risen each year. Google’s experience mirrors that of Amazon and Microsoft, which aim to reach net-zero carbon emissions by 2030 and 2040 respectively. Amazon’s emissions&nbsp;<a href="https://sustainability.aboutamazon.com/2022-sustainability-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">increased</a>&nbsp;39 percent from 2019 to 2022, while Microsoft’s emissions&nbsp;<a href="https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW1lMjE?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">rose</a>&nbsp;29 percent between 2020 and 2023. (Amazon’s and Microsoft’s cloud computing revenues were roughly triple Google’s in 2023 and thus their AI-related greenhouse case emissions&nbsp; presumably were larger.)</p><p><strong>Why it matters:</strong>&nbsp;Growing use of AI means greater consumption of energy. The tech giants’ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that it’s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;We applaud Google’s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. We’re somewhat relieved to note that, for now, data centers and cloud computing are responsible for&nbsp;<a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">1 percent</a>&nbsp;of the world’s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--71-.jpg" width="1200" /></figure><h1 id="amazon-onboards-adept">Amazon Onboards Adept</h1><p>Amazon hired most of the staff of agentic-AI specialist Adept AI in a move that echoes Microsoft’s absorption of Inflection in March.</p><p><strong>What’s new:</strong>&nbsp;Amazon onboarded most of the leadership and staff of Adept AI, which has been training models to operate software applications running on local hardware,&nbsp;<em>GeekWire</em>&nbsp;<a href="https://www.geekwire.com/2024/amazon-hires-founders-from-well-funded-enterprise-ai-startup-adept-to-boost-tech-giants-agi-team/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">reported</a>. Amazon licensed Adept’s models, datasets, and other technology non-exclusively. The companies did not disclose the financial terms of the deal. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)</p><p><strong>How it works:</strong>&nbsp;Amazon hired two thirds of Adept’s former employees. Those who remain will “focus entirely on solutions that enable agentic AI” based on proprietary models, custom infrastructure, and other technology.&nbsp;</p><ul><li>Amazon hired Adept CEO David Luan and four of his fellow co-founders, all Google or Open AI alumni. They joined Amazon’s artificial general intelligence (AGI) autonomy team, which reports to Amazon head scientist for AGI Rohit Pradad. The autonomy team will build agents that can automate software workflows.</li><li>Adept built agents that control applications on a user’s desktop in response to natural-language commands based on proprietary language and vision-language models. For example, a recruiter could use Adept’s&nbsp;<a href="https://www.adept.ai/blog/experiments?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">technology</a>&nbsp;to find promising job candidates on LinkedIn and import their profiles into a Salesforce database.&nbsp;</li><li>The startup found that the high cost of building foundation models was unsustainable without further fundraising. Although Adept had&nbsp;<a href="https://www.theinformation.com/articles/to-unlock-ai-spending-microsoft-openai-and-google-prep-agents?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">planned</a>&nbsp;to release a full-fledged agentic tool this year, it also&nbsp;<a href="https://www.theinformation.com/articles/ai-agent-startup-adept-has-talked-to-potential-buyers-including-meta?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">explored</a>&nbsp;an outright sale to several companies including Meta.</li><li>As of March 2023, Adept had&nbsp;<a href="https://techcrunch.com/2023/03/15/adept-a-startup-training-ai-to-use-existing-software-and-apis-raises-350m/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">raised</a>&nbsp;a total of $415 million at a valuation of more than $1 billion.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon’s agreement with Adept is one of several moves to compete in AI for both businesses and consumers. In March, the company completed a $4 billion&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">investment</a>&nbsp;in Anthropic in exchange for a minority share in the startup. It’s reportedly developing new models and&nbsp;<a href="https://www.reuters.com/technology/amazon-mulls-5-10-monthly-price-tag-unprofitable-alexa-service-ai-revamp-2024-06-21/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">overhauling</a>&nbsp;its longstanding Alexa voice assistant.</p><p><strong>Why it matters:</strong>&nbsp;Luan and his team say they’re aiming to automate corporate software workflows, a potentially valuable and lucrative market. Although Amazon Web Services’ Bedrock platform already enables users to&nbsp;<a href="https://aws.amazon.com/bedrock/agents/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">build</a>&nbsp;AI agents, Adept’s talent may bring expanded agentic and interactive capabilities.<br /><strong>We’re thinking:</strong>&nbsp;AI agentic capabilities are&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">blossoming</a>, and Adept’s work is a notable example.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-10T143728.158.png" width="600" /></figure><h1 id="like-lora-but-for-pretraining">Like LoRA, But for Pretraining</h1><p>Low-rank adaptation (LoRA) reduces memory requirements when fine-tuning large language models, but it isn’t as conducive to pretraining. Researchers devised a method that achieves similar memory savings but works well for both fine-tuning and pretraining.</p><p><strong>What’s new:&nbsp;</strong>Jiawei Zhao and colleagues at California Institute of Technology, Meta, University of Texas at Austin, and Carnegie Mellon proposed&nbsp;<a href="https://arxiv.org/abs/2403.03507?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">Gradient Low-Rank Projection</a>&nbsp;(GaLore), an optimizer modification that saves memory during training by reducing the sizes of optimizer states. They used this approach to pretrain a 7B parameter transformer using a consumer-grade Nvidia RTX 4090 GPU.</p><p><strong>Key insight:&nbsp;</strong><a href="https://arxiv.org/abs/2106.09685?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">LoRA</a>&nbsp;saves memory during training by learning to approximate a change in the weight matrix of each layer in a neural network using the product of two smaller matrices. This approximation results in good performance when fine-tuning (though not quite as good as fine-tuning all weights) but worse performance when pretraining from a random initialization. The authors proved theoretically that updating weights according to an approximate gradient matrix — which reduces the memory required to store optimizer states — can yield the same performance as using the exact gradient matrix (at least for deep neural networks with ReLU activation functions and classification loss functions). Updating weights only once using an approximate gradient matrix is insufficient. However, updating weights repeatedly using gradient approximations&nbsp;that change with each training step (because the inputs change between training steps)&nbsp;achieves an effect similar to training weights in the usual way.&nbsp;</p><p><strong>How it works:</strong>&nbsp;GaLore approximates a network’s gradient matrix divided into layer-wise matrices. Given a layer’s gradient matrix G (size m x n), GaLore computes a smaller matrix P (size r x m). It uses PG, a smaller approximation of the gradient matrix (size r x n), to update optimizer states.&nbsp;To further save memory, it updates layers one at a time instead of all at once, following&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-method-to-reduce-memory-needs-when-fine-tuning-ai-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">LOMO</a>.&nbsp;</p><ul><li>At each training step, for each layer, GaLore computed the layer-wise gradient matrix normally.</li><li>GaLore computed a smaller matrix P that, when multiplied by the gradient matrix, yielded a smaller matrix that approximated the weight update. GaLore computed P every 200 training steps (that is, it used the same P for 200 training steps at a time before computing a new P).</li><li>GaLore multiplied P by the gradient matrix to compute a smaller, approximate version of the gradient matrix. It used this smaller version to update the Adam optimizer’s internal states, requiring less memory to store the optimizer’s internal states. Then the optimizer used its internal states to update the smaller matrix.</li><li>GaLore multiplied P by the smaller matrix to produce a full-sized approximation of the gradient matrix. It used the full-sized approximation to update the current layer’s weights.&nbsp;</li></ul><p><strong>Results:&nbsp;</strong>The authors tested GaLore in both pretraining and fine-tuning scenarios.</p><ul><li>The authors compared GaLore to Adam while pretraining five transformer architectures from 60 million to 7 billion parameters to generate the next token in&nbsp;<a href="https://arxiv.org/abs/1910.10683v4?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">web text</a>. GaLore (set up to represent its internal states using 8-bit numbers) pretrained LLaMA 7B from scratch using 22GB of memory, while Adam (modified to represent its internal states using 8-bit numbers) needed 46GB of memory. After training on 19.7 billion tokens, LLaMA 7B achieved 14.65 perplexity, while Adam achieved 14.61 perplexity (a measure of how well a model reproduces validation examples, lower is better).</li><li>They also used GaLore to fine-tune RoBERTaBase on the multi-task benchmark&nbsp;<a href="https://aclanthology.org/W18-5446/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">GLUE</a>. GaLore needed 253MB of memory and achieved a score of 85.89 (averaging eight of 11 GLUE tasks), while LoRA needed 257MB of memory and reached 85.61.</li></ul><p><strong>Why it matters:</strong>&nbsp;LoRA’s ability to fine-tune large models using far less memory makes it a very popular fine-tuning method. GaLore is a theoretically motivated approach to memory-efficient training that’s good for both pretraining and fine-tuning.</p><p><strong>We're thinking:&nbsp;</strong>LoRA-style approximation has been unlocking data- and memory-efficient approaches in&nbsp;<a href="https://www.deeplearning.ai/the-batch/apple-unveils-ai-features-in-new-ios-and-macos-update-during-wwdc/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">a</a>&nbsp;<a href="https://arxiv.org/abs/2307.06949?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">variety</a>&nbsp;of machine learning situations — an exciting trend as models grow and demand for compute resources intensifies.</p>
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 19:39:41 GMT</pubDate>
</item>
<item>
<title>OpenAI Blocks China, Tests for Human-Level Models, Music Industry Sues AI Startups, Model Merging Evolves</title>
<link>https://www.deeplearning.ai/the-batch/issue-256</link>
<guid>https://www.deeplearning.ai/the-batch/issue-256</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>As we reach the milestone of the 256th issue of <em>The Batch</em>, I’m reflecting on how AI has changed over the years and how society continues to change with it. As AI becomes more widely available, it’s clear that many people — developers and non-developers — will benefit from high-quality training to keep up with the changes and gain useful AI skills.&nbsp;</p><p>In my years of working in education, I’ve felt that the world has enough low-quality courses, newsletters, social media posts, and other forms of content.&nbsp;It’s possible to build a business churning out mediocre content in sufficient volume to attract a meaningful amount of attention, but I have no interest in doing that.&nbsp;</p><p>At DeepLearning.AI, our core philosophy is to&nbsp;<em>put learners first</em>. Our team obsesses about how to create quality training or other programs that benefit people who want to learn about AI. We have intense debates about what tools to teach, which examples to include, even which partners to work with, based on what we think is best for learners.</p><p>For example, I recall vividly how, when working on the&nbsp;<em>Machine Learning Specialization</em>, our team spent ages debating whether to use row or column matrices. Both sides showed up with deep analysis of the pros and cons, made Powerpoint presentations to argue their case, and we spent hours debating over what was better for learners in terms of both ease of picking up the concepts as well as subsequently being able to use these skills with third-party machine learning libraries.&nbsp;</p><p>We don’t release a course unless we think it’s a good use of a learner’s time and we’d be proud to recommend it to our own friends and family members. Quality, of course, can mean a lot of things. I expect what we do to be technically accurate, useful, up to date, clear, and time-efficient for learners. And, if possible, fun!&nbsp;</p><p>We don’t always get it right, but we scrutinize learner feedback (one of my most important weekly routines is to study a dashboard that summarizes learner ratings of our courses) and work to make sure our courses serve learners well. And yes, we have a large-language model powered application that reads learner reviews to flag important issues quickly.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--66--1.jpg" width="1200" /></figure><p>Earlier this year, we realized that some of the paid content we had launched was below our quality standard, and that I wouldn’t in good conscience recommend it to my friends or family members. Despite this content being profitable, we did what we felt was the right thing for learners. So we decided to retire that content and forgo the revenues, but we feel much better now for having done the right thing for learners.&nbsp;</p><p>When we teach courses with partners, we tell them our priorities are “learners first, partners second, ourselves last.” I’m grateful to the many wonderful companies and individuals that work with us to teach cutting-edge techniques, and given an opportunity we try to support our partners’ goals as well. But we never prioritize the interest of our educational partners over that of learners. Fortunately, our partners are onboard with this as well. We have a common goal to serve learners. Without their help, it would be difficult to teach many of the topics we do with high-quality content.&nbsp;</p><p>Quite a few companies have tried to offer to pay us to teach a course with them, but we’ve always said no. We work only with the companies that we think help us serve learners best, and are not interested in being paid to teach lower quality courses.</p><p>One reason I obsess about building quality training materials is that I think learning must be a habit. Learning a little every week is important to get through the volume of learning we all need, and additionally to keep up with changing technology. High-quality training that’s also fun supports a healthy learning habit!&nbsp;</p><p>Fun fact: In addition to taking online courses, I also read a lot. Recently I noticed that my digital reading app says I’ve been on a reading streak for 170 weeks. I’ve used the app for many years, but apparently I had broken and restarted my streak 170 weeks ago. What happened then? That was the week that my son was born,&nbsp;<a href="https://www.deeplearning.ai/the-batch/coursera-goes-public/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Coursera became a public company</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-key-to-longevity/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">my grandfather</a>&nbsp;died. While my life has had disruptions since then, I was happy to find that it takes a disruption of this magnitude to make me pause my learning habit for a week.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-ai-fund-and-deeplearningai">A MESSAGE FROM AI FUND AND&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://us06web.zoom.us/webinar/register/3017198521323/WN_cYpQlgFdRDeXBy61YuiO7w?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="540" src="https://dl-staging-website.ghost.io/content/images/2024/07/AIF_Event-Templates--18-.png" width="960" /></a></figure><p>Join us for a Q&amp;A webinar on July 11, 2024, at 11:00 AM Pacific Time. Andrew Ng and Roy Bahat will discuss business trends and strategies to integrate AI into organizations.&nbsp;<a href="https://us06web.zoom.us/webinar/register/3017198521323/WN_cYpQlgFdRDeXBy61YuiO7w?ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a>&nbsp;</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T153037.104.gif" width="1200" /></figure><h1 id="openai-blocks-china-and-elsewhere">OpenAI Blocks China and Elsewhere</h1><p>OpenAI will stop serving users in China and other nations of concern to the U.S. government as soon as next week.</p><p><strong>What’s new:</strong>&nbsp;Open AI notified users in China they would lose API access on July 9,&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-cut-access-tools-developers-china-other-regions-chinese-state-media-says-2024-06-25/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">reported</a>. The move affects users in countries where the company doesn’t support access to its services officially (which include Cuba, Iran, Russia, North Korea, Syria, Venezuela, and others), but where it appears to have been serving API calls anyway.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Previously OpenAI blocked requests from outside&nbsp;<a href="https://platform.openai.com/docs/supported-countries?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">supported countries</a>&nbsp;if it detected a virtual private network or other method to circumvent geographic restrictions, but it had enforced such limits lightly&nbsp;<a href="https://www.stcn.com/article/detail/1240148.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">according to</a>&nbsp;<em>Securities Times</em>. The email warning started a race among AI companies in China to attract cast-off OpenAI users.</p><ul><li>Baidu said it would give former OpenAI users 50 million free tokens for its&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/baidu-launches-upgraded-ai-model-says-user-base-hits-300-mln-2024-06-28/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Ernie</a>&nbsp;model, additional tokens equivalent to a customer’s OpenAI credits, and unlimited access to older models like&nbsp;<a href="http://research.baidu.com/Blog/index-view?id=165&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Wenxin</a>. Alibaba Cloud offered 22 million free tokens for Qwen-plus.&nbsp;<a href="https://open.bigmodel.cn/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Zhipu AI</a>, a lesser-known startup, promised 50 million free tokens for its GPT-4 competitor&nbsp;<a href="https://arxiv.org/abs/2406.12793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GLM-4</a>&nbsp;and 100 million tokens for the lower-cost GLM-4 Air.</li><li>Microsoft&nbsp;<a href="https://www.scmp.com/tech/big-tech/article/3268233/microsoft-maintains-ai-services-hong-kong-openai-curbs-api-access-china?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">announced</a>&nbsp;that customers in Hong Kong would be able to address OpenAI models via Azure, which has served the models there despite lack of official support by OpenAI. For the rest of China, Microsoft posted on WeChat a&nbsp;<a href="https://mp.weixin.qq.com/s?__biz=MzA3MTA0ODYyOA%3D%3D&amp;mid=2651435559&amp;idx=1&amp;sn=9a79957563b140a2ef66cc092ded6f41&amp;chksm=84ce9efcb3b917ea3a4ccdd7d562ae4af729dcf51f538a3ae0a02ff4f35799254db4aa075a81&amp;mpshare=1&amp;scene=1&amp;srcid=06263qGLSaYOd75H5Ut3mbDy&amp;sharer_shareinfo=1162dec359fd32b1e0f9ab27bca64d29&amp;sharer_shareinfo_first=1162dec359fd32b1e0f9ab27bca64d29&amp;exportkey=n_ChQIAhIQu31uFQMTmt32Lmlng1rskRKfAgIE97dBBAEAAAAAAEKHDC3c4zIAAAAOpnltbLcz9gKNyK89dVj02BUGLGQW6qhJxWwjTzJSaQtJPMCHTG1%2BZ6KELT9TQemKJjC8gpUGfomNIndMiy96lThhvVsiRrH1r%2FLMdfwTXH1iucLZpU1yxw5ZayJcG27r7fxMruMVgr%2BX4ECa6T%2BvtSYD1nrs9UrJG1g3XzazMhwv4MMKAK5LlxIXCh%2F92nSH11CAmSUPOBb9wIR2FY703EhwgIrMyoKmIT6Jw5vLeszRZhtVUUek9cvbIJzV9ebGNIrEIDPUig39jor6GLojmQfaDH8U0CpTwM%2FXe%2FtxmtwnxDa2eOUi7%2BBmBBoYemMvrGawuLIQvnnaFv6rzukCEmEBvF2nzx%2FZ&amp;acctmode=1&amp;pass_ticket=pMFyhjLD%2BzeFaSyQmWmbCVUa5OdfdTucMEjXf1S6W0wIuUG2iyTKNMer14boYLTT&amp;wx_header=0&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_#rd" rel="noopener">guide</a>&nbsp;to migrating from Open AI’s API to equivalent service by Microsoft’s Chinese partner 21Vianet.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI’s crackdown on non-supported countries comes amid rising technological rivalry between the governments of the United States and China. The U.S. has taken several steps to try to curb China’s access to U.S.-built AI hardware and software, and some U.S. AI companies such as Anthropic and Google don’t operate in China. The Commerce Department&nbsp;<a href="https://www.reuters.com/technology/us-eyes-curbs-chinas-access-ai-software-behind-apps-like-chatgpt-2024-05-08/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">plans</a>&nbsp;to attempt to restrict China’s access to the most advanced AI models built by U.S. developers such as OpenAI. The Treasury Department&nbsp;<a href="https://home.treasury.gov/news/press-releases/jy2421?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">issued</a>&nbsp;draft restrictions on U.S. investments in AI companies based in China, Hong Kong, and Macau. Moreover, the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">imposed</a>&nbsp;controls on exports of advanced GPUs to Chinese customers.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Many startups in China and elsewhere relied on OpenAI’s models. However, China’s development of AI models is already quite advanced. For example, Alibaba’s Qwen2, which offers open weights, currently tops Hugging Face’s Open LLM Leaderboard (see below), ahead of Meta's Llama 3.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Efforts to restrict U.S. AI technology can go only so far. At this point, the U.S. seems to have at most a six-month lead over China. OpenAI’s move encourages other nations to make sure they have robust, homegrown models or access to open source alternatives.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T153334.258.png" width="600" /></figure><h1 id="challenging-human-level-models">Challenging Human-Level Models</h1><p>An influential ranking of open models revamped its criteria, as large language models approach human-level performance on popular tests.</p><p><strong>What’s new:</strong>&nbsp;Hugging Face&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard/blog?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">overhauled</a>&nbsp;its Open LLM Leaderboard, reshuffling its assessments of the smartest contenders. The&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">revised leaderboard</a>&nbsp;is based on new benchmarks designed to be more challenging and harder to game.</p><p><strong>Intelligence reordered:</strong>&nbsp;The new Open LLM Leaderboard paints a very different picture than the earlier version: Some models moved up or down as many as 59 places. In the debut rankings, Qwen2’s recently&nbsp;<a href="https://www.deeplearning.ai/the-batch/new-models-from-nvidia-alibaba-and-stability-ai-expand-open-options/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">released</a>&nbsp;72-billion-parameter, instruction-tuned version topped the list with an average score of 43.02 out of 100. Meta’s Llama 3-70B-Instruct came in second with 36.67.<br /><br /><strong>Addressing saturation and contamination:</strong>&nbsp;Launched last year, the&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">earlier version</a>&nbsp;(which is still operating) ranks open large language models according to an aggregate of scores on six popular benchmarks. However, in the intervening months, the best models approached human-level scores, partly due to technical improvements and partly because the test answers leaked into the models’ training sets. The revised leaderboard replaces the old tests and corrects earlier flaws and errors:</p><ul><li><a href="https://arxiv.org/abs/2406.01574?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MMLU-Pro</a>&nbsp;updates the MMLU set of multiple-choice questions. MMLU-Pro offers 10 choices, while the earlier version offered four. The authors eliminated questions deemed too easy and made many others more difficult by, for instance, adding misleading answers. The results correlate well with human preferences as determined by the&nbsp;<a href="https://www.deeplearning.ai/the-batch/chatbot-arena-compares-chatbots-side-by-side?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">LMSYS Chatbot Arena</a>.</li><li><a href="https://arxiv.org/abs/2311.12022?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GPQA</a>&nbsp;includes PhD-level questions in biology, physics, and chemistry. It’s intended to be very difficult for non-experts even with access to web search.</li><li><a href="https://arxiv.org/abs/2310.16049?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MuSR</a>&nbsp;asks models to answer lengthy, complex word problems that test multi-step reasoning. To do well, a model must solve murder mysteries, assign characters to perform tasks, and identify the locations of objects in a narrative.</li><li><a href="https://arxiv.org/abs/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MATH lvl 5</a>&nbsp;includes multi-step math problems. The dataset covers five levels based on difficulty, but the benchmark includes only the hardest level.</li><li><a href="https://arxiv.org/abs/2311.07911?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">IFEval</a>&nbsp;asks models to respond to prompts that include specific instructions like “no capital letters are allowed” and “your response must have three sections.”</li><li><a href="https://arxiv.org/abs/2210.09261?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">BIG-Bench Hard</a>&nbsp;covers 23 diverse, complex tasks, such as understanding boolean expressions, detecting sarcasm, and determining shapes from graphics vectors. Examples are drawn from the most formidable problems in BIG-Bench. Like MMLU-PRo, BIG-Bench Hard scores correlate well with those of the LMSYS Chatbot Arena.</li></ul><p><strong>Behind the news:</strong>&nbsp;Leakage of training examples into test sets is a rising challenge to evaluating model performance. While Hugging Face relies on open benchmarks, other groups have attempted to address the issue by limiting access to the test questions or changing them regularly. Vals.AI, an independent model testing company,&nbsp;<a href="https://www.deeplearning.ai/the-batch/vals-ai-evaluates-large-language-models-on-industry-specific-tasks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">developed</a>&nbsp;proprietary industry-specific tests for finance and law. Data consultancy Scale AI&nbsp;<a href="https://www.deeplearning.ai/the-batch/private-benchmarks-for-fairer-tests/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">introduced</a>&nbsp;its own leaderboards, measuring models on proprietary tests in natural languages, math, and coding.<br /><br /><strong>Why it matters:</strong>&nbsp;Two million unique visitors browsed the Open LLM Leaderboard in the past year, and over 300,000 Hugging Face community members use and collaborate on it each month. Developers trust its scores, both individually and in aggregate, to decide which models to use and to judge the progress of their own efforts based on open models.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;As its name implies, the Open LLM leaderboard measures performance in natural language skills. Hugging Face also maintains an&nbsp;<a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Open VLM Leaderboard</a>, which tests vision-language skills.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--67-.jpg" width="1200" /></figure><h1 id="music-industry-sues-ai-startups">Music Industry Sues AI Startups</h1><p>A smoldering conflict between the music industry and AI companies exploded when major recording companies sued up-and-coming AI music makers.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Sony Music, Universal Music Group (UMG), and Warner Music — the world’s three largest music companies — and a trade organization, Recording Industry Association of America (RIAA),&nbsp;<a href="https://www.riaa.com/record-companies-bring-landmark-cases-for-responsible-ai-againstsuno-and-udio-in-boston-and-new-york-federal-courts-respectively/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">sued</a>&nbsp;Suno and Udio, which offer web-based music generators, for alleged copyright violations.<br /><br /><strong>How it works:</strong>&nbsp;The music powers filed separate lawsuits against&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/Suno-complaint-file-stamped20.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Suno</a>&nbsp;and&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/Udio-Complaint-6.24.241.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Udio</a>&nbsp;in U.S. federal courts. The plaintiffs allege that the startups used copyrighted songs owned by RIAA members as training data, in the process making unauthorized copies without receiving permission or compensating the owners. They seek damages of at least $150,000 per song and cessation of further AI training on their catalogs.</p><ul><li>The recording companies argue that training AI models on songs involves making a number of unauthorized copies of the original music, first by scraping the audio files, then cleaning, converting file formats, dividing songs into subunits, and fine-tuning.</li><li>To show that the startups had trained their models on copyrighted music, the recording companies presented&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/AITrainedonCopyrighted.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">examples</a>&nbsp;(most of which are no longer available) in which they prompted a model to generate a copyrighted work. For instance, given the prompt, “m a r i a h c a r e y, contemporary r&amp;b, holiday, Grammy Award-winning American singer-songwriter, remarkable vocal range,” Udio allegedly generated a facsimile of “All I Want for Christmas is You” by Mariah Carey. Other prompts that caused a model to generate an existing song included the song’s lyrics but not the artist’s name.</li><li>The lawsuits claim that generated music directly competes with original music because Suno and Udio charge for their services and generated music can be used in lieu of copyrighted music. Furthermore, they claim the models’ outputs are not sufficiently transformative of copyrighted works for the copying to be considered fair use.&nbsp;</li><li>Udio did not address the specific allegations. In a blog post, it&nbsp;<a href="https://www.udio.com/blog/ai-and-the-future-of-music?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">compared</a>&nbsp;its models to music students learning and taking inspiration from accomplished musicians. Suno’s CEO&nbsp;<a href="https://www.billboard.com/pro/ai-music-lawsuit-suno-udio-respond-major-labels/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">told</a>&nbsp;<em>Billboard</em>, a music-industry trade magazine, that the company’s technology is transformative rather than copying.</li></ul><p><strong>Behind the news:</strong>&nbsp;Although major music companies have a history of&nbsp;<a href="https://www.deeplearning.ai/the-batch/universal-music-group-targets-ai-generated-music/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">taking</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-music-accuses-ai-developers-of-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">action</a>&nbsp;against AI companies, music streamers, and musicians who distributed generated likenesses of music they owned, they’re also working with AI startups on their own terms. For instance, UMG is&nbsp;<a href="https://www.rollingstone.com/music/music-news/umg-startsai-voice-clone-partnership-with-soundlabs-1235041808/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">collaborating</a>&nbsp;with voice-cloning startup Soundlabs to create authorized synthetic voices of UMG artists. UMG, Sony, and Warner are also&nbsp;<a href="https://www.ft.com/content/e2d9472d-32e0-43f5-8109-efb753fac330?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">negotiating</a>&nbsp;with YouTube to license music for a song generator to be launched this year.</p><p><strong>Why it matters:</strong>&nbsp;As in similar lawsuits that involve text generators, the outcome of these actions could have an important impact on AI developers and users alike. Copyright law in the United States (and many other countries) does not address whether training AI models on copyrighted materials is a use that requires permission from copyright owners. In lieu of further legislation that answers the question, courts will decide. Assuming these cases go to trial, a verdict in favor of Suno or Udio would set a precedent that copyright doesn’t necessarily protect copyrighted works from AI training. Conversely, a verdict in favor of the music industry could restrict the use of copyrighted works in training, impeding a range of AI technologies that historically have been trained on data from the open internet.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Copyright aims to prohibit unauthorized copying of intellectual property, but routine copying of data is built into the infrastructure of digital communications, never mind training AI systems. A web browser makes a temporary copy of every web page it displays, and web search engines typically copy the page they’ve indexed. It’s high time to&nbsp;<a href="https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">revise</a>&nbsp;copyright law for the AI era in ways that create the most value for the most people.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T154036.152.gif" width="600" /></figure><h1 id="model-merging-evolves">Model Merging Evolves</h1><p>The technique of model merging combines separate models into a single, more capable model without further training, but it requires expertise and manual effort. Researchers automated the process.</p><p><strong>What's new:</strong>&nbsp;Takuya Akiba and colleagues at Sakana, a research lab based in Tokyo, devised an automated&nbsp;<a href="https://arxiv.org/abs/2403.13187?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">method for merging models</a>. It combines models trained for general tasks to produce models that perform well at the intersection of those tasks.</p><p><strong>Key insight:</strong>&nbsp;Researchers have demonstrated various&nbsp;<a href="https://arxiv.org/abs/2309.15698?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">approaches</a>&nbsp;to model merging. Earlier work showed that vision models of the same architecture can be combined with good results simply by&nbsp;<a href="https://www.deeplearning.ai/the-batch/ensemble-models-simplified/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">averaging their corresponding weights</a>, although subsequent studies revealed limitations in this approach. (When models have different architectures, averaging weights can combine parts they have in common.) An alternative is to&nbsp;<a href="https://arxiv.org/pdf/2312.15166?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">stack layers</a>&nbsp;drawn from different models. These methods can be varied and integrated to offer a wide variety of possible model combinations. An automated process that tries various combinations at random, finds the best performers among the resulting models, and recombines them at random can discover the high-performance combinations of these approaches without relying on intuition and experience.</p><p><strong>How it works:</strong>&nbsp;The authors aimed to build a large language model that would solve problems in Japanese. They used the algorithm known as&nbsp;<a href="https://www.semanticscholar.org/paper/The-CMA-Evolution-Strategy%3A-A-Comparing-Review-Hansen/95a1f9e009d16e141448fbfea33353b02e1e9335?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Covariance Matrix Adaptation Evolution Strategy</a>&nbsp;(CMA-ES) to merge the Japanese-language LLM&nbsp;<a href="https://hf.co/augmxnt/shisa-gamma-7b-v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Shisa-Gamma</a>&nbsp;and two math-specific, English-language LLMs:&nbsp;<a href="https://gair-nlp.github.io/abel/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Abel</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2308.09583?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">WizardMath</a>. All three models were fine-tuned from&nbsp;<a href="https://arxiv.org/abs/2310.06825?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Mistral 7B</a>, which was pretrained on text from the web.</p><ul><li>The authors produced dozens of 10 billion-parameter models by merging the three initial ones. They merged the models by (i) combining weights of two or more layers from each model according to&nbsp;<a href="https://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">TIES-Merging</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2311.03099?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">DARE</a>&nbsp;and (ii) stacking either the combined layers or the original ones.&nbsp;</li><li>They evaluated the merged models on 1,069 examples translated into Japanese from&nbsp;<a href="https://arxiv.org/abs/2110.14168?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GSM8k</a>, which contains grade-school word problems.&nbsp;</li><li>They saved the models that performed best and repeated the process more than 100 times, merging the saved models and measuring their performance. The final model was the one with the highest accuracy on the translated GSM8k examples.</li></ul><p><strong>Results:</strong>&nbsp;The authors evaluated their model on the Japanese subset of&nbsp;<a href="https://arxiv.org/abs/2210.03057?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Multilingual Grade School Math</a>&nbsp;(MGSM). The merged model achieved 55.2 percent accuracy. Among the source models, Abel achieved 30.0 percent accuracy, WizardMath 18.4 percent accuracy, and Shisa Gamma 9.6 percent accuracy. The merged model’s performance fell between that of GPT-3.5 (50.4 percent accuracy) and GPT-4 (78.8 percent accuracy), which presumably are an order of magnitude larger.</p><p><strong>Why it matters:</strong>&nbsp;Combining existing models offers a way to take advantage of their strengths without further training. It can be especially valuable in building models at the intersection between tasks, such as understanding Japanese language and solving math problems.</p><p><strong>We're thinking:</strong>&nbsp;In addition to building new models, how can we make best use of the ones we already have? Merging them may be an efficient option.</p>
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 20:43:25 GMT</pubDate>
</item>
<item>
<title>AI Monopolies, Ancestor Avatars, Benchmarks for Agentic Behavior, Chatbot for Minority Languages</title>
<link>https://www.deeplearning.ai/the-batch/issue-255</link>
<guid>https://www.deeplearning.ai/the-batch/issue-255</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>On Monday, a number of large music labels&nbsp;<a href="https://www.nytimes.com/2024/06/25/arts/music/record-labels-ai-lawsuit-sony-universal-warner.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">sued</a>&nbsp;AI music makers Suno and Udio for copyright infringement. Their lawsuit echoes&nbsp;<em>The New York Times</em>’&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">lawsuit</a>&nbsp;against OpenAI in December. The question of what’s fair when it comes to AI software remains a difficult one.&nbsp;</p><p>I&nbsp;<a href="https://x.com/AndrewYNg/status/1744433663969022090?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">spoke</a>&nbsp;out in favor of OpenAI’s side in the earlier lawsuit. Humans can learn from online articles and use what they learn to produce novel works, so I’d like to be allowed to use AI to do so. Some people criticized my view as making an unjustifiable equivalence between humans and AI. This made me realize that people have at least two views of AI: I view AI as a tool we can use and direct to our own purposes, while some people see it as akin to a separate species, distinct from us, with its own goals and desires.</p><p>If I’m allowed to build a house, I want to be allowed to use a hammer, saw, drill, or any other tool that might get the job done efficiently. If I’m allowed to read a webpage, I’d like to be allowed to read it with any web browser, and perhaps even have the browser modify the page’s formatting for accessibility. More generally, if we agree that humans are allowed to do certain things — such as read and synthesize information on the web — then my inclination is to let humans direct AI to automate this task.&nbsp;</p><p>In contrast to this view of AI as a tool, if someone thinks humans and AI are akin to separate species, they’ll frame the question differently. Few people today think all species should have identical rights. If a mosquito annoys a human, the mosquito can be evicted (or worse). In this view, there’s no reason to think that, just because humans are allowed to do something, AI should be allowed to do it as well.&nbsp;</p><p>To be clear, just as humans aren’t allowed to reproduce large parts of copyrighted works verbatim (or nearly verbatim) without permission, AI shouldn’t be allowed to do so either. The lawsuit against Suno and Udio points out that, when prompted in a particular way, these services can nearly reproduce pieces of copyrighted music.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--64--1.jpg" width="1200" /></figure><p>But here, too, there are complex issues. If someone were to use a public cloud to distribute online content in violation of copyright, typically the person who did that would be at fault, not the cloud company (so long as the company took reasonable precautions and didn’t enable copyright infringement deliberately). The plaintiffs in the lawsuit against Suno and Udio managed to write prompts that caused the systems to reproduce copyrighted work. But is this like someone managing to get a public cloud to scrape and distribute content in a way that violates copyright? Or is this — as OpenAI&nbsp;<a href="https://openai.com/index/openai-and-journalism/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">said</a>&nbsp;— a rare bug that AI companies are working to eliminate?&nbsp;(Disclaimer: I’m not a lawyer and I’m not giving legal advice.)</p><p>Humans and software systems use very different mechanisms for processing information. So in terms of what humans can do — and thus what I’d like to be allowed to use software to help me do — it’s helpful to consider the inputs and outputs. Specifically, if I’m allowed to listen to a lot of music and then compose a novel piece of music, I would like to be allowed to use AI to implement a similar input-to-output mapping. The process for implementing this mapping may be training a neural network on music that’s legally published on the open internet for people to enjoy without encumbrances.</p><p>To acknowledge a weakness of my argument, just because humans are allowed to emit a few pounds of carbon dioxide per day simply by breathing doesn’t mean we should allow machines to emit massively more carbon dioxide without restrictions. Scale can change the nature of an act.&nbsp;</p><p>When I was a high-school student in an internship job, I spent numerous hours photocopying, and I remember wishing I could automate that repetitive work. Humans do lots of valuable work, and AI, used as a tool to automate what we do, will create lots of value. I hope we can empower people to use tools to automate activities they’re allowed to do, and erect barriers to this only in extraordinary circumstances, when we have clear evidence that it creates more harm than benefit to society.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/carbon-aware-computing-for-genai-developers?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-25T085213.553.png" width="1680" /></a></figure><p>Learn to reduce the carbon footprints of your AI projects in “Carbon Aware Computing for GenAI Developers,” a new course built in collaboration with Google Cloud. Perform model training and inference jobs with cleaner, low-carbon energy and make your AI development greener!&nbsp;<a href="https://www.deeplearning.ai/short-courses/carbon-aware-computing-for-genai-developers?ref=dl-staging-website.ghost.io" rel="noreferrer">Join today</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T151248.547.png" width="1200" /></figure><h1 id="us-to-probe-ai-monopoly-concerns">U.S. to Probe AI Monopoly Concerns</h1><p>U.S. antitrust regulators are preparing to investigate a trio of AI giants.</p><p><strong>What’s new:</strong>&nbsp;Two government agencies responsible for enforcing United States anti-monopoly laws agreed to investigate Microsoft, Nvidia, and OpenAI,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">reported</a>.&nbsp;</p><p><strong>How it works:&nbsp;</strong>The Department of Justice (DOJ) will investigate Nvidia, which dominates the market for chips that train and run neural networks. The Federal Trade Commission (FTC) will probe Microsoft and its relationship with OpenAI, which together control the distribution of OpenAI’s popular GPT-series models. In February, FTC chair Lina Khan&nbsp;<a href="https://hls.harvard.edu/today/ftc-chair-lina-khan-discusses-ai-antitrust-concerns-at-harvard-law-school/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">said</a>&nbsp;the agency would look for possible anti-competitive forces in the AI market.&nbsp;</p><ul><li>The DOJ is concerned that Nvidia may use unfair practices to maintain its market dominance. They may look into Nvidia’s CUDA software, which strengthens users’ reliance on its chips. They may also explore&nbsp;<a href="https://www.wsj.com/tech/ai/nvidias-french-offices-raided-in-cloud-computing-competition-inquiry-97c094ea?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">claims</a>&nbsp;raised by French authorities that Nvidia favors some cloud computing firms over others.</li><li>The FTC worries that the partnership between OpenAI and Microsoft, which owns 49 percent of OpenAI and&nbsp;<a href="https://www.theverge.com/2023/11/29/23981848/sam-altman-back-open-ai-ceo-microsoft-board?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">holds</a>&nbsp;a non-voting seat on OpenAI’s board of directors, may work to limit consumer choice. Microsoft’s April&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-pays-inflection-ai-650-million-hires-most-of-its-staff/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">agreement</a>&nbsp;with Inflection AI to hire most of its staff in return for a $650 million payment, which resembled an acquisition but left Inflection’s corporate structure intact, raised suspicions that the deal had been structured to avoid automatic antitrust scrutiny.&nbsp;</li><li>The FTC previously investigated investments in Anthropic by&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Amazon</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Google</a>&nbsp;as well as whether OpenAI&nbsp;<a href="https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">gathered</a>&nbsp;training data in ways that harmed consumers.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Government attention to top AI companies is rising worldwide. Microsoft’s partnership with OpenAI&nbsp;<a href="https://www.reuters.com/technology/microsofts-openai-investment-risks-eu-merger-probe-eu-regulators-say-2024-01-09/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">faces</a>&nbsp;additional scrutiny by European Union regulators, who are probing whether the relationship violates EU regulations that govern corporate mergers. U.K. regulators are&nbsp;<a href="https://apnews.com/article/microsoft-amazon-anthropic-ai-investment-scrutiny-a52f6409fa6ee9b335ab6801b8e84cde?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">investigating</a>&nbsp;Amazon’s relationship with Anthropic and Microsoft’s relationship with Mistral and Inflection AI. Last year, French regulators&nbsp;<a href="https://www.wsj.com/tech/ai/nvidias-french-offices-raided-in-cloud-computing-competition-inquiry-97c094ea?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">raided</a>&nbsp;an Nvidia office over suspected anti-competitive practices. In 2022, Nvidia&nbsp;<a href="https://edition.cnn.com/2022/02/08/tech/nvidia-arm-deal-softbank-intl-hnk/index.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">withdrew</a>&nbsp;a bid to acquire chip designer Arm Holdings after the proposal attracted international regulatory scrutiny including an FTC lawsuit.</p><p><strong>Why it matters:</strong>&nbsp;Microsoft, Nvidia, and OpenAI have put tens of billions of dollars each into the AI market, and lawsuits, settlements, judgments, or other interventions could shape the fate of those investments. The FTC and DOJ similarly&nbsp;<a href="https://www.reuters.com/article/idUSKCN1T42JF/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">divided</a>&nbsp;their jurisdictions in 2019, resulting in investigations into — and ongoing lawsuits against — Amazon, Apple, Google, and Meta for alleged anti-competitive practices in search, social media, and consumer electronics. Their inquiries into the AI market could have similar impacts.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Governments must limit unfair corporate behavior without stifling legitimate activities. Recently, in the U.S. and Europe, the pendulum has swung toward overly aggressive enforcement. For example, government opposition to Adobe’s purchase of Figma had a chilling effect on acquisitions that seems likely to hurt startups. The UK blocked Meta’s acquisition of Giphy, which didn’t seem especially anticompetitive. We appreciate antitrust regulators’ efforts to create a level playing field, and we hope they’ll take a balanced approach to antitrust.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T152037.544.gif" width="1200" /></figure><h1 id="chatbot-for-minority-languages">Chatbot for Minority Languages</h1><p>An AI startup that aims to crack markets in southern Asia launched a multilingual competitor to GPT-4.</p><p><strong>What’s new:</strong>&nbsp;The company known as Two AI&nbsp;<a href="https://www.two.ai/sutra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">offers</a>&nbsp;SUTRA, a low-cost language model built to be proficient in more than 30 languages, including underserved South Asian languages like Gujarati, Marathi, Tamil, and Telugu. The company also launched&nbsp;<a href="https://chat.two.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">ChatSUTRA</a>, a free-to-use web chatbot based on the model.</p><p><strong>How it works:</strong>&nbsp;SUTRA comprises two mixture-of-experts transformers: a concept model and an encoder-decoder for translation. A&nbsp;<a href="https://arxiv.org/abs/2405.06694?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">paper</a>&nbsp;includes some technical details, but certain details and a description of how the system fits together are either absent or ambiguous.&nbsp;</p><ul><li>The concept model learned to predict the next token. The training dataset included publicly available datasets in a small number of languages for which abundant data is available, including English.</li><li>Concurrently, the translation model learned to translate 100 million human- and machine-translated conversations among many languages. This model learned to map concepts to similar embeddings across all languages in the dataset.&nbsp;</li><li>The authors combined the two models, so the translation model’s encoder fed the concept model, which in turn fed the translation model’s decoder, and further trained them together. More explicitly, during this stage of training and at inference, the translation model’s encoder receives text and produces an initial embedding. The concept model processes the embedding and delivers its output to the translation model’s decoder, which produces the resulting text.&nbsp;</li><li>SUTRA is available via an&nbsp;<a href="https://docs.two.ai/aboutsutra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">API</a>&nbsp;in versions that are designated Pro (highest-performing), Light (lowest-latency), and Online (internet-connected). SUTRA-Pro and SUTRA-Online cost $1 per 1 million tokens for input and output. SUTRA-Light costs $0.75 per 1 million tokens.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;On&nbsp;<a href="https://huggingface.co/datasets/alexandrainst/m_mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">multilingual MMLU</a>&nbsp;(a machine-translated version of multiple-choice questions that cover a wide variety of disciplines), SUTRA outperformed GPT-4 in four of the 11 languages for which the developer reported the results: Gujarati, Marathi, Tamil, and Telugu. Moreover, SUTRA’s tokenizer is highly efficient, making the model fast and cost-effective. In key languages, it compares favorably to the tokenizer used with GPT-3.5 and GPT-4, and even narrowly outperforms GPT-4o’s improved tokenizer, according to Two AI’s tokenizer comparison&nbsp;<a href="https://huggingface.co/spaces/TWO/sutra-tokenizer-comparison?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">space</a>&nbsp;on HuggingFace. In languages such as Hindi and Korean that are written in non-Latin scripts and for which GPT-4 performs better on MMLU, SUTRA’s tokenizer generates less than half as many tokens as the one used with GPT-3.5 and GPT-4, and slightly fewer than GPT-4o’s tokenizer.<br /><br /><strong>Yes, but:</strong>&nbsp;Multilingual MMLU tests only 11 of SUTRA’s 33 languages, making it difficult to fully evaluate the model’s multilingual performance.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Two AI was founded in 2021 by Pranav Mistry, former president and CEO of Samsung Technology &amp; Advanced Research Labs. The startup has offices in California, South Korea, and India. In 2022, it raised $20 million in seed funding from Indian telecommunications firm Jio and South Korean internet firm Naver. Mistry aims to focus on predominantly non-English-speaking markets such as India, South Korea, Japan, and the Middle East, he&nbsp;<a href="https://analyticsindiamag.com/jio-backed-startup-two-ai-unveils-chatsutra-indias-answer-to-chatgpt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">told</a>&nbsp;<em>Analytics India</em>.</p><p><strong>Why it matters:</strong>&nbsp;Many top models work in a variety of languages, but from a practical standpoint, multilingual models remain a frontier in natural language processing. Although SUTRA doesn’t match GPT-4 in all the languages reported, its low price and comparatively high performance may make it appealing in South Asian markets, especially rural areas where people are less likely to speak English. The languages in which SUTRA excels are spoken by tens of millions of people, and they’re the most widely spoken languages in their respective regions. Users in these places have yet to experience GPT-4-level performance in their native tongues.<br /><br /><strong>We’re thinking:</strong>&nbsp;Can a newcomer like Two AI compete with OpenAI? If SUTRA continues to improve, or if it can maintain its cost-effective service, it may yet carve out a niche.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--65-.jpg" width="1200" /></figure><h1 id="conversing-with-the-departed">Conversing With the Departed</h1><p>Advances in video generation have spawned a market for lifelike avatars of deceased loved ones.</p><p><strong>What’s new:&nbsp;</strong>Several companies in China produce interactive videos that enable customers to chat with animated likenesses of dead friends and relatives,&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/05/07/1092116/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">reported</a>.&nbsp;</p><p><strong>How it works:&nbsp;</strong><a href="https://www.france24.com/en/live-news/20231214-chinese-mourners-use-ai-to-digitally-resurrect-the-dead?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Super Brain</a>&nbsp;and&nbsp;<a href="https://guiji.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Silicon Intelligence</a>&nbsp;have built such models for several thousand customers. They provide a modern equivalent of portrait photos of deceased relatives and a vivid way to commune with ancestors.</p><ul><li>The developers use undisclosed tools to stitch photos, videos, audio recordings, and writings supplied by customers into interactive talking-head avatars of deceased loved ones.</li><li>The cost has dropped dramatically. In December 2023, Super Brain charged between $1,400 and $2,800 for a basic chat avatar wrapped in a phone app. Today it charges between $700 and $1,400 and plans eventually to drop the price to around $140. Silicon Intelligence charges between several hundred dollars for a phone-based avatar to several thousand for one displayed on a tablet.</li></ul><p><strong>Behind the news:</strong>&nbsp;The desire to interact with the dead in the form of an AI-generated avatar is neither new nor limited to China. In the U.S., the startup HereAfter AI&nbsp;<a href="https://www.nytimes.com/2023/12/11/technology/ai-chatbots-dead-relatives.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">builds</a>&nbsp;chatbots that mimic the deceased based on interviews conducted while they were alive. Another startup, StoryFile, markets similar capabilities to elders (<a href="https://www.deeplearning.ai/the-batch/star-trek-the-videobot-generation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">pitched</a>&nbsp;by 93-year-old&nbsp;<em>Star Trek</em>&nbsp;star William Shatner) to keep their memory alive for younger family members. The chatbot app&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-replika-chatbot-stopped-flirting-with-users/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Replika</a>&nbsp;began as a project by founder Eugenia Kuyda to virtually resurrect a friend who perished in a car accident in 2015.&nbsp;</p><p><strong>Yes, but:&nbsp;</strong>In China, language models struggle with the variety of dialects spoken by many elders.</p><p><strong>Why it matters:&nbsp;</strong>Virtual&nbsp;<a href="https://www.deeplearning.ai/the-batch/indian-and-southeast-asian-broadcasters-embrace-ai-news-presenters/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">newscasters</a>&nbsp;and&nbsp;<a href="https://www.theinformation.com/articles/tiktok-plots-using-virtual-influencers-for-advertising?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">influencers</a>&nbsp;are increasingly visible on the web, but the technology has more poignant uses. People long to feel close to loved ones who are no longer present. AI can foster that sense of closeness and rapport, helping to fulfill a deep need to remember, honor, and consult the dead.</p><p><strong>We’re thinking:&nbsp;</strong>No doubt, virtual avatars of the dead can bring comfort to the bereaved. But they also bring the risk that providers might manipulate their customers’ emotional attachments for profit. We urge developers to focus on strengthening relationships among living family and friends.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T152214.754.gif" width="1200" /></figure><h1 id="benchmarks-for-agentic-behaviors">Benchmarks for Agentic Behaviors</h1><p>Tool use and planning are key behaviors in agentic workflows that enable large language models (LLMs) to execute complex sequences of steps. New benchmarks measure these capabilities in common workplace tasks.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Recent benchmarks gauge the ability of a large language model (LLM) to use external tools to manipulate corporate databases and to plan events such as travel and meetings.&nbsp;</p><p><strong>Tool use:&nbsp;</strong>Olly Styles, Sam Miller, and colleagues at Mindsdb, University of Warwick, and University of Glasgow proposed&nbsp;<a href="https://arxiv.org/abs/2405.00823?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">WorkBench</a>, which tests an LLM’s ability to use 26 software tools to operate on five simulated workplace databases: email, calendar, web analytics, projects, and customer relationship management. Tools include deleting emails, looking up calendar events, creating graphs, and looking up tasks in a to-do list.</p><ul><li>The benchmark includes 690 problems that require using between zero to 12 tools to succeed. It evaluates individual examples based on whether the databases changed as expected after the final tool had been called (rather than simply whether particular tools were used, as in earlier work). In this way, a model can use tools in any sequence and/or revise its initial choices if they prove unproductive and still receive credit for responding correctly.</li><li>Upon receiving a problem, models are given a list of all tools and an example of how to use each one. Following the&nbsp;<a href="https://arxiv.org/abs/2210.03629?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">ReAct</a>&nbsp;prompting strategy, they’re asked first to reason about the problem and then use a tool. After they’ve received a tool’s output (typically either information or an error message), they’re asked to reason again and choose another tool. The cycle of reasoning, tool selection, and receiving output repeats until the model decides it doesn’t need to use another tool.&nbsp;</li><li>The authors evaluated GPT-4, GPT-3.5, Claude 2, Llama2-70B, and Mixtral-8x7B. GPT-4 performed the best by a large margin: It modified the databases correctly 43 percent of the time. The closest competitor, Claude 2, modified the databases correctly 26 percent of the time.</li></ul><p><strong>Planning:</strong>&nbsp;Huaixiu Steven Zheng, Swaroop Mishra, Hugh Zhang, and colleagues at Google published&nbsp;<a href="https://arxiv.org/abs/2406.04520?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Natural Plan</a>, a benchmark that evaluates an LLM’s ability to (i) plan trips, (ii) arrange a series of meeting times and locations, and (iii) schedule a group meeting. Each example has only one solution.</p><ul><li>The benchmark includes 1,600 prompts that ask the model to plan a trip based on an itinerary of cities, time to be spent in each city, total duration of the trip, days when other people are available to meet, and available flights between cities.&nbsp;</li><li>1,000 prompts ask the model to plan a schedule to meet as many people as possible. The prompts include places, times when people will be in each place, and how long it takes to drive from one place to another.&nbsp;</li><li>1,000 prompts ask the model, given the existing schedules of a number of people, to find a good time for them to meet.</li><li>The authors tested GPT 3.5, GPT-4, GPT-4o, Gemini 1.5 Flash, and Gemini 1.5 Pro, using five-shot prompts (that is, providing five examples for context). Gemini 1.5 Pro achieved the highest scores on planning trips (34.8 percent) and scheduling group meetings (48.9 percent). GPT-4 ranked second for planning trips (31.1), and GPT-4o ranked second for scheduling meetings (43.7 percent). GPT-4 dominated in arranging meetings (47 percent), followed by GPT-40 (45.2 percent).</li></ul><p><strong>Why it matters:</strong>&nbsp;When building&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">agentic workflows</a>, developers must decide on LLM choices, prompting strategies, sequencing of steps to be carried out, tool designs, single- versus multi-agent architectures, and so on. Good benchmarks can reveal which approaches work best.</p><p><strong>We're thinking:</strong>&nbsp;These tests have unambiguous right answers, so agent outputs can be evaluated automatically as correct or incorrect. We look forward to further work to evaluate agents that generate free text output.</p>
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 20:29:04 GMT</pubDate>
</item>
<item>
<title>Open Model Bonanza, Private Benchmarks for Fairer Tests, More Interactive Music Generation, Diffusion + GAN</title>
<link>https://www.deeplearning.ai/the-batch/issue-254</link>
<guid>https://www.deeplearning.ai/the-batch/issue-254</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>On Father’s Day last weekend, I sat with my daughter to help her practice solving arithmetic problems. To give her practice problems, I used&nbsp;<a href="https://github.com/OpenDevin/OpenDevin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">OpenDevin</a>, an open-source agentic coding framework, to write a Python script that generated questions that she enjoyed answering at her own pace. OpenDevin wrote the code much faster than I could have and genuinely improved my and my daughter’s day.&nbsp;</p><p>Six months ago, coding agents were a novelty. They still frequently fail to deliver, but I find that they’re now working well enough that they might be genuinely useful to more and more people!&nbsp;</p><p>Given a coding problem that’s specified in a prompt, the workflow for a coding agent typically goes something like this: Use a large language model (LLM) to analyze the problem and potentially break it into steps to write code for, generate the code, test it, and iteratively use any errors discovered to ask the coding agent to refine its answer. But within this broad framework, a huge design space and numerous innovations are available to experiment with. I’d like to highlight a few papers that I find notable:</p><ul><li>“<a href="https://arxiv.org/abs/2312.13010?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">AgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation</a>,” Huang et al. (2024).&nbsp;</li><li>“<a href="https://arxiv.org/abs/2402.16906?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">LDB: A Large Language Model Debugger via Verifying Runtime Execution Step by Step</a>,” Zhong et al., (2024).&nbsp;</li><li>“<a href="https://arxiv.org/abs/2405.15793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering</a>,” Yang et al. (2024).</li></ul><p>How can we test the code without requiring the user to write test cases? In a multi-agent system, each “agent” is an LLM prompted to play a particular role. An interesting result from&nbsp;<a href="https://arxiv.org/html/2312.13010v2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">AgentCoder</a>&nbsp;shows that having separate agents for writing code and generating tests results in better performance than letting a single agent do both tasks. This is presumably because, if the agent writing the code is also responsible for writing the tests, the tests might be influenced by the code and fail to consider corner cases that the code does not cover.&nbsp;</p><p>When people think of testing code, many initially think of output testing, in which we see if the code generates the correct outputs to a specific set of test inputs. If the code fails a test, an LLM can be prompted to reflect on why the code failed and then to try to fix it. In addition to testing the output, the LDB method is helpful. LDB steps through the code and presents to the LLM values of the variables during intermediate steps of execution, to see if the LLM can spot exactly where the error is. This mimics how a human developer might step through the code to see where one of the computational steps went wrong, and so pinpoint and fix the problem.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154106.403.png" width="600" /></figure><p>A lot of agentic workflows mimic human workflows. Similar to other work in machine learning, if humans can do a task, then trying to mimic humans makes development much easier compared to inventing a new process. However, the authors of&nbsp;<a href="https://arxiv.org/abs/2405.15793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">SWE-agent</a>&nbsp;noticed that many tools that humans use for coding are very inefficient for agents. For example, giving an agent access to a bash shell and having it find a piece of code by executing numerous cd, ls, and cat commands is inefficient, even though humans can do this rapidly. Similarly, visual coding editors like VSCode, emacs, and vim are easy for humans to use, but hard for LLMs (or LMMs) to navigate. Because agents interact with computers differently than humans do, the authors found that building special-purpose tools (functions) to let an agent search, view, and edit codebases resulted in better performance.&nbsp;</p><p>One reason research into coding agents is making rapid progress is that their performance can be evaluated automatically and reliably. With benchmarks like HumanEval, MBPP, and SWE-bench, researchers can try out an idea and automatically test how often it generates correct code. In contrast, even though there’s considerable activity on AI research agents that search the web and synthesize an article (I’ve enjoyed using the open-source&nbsp;<a href="https://github.com/stanford-oval/storm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">STORM</a>&nbsp;system by Stanford's Yijia Shao et al.), they are&nbsp;<a href="https://www.deeplearning.ai/the-batch/we-need-better-evals-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">hard to evaluate</a>&nbsp;and this makes progress harder.&nbsp;</p><p>Github Copilot was released in 2021, and many developers have been getting coding help by prompting LLMs. The rapid evolution from that to more sophisticated coding agents is expanding how computers can help us with coding tasks, and the pace of progress is rapid. With these tools, I expect programming to become even more fun and more productive.</p><p>Keep coding!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-your-own-database-agent?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-11T083858.583.png" width="1680" /></a></figure><p>Develop an AI agent that interacts with tabular data and SQL databases using natural language prompts to simplify querying and extracting insights!&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-your-own-database-agent?ref=dl-staging-website.ghost.io" rel="noreferrer">Start learning for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="Different results from new text-to-image models from Nvidia, Alibaba, and Stability AI" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154252.807.gif" width="600" /></figure><h1 id="more-new-open-models">More New Open Models</h1><p>A trio of powerful open and semi-open models give developers new options for both text and image generation.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Nvidia and Alibaba released high-performance large language models (LLMs), while Stability AI released a slimmed-down version of its flagship text-to-image generator.<br /><br /><strong>How it works:</strong>&nbsp;The weights for Nvidia’s and Alibaba’s new models are fully open, while Stability AI’s are restricted.</p><ul><li>Nvidia offers the&nbsp;<a href="https://research.nvidia.com/publication/2024-06_nemotron-4-340b?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Nemotron-4 340B</a>&nbsp;family of language models, which includes a 340-billion parameter base model as well as versions fine-tuned to follow instructions and to serve as a reward model in reinforcement learning from human feedback. (Nemotron-4 340B-Reward currently&nbsp;<a href="https://huggingface.co/spaces/allenai/reward-bench?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">tops</a>&nbsp;the HuggingFace RewardBench leaderboard, which ranks reward models.) The models, which can work with 4,096 tokens of context, were pretrained on 9 trillion tokens that divide between English-language text, text in over 50 other natural languages, and code in more than 40 programming languages. 98 percent of the alignment training set was generated, and Nvidia also released the generation pipeline. The&nbsp;<a href="https://developer.download.nvidia.com/licenses/nvidia-open-model-license-agreement-june-2024.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;allows people to use and modify the model freely except for illegal uses.&nbsp;</li><li>Alibaba introduced the&nbsp;<a href="https://qwenlm.github.io/blog/qwen2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Qwen2</a>&nbsp;family of language models. Qwen2 includes base and instruction-tuned versions of five models that range in size from 500 million to 72 billion parameters and process context lengths between 32,000 and 128,000 tokens. The largest, Qwen2-72B, outperforms Llama 3-70B on MMLU, MMLU-Pro, HumanEval, and other benchmarks that gauge performance in natural language, mathematics, and coding. Qwen2-72B and Qwen2-72B-Instruct are available under a&nbsp;<a href="https://huggingface.co/Qwen/Qwen2-72B/blob/main/LICENSE?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;that permits users to use and modify them in commercial applications up to 100 million monthly users. The smaller models are available under the Apache&nbsp;<a href="https://apache.org/licenses/LICENSE-2.0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>, which allows people to use and modify them freely. Alibaba said it plans to add multimodal capabilities in future updates.</li><li>Stability AI&nbsp;<a href="https://stability.ai/news/stable-diffusion-3-medium?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">launched</a>&nbsp;the Stable Diffusion 3 Medium text-to-image generator, a 2 billion-parameter based on the&nbsp;<a href="https://arxiv.org/pdf/2403.03206?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">technology</a>&nbsp;that underpins Stable Diffusion 3. The model is intended to run on laptops and home computers that have consumer GPUs and is optimized for Nvidia and AMD hardware. It excels at rendering imaginary scenes and text; early users encountered inaccuracies in depicting human anatomy, a shortcoming that former Stability AI CEO Emad Mostaque, in a social post,&nbsp;<a href="https://x.com/EMostaque/status/1801686921967436056?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">attributed</a>&nbsp;to tuning for safety. The&nbsp;<a href="https://stability.ai/license?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;allows use of the model’s weights for noncommercial purposes. Businesses that have less than 1 million users and $1 million in revenue can license it, along with other Stability AI models, for $20 per month.</li></ul><p><strong>Why it matters:</strong>&nbsp;AI models that come with published weights are proliferating, and this week’s crop further extends the opportunity to build competitive AI applications. Nemotron-4 340B provides an exceptionally large model among open LLMs. Among smaller models, Qwen2-72B poses stiff competition for Llama 3-70B, which has energized the developer community since its May release. And Stable Diffusion 3 puts Stability AI’s image generation technology into the hands of developers working on edge devices.</p><p><strong>We’re thinking:&nbsp;</strong>Given the difficulty of acquiring high-quality data to train LLMs, and that the terms of service for many leading models prohibit generating data to train other models, Nvidia’s choice to equip Nemotron-4 to generate synthetic data is especially welcome. And it makes sense from a business perspective: Making it easier for developers to train their own LLMs may be good for GPU sales.</p><hr /><figure class="kg-card kg-image-card"><img alt="Safety, Evaluations and Alignment Lab (SEAL) Leaderboards." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154339.904.gif" width="1200" /></figure><h1 id="private-benchmarks-for-fairer-tests">Private Benchmarks for Fairer Tests</h1><p>Scale AI offers new leaderboards based on its own benchmarks.</p><p><strong>What’s new:</strong>&nbsp;Scale AI, which helps companies prepare and manage training data,&nbsp;<a href="https://scale.com/leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">introduced</a>&nbsp;the Safety, Evaluations and Alignment Lab (SEAL) Leaderboards. Four leaderboards test models’ abilities to (i) generate code, (ii) work on Spanish-language inputs and outputs, (iii) follow detailed instructions, and (iv) solve fifth-grade math problems. The company currently tests 11 models from Anthropic, Google, Meta, Mistral, and OpenAI. Developers who want to have their model ranked can contact Scale AI via email.<br /><br /><strong>How it works:</strong>&nbsp;The leaderboards track performance on proprietary datasets of roughly 1,000 examples. In all but the math tests, models to be evaluated are grouped and pitted against each other. Each pair receives 50 prompts at a time. Human annotators evaluate the models’ responses and grade which was superior and by how much. Then the models receive another 50 prompts. Models are ranked using a variation on Elo, which scores competitors relative to each other. To keep the test sets from leaking, a given model will be tested only once except in “exceptional cases” where Scale AI believes the risk of overfitting is low.&nbsp;</p><ul><li>The&nbsp;<a href="https://scale.com/leaderboard/coding?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">coding</a>&nbsp;evaluation tests models’ abilities to generate code, analyze code, fix errors, and solve problems in SQL, Python, Java, JavaScript, HTML, CSS, C++, C, and C#. Annotators judge the code based on correctness, efficiency, readability, adherence to the prompt, and overall quality.&nbsp;</li><li>The&nbsp;<a href="https://scale.com/leaderboard/spanish?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Spanish</a>&nbsp;dataset tests the ability to respond to prompts written in European and Latin American Spanish, covering both general and cultural subject matter. Annotators evaluate the responses on 16 criteria including style, correctness, harmfulness, and internal contradiction. (The company plans to extend its multilingual evaluation to other languages.)</li><li><a href="https://scale.com/leaderboard/instruction_following?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Instruction Following</a>&nbsp;asks models to fulfill detailed, multi-step instructions in a single response. The dataset includes prompts that ask a model to generate poetry, fiction, social posts, or responses playing a particular role. Annotators evaluate the responses using 12 criteria, including how well they reflect the prompt and how useful they are. They rate how well each model followed the instructions and how well they performed relative to each other.</li><li>The&nbsp;<a href="https://scale.com/leaderboard/math?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Math</a>&nbsp;leaderboard evaluates models on Scale AI’s&nbsp;<a href="https://arxiv.org/abs/2405.00332?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">GSM1k</a>&nbsp;benchmark of fifth-grade arithmetic and algebra problems written in English. Unlike the other three tests, it tests whether responses are correct rather than pitting models against one another.</li></ul><p><strong>Results:</strong>&nbsp;As of this writing, GPT-4 Turbo tops the Coding leaderboard with GPT-4o a very close second. GPT-4o tops the Spanish and Instruction Following leaderboards, just ahead of Gemini 1.5 Pro in Spanish and GPT-4 Turbo in Instruction Following. On the Math leaderboard, Claude 3 Opus holds a narrow lead over GPT-4 Turbo (second) and GPT-4o (third).</p><p><strong>Behind the news:&nbsp;</strong>As more models are trained on data scraped from the web, leakage of test data into training sets has made it more difficult to evaluate their performance on common benchmarks. Earlier this year, researchers at Shanghai Jiao Tong University&nbsp;<a href="https://arxiv.org/html/2404.18824v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">evaluated</a>&nbsp;31 open-source large language models and found that several had a high probability of inaccurate benchmark results due to data leakage. Scale AI built the GSM1k math dataset partly to show that some high-profile language models show evidence of overfitting to the common math benchmark GSM8k.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Traditionally, benchmarks have been open source efforts. But proprietary benchmarks are emerging to help developers evaluate their models and applications with greater confidence. By keeping their datasets under wraps, companies like Scale AI and&nbsp;<a href="https://www.deeplearning.ai/the-batch/vals-ai-evaluates-large-language-models-on-industry-specific-tasks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Vals AI</a>&nbsp;ensure that models haven’t been exposed to test questions and answers previously, making evaluations more reliable. However, private benchmarks lack the transparency of their open counterparts. A mix of public, private, and internal evals may be necessary to get a well rounded picture of a given model’s capabilities.<br /><br /><strong>We’re thinking:</strong>&nbsp;We welcome Scale AI’s contribution to the important field of&nbsp;<a href="https://www.deeplearning.ai/the-batch/we-need-better-evals-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">evals</a>, which also includes open benchmarks,&nbsp;<a href="https://chat.lmsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">LMSYS Chatbot Arena</a>, and&nbsp;<a href="https://crfm.stanford.edu/helm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">HELM</a>.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154435.801.gif" width="600" /></figure><h1 id="from-clip-to-composition">From Clip to Composition</h1><p>Is your song’s verse in need of a chorus? A popular text-to-music generator can extend existing recordings while maintaining their musical character.</p><p><strong>What’s new:</strong>&nbsp;Paying users of Udio, a web service that generates pop-song productions from prompts, can&nbsp;<a href="https://www.udio.com/announcements?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">upload</a>&nbsp;audio clips and extend or alter them according to a text description. The service also increased its context window from 30 seconds to 2 minutes for more coherent output. You can hear the new capability&nbsp;<a href="https://www.youtube.com/watch?v=hFWdHzk70-Q&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">here</a>. Subscriptions start at $10 per month.<br /><br /><strong>How it works:</strong>&nbsp;Given a prompt, Udio generates a 30-second passage and lets you assemble passages into compositions (previously up to four minutes long, now 15 minutes). Now users can create passages by uploading audio clips and extending them or modifying them by, say, adding or removing instruments or vocals complete with lyrics.&nbsp;</p><ul><li>In the demonstration video linked above, Udio adds a singing voice to an instrumental backing track using the prompt “funk, female vocalist.” Other examples enhance an electronic beat with a guitar melody and fill out hard-rock drums with a guitar riff and wailing voice.</li><li>Users are responsible for securing legal rights to use audio files they upload. They retain commercial rights to audio that they produce using the software, as long as they specify that Udio generated the recording.&nbsp;</li><li>Udio has shared few details about how it built its model. “A large amount of publicly available and high-quality music” was in the training set, CEO David Ding&nbsp;<a href="https://musically.com/2024/04/10/ai-music-startup-udio-launches-backed-by-artists-and-instagrams-co-founder/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">told</a>&nbsp;<em>Music Ally</em>. The company has “very strong artist filters and a copyright focus” to avoid generating output that sounded too much like copyrighted music, he added.</li></ul><p><strong>Behind the news:</strong>&nbsp;Udio competes with&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Suno</a>, whose service also generates audio output with vocals, lyrics, and song structures. Also in the mix is Stability AI, whose&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Stable Audio 2.0</a>&nbsp;enables users to upload and extend brief instrumental recordings to a length of around three minutes.</p><p><strong>Why it matters:</strong>&nbsp;Udio is quickly becoming not just a song generator, but a song editor and builder. Just as the ability of text-to-image generators to edit, extend, and infill existing images made those applications more useful in a variety of creative situations, Udio’s audio-to-audio capabilities give composers and producers new horizons for enhancing, orchestrating, and structuring their own productions.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Udio offers impressive capabilities for musicians (and wanna-be musicians), but its developer tools are lacking. A public-facing API would enable producers to automate the service and integrate it with other applications.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154515.714.gif" width="600" /></figure><h1 id="for-faster-diffusion-think-a-gan">For Faster Diffusion, Think a GAN</h1><p>Generative adversarial networks (GANs) produce images quickly, but they’re of relatively low quality. Diffusion image generators typically take more time, but they produce higher-quality output. Researchers aimed to achieve the best of both worlds.</p><p><strong>What's new:</strong>&nbsp;Axel Sauer and colleagues at Stability AI accelerated a diffusion model using a method called&nbsp;<a href="https://arxiv.org/abs/2311.17042?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">adversarial diffusion distillation</a>&nbsp;(ADD). As the name implies, ADD combines diffusion with techniques borrowed from GANs and teacher-student distillation.</p><p><strong>Key insight:</strong>&nbsp;<a href="https://arxiv.org/abs/1406.2661?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">GANs</a>&nbsp;are fast because they produce images in a single step. Diffusion models are slower because they remove noise from a noisy image over many steps. A diffusion model can learn to generate images in a single denoising step if, like a GAN, it learns to fool a discriminator, while the discriminator learns to identify generated output. The resulting one-step output doesn’t match the quality of multi-step diffusion, but distillation can improve it: While learning to fool the discriminator, the diffusion model (the student) can simultaneously learn to emulate the output of a different pretrained diffusion model (the teacher).</p><p><strong>How it works:&nbsp;</strong>The authors paired a pretrained&nbsp;<a href="https://arxiv.org/abs/2307.01952?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Stable Diffusion XL</a>&nbsp;(SDXL) generator (the student) with a pretrained&nbsp;<a href="https://arxiv.org/abs/2304.07193?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">DINOv2</a>&nbsp;vision transformer discriminator. The teacher was another pretrained Stable Diffusion XL with frozen weights. They didn’t specify the training dataset.&nbsp;&nbsp;</p><ul><li>The researchers added noise to images in the training dataset. Given a noisy image and the corresponding caption, the student model removed noise in a single step.</li><li>Given the student’s output, the discriminator learned to distinguish it from the images in the dataset.</li><li>Given the student’s output with added noise plus the caption, the teacher removed the noise from the image in a single step.</li><li>The student’s loss function encouraged the model to produce images that the discriminator could not distinguish from images in the dataset and to minimize the difference between the student’s and teacher’s output.</li></ul><p><strong>Results:&nbsp;</strong>The authors tested their method using 100 prompts from&nbsp;<a href="https://huggingface.co/datasets/nateraw/parti-prompts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">PartiPrompts</a>. They compared the student’s output after either one or four denoising steps to a pretrained SDXL after 50 denoising steps. Human judges were asked which they preferred with respect to (i) image quality and (ii) alignment with the prompt. They preferred the student’s four-step images about 57 percent of the time for image quality and about 55 percent of the time for alignment with the prompt. They preferred SDXL to the student’s one-step images around 58 percent of the time for image quality and 52 percent of the time for alignment with the prompt.</p><p><strong>Why it matters:</strong>&nbsp;In this work, the key steps — having a student model learn from a teacher model, and training a generator against a discriminator&nbsp;— are established techniques in their own right. Combining them conferred upon the student model the advantages of both.</p><p><strong>We're thinking:</strong>&nbsp;With the growing popularity of diffusion models, how to reduce the number of steps they take while maintaining their performance is a hot topic. We look forward to future advances.</p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 20:49:35 GMT</pubDate>
</item>
<item>
<title>Apple’s Gen AI Strategy, Stability's Copyright-Clear Audio Generator, International Safety Agreements, LLMs Play Doctor</title>
<link>https://www.deeplearning.ai/the-batch/issue-253</link>
<guid>https://www.deeplearning.ai/the-batch/issue-253</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>One reason for machine learning’s success is that our field welcomes a wide range of work. I can’t think of even one example where someone developed what they called a machine learning algorithm and senior members of our community criticized it saying, “that’s not machine learning!” Indeed, linear regression using a least-squares cost function was used by mathematicians Legendre and Gauss in the early 1800s — long before the invention of computers — yet machine learning has embraced these algorithms, and we routinely call them “machine learning” in introductory courses!</p><p>In contrast, about 20 years ago, I saw statistics departments at a number of universities look at developments in machine learning and say, “that’s not really statistics.” This is one reason why machine learning grew much more in computer science than statistics departments. (Fortunately, since then, most statistics departments have become much more open to machine learning.)</p><p>This contrast came to mind a few months ago, as I thought about how to talk about&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agentic systems</a>&nbsp;that use design patterns such as&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">reflection</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">tool use</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">planning</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">multi-agent collaboration</a>&nbsp;to produce better results than zero-shot prompting. I had been involved in conversations about whether certain systems should count as “agents.” Rather than having to choose whether or not something is an agent in a binary way, I thought, it would be more useful to think of systems as being agent-like to different degrees. Unlike the noun “agent,” the adjective “agentic” allows us to contemplate such systems and include all of them in this growing movement.</p><p>More and more people are building systems that prompt a large language model multiple times using agent-like design patterns. But there’s a gray zone between what clearly is not an agent (prompting a model once) and what clearly is (say, an autonomous agent that, given high-level instructions, plans, uses tools, and carries out multiple, iterative steps of processing).&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--63-.jpg" width="1200" /></figure><p>Rather than arguing over which work to include or exclude as being a true agent, we can acknowledge that there are different degrees to which systems can be agentic. Then we can more easily include everyone who wants to work on agentic systems. We can also encourage newcomers to start by building simple agentic workflows and iteratively make their systems more sophisticated.&nbsp;</p><p>In the past few weeks, I’ve noticed that, while technical people and non-technical people alike sometimes use the word “agent,” mainly only technical people use the word “agentic” (for now!). So when I see an article that talks about “agentic” workflows, I’m more likely to read it, since it’s less likely to be marketing fluff and more likely to have been written by someone who understands the technology.</p><p>Let’s keep working on agentic systems and keep welcoming anyone who wants to join our field!</p><p>Keep learning,</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/courses/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-12T075130.872.png" width="1680" /></a></figure><p>Grow your generative AI skills with DeepLearning.AI’s&nbsp;<a href="https://www.deeplearning.ai/courses/?ref=dl-staging-website.ghost.io" rel="noreferrer">short courses</a>! Learn how to build highly controllable agents in “AI Agents in LangGraph.”&nbsp;<a href="https://learn.deeplearning.ai/courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free and get started</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/APPLEAI.png" width="1200" /></figure><h1 id="apple%E2%80%99s-gen-ai-strategy-revealed">Apple’s Gen AI Strategy Revealed</h1><p>Apple presented its plan to imbue its phones and computers with artificial intelligence.&nbsp;<br /><br /><strong>What’s new:</strong>&nbsp;Apple&nbsp;<a href="https://www.apple.com/apple-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">announced</a>&nbsp;Apple Intelligence, a plethora of generative-AI features that integrate with iOS 18, iPadOS 18, and MacOS Sequoia. The beta version of Apple Intelligence will be available in U.S. English prior to a wider rollout near the end of the year, starting with the iPhone 15 Pro and Mac computers that use&nbsp;<a href="https://support.apple.com/en-gb/116943?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">M-series</a>&nbsp;chips.&nbsp;<br /><br /><strong>On-device and in the cloud:&nbsp;</strong>The new capabilities rely on a suite of language and vision models. Many of the models will run on-device, while workloads that require more processing power will run on a cloud powered by Apple chips.&nbsp;</p><ul><li>Semantic search analyzes the data on a device to better understand context such as the user’s routines and relationships. For example, if a user enters a prompt like, “Show me the files my boss shared with me the other day,” models can identify the user’s boss and the day in question.</li><li>Generative media capabilities are geared to fulfill preset functions. For instance, the text generator offers options to make writing more friendly, professional, or concise. Image generation focuses on tasks like making custom emojis from text prompts and turning rough sketches into polished images.&nbsp;</li><li>Apple’s voice assistant Siri will accept text as well as voice prompts. It will also interact with apps, so Siri can, say, determine whether a meeting scheduled in the Calendar app will prevent a user from attending an event at a location designated in the Maps app.&nbsp;</li><li>Starting later this year, Siri users will be able to converse with OpenAI’s ChatGPT without having an OpenAI account or paying a fee. Paid ChatGPT users will be able to log in for access to paid features. Apple plans to integrate other third-party large language models.</li><li>The underlying infrastructure is designed to maintain user privacy. Apple’s cloud won’t retain user data. Apple won’t have privileged access to user data. Queries to ChatGPT from users who are not logged into an OpenAI account will have their IP masked. In addition, independent researchers can inspect the infrastructure code to verify assurances and find flaws.</li></ul><p><strong>How it works:&nbsp;</strong>Apple&nbsp;<a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">outlined</a>&nbsp;the architecture that underpins the new features and compared two models of its against competitors.</p><ul><li>All Apple models were trained on a mix of licensed, synthetic, and web-crawled data (filtered to remove personal and low-quality information). The models were fine-tuned to follow instructions via methods including reinforcement learning from human feedback.&nbsp;</li><li>To adapt its models to specific tasks, Apple uses LoRA weights that plug into a pretrained model and adjust its weights at inference. Such LoRA adapters are included for many tasks including summarization, proofreading, email replies, and answering questions.</li><li>Apple used quantization, a compression technique called low-bit parallelization (also known as&nbsp;<a href="https://www.tensorflow.org/model_optimization/guide/clustering?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">weight clustering</a>), and other methods to improve speed and energy efficiency. On an iPhone 15 Pro, Apple clocked a generation rate of 30 tokens per second.</li><li>Apple hired human graders to test two of its models on an internal benchmark that covers tasks including brainstorming, classification, answering questions, rewriting, summarization, and safety. The graders preferred an on-device model of 3 billion parameters over Phi-3-mini, Mistral-7B, and Gemma-7B. They preferred a large language model designed to run in the cloud to DBRX-Instruct, GPT-3.5-Turbo, and Mixtral-8x22B, but not to GPT-4-Turbo.</li></ul><p><strong>Behind the news:&nbsp;</strong>While rivals like Microsoft and Google dove into generative AI, Apple&nbsp;<a href="https://www.deeplearning.ai/the-batch/apple-is-proceeding-on-the-sly-to-capitalize-on-the-generative-ai-trend/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">moved</a>&nbsp;more cautiously. During the 2010s, it invested heavily in its Siri voice assistant, but the technology was&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-was-the-first-big-company-to-get-chatbots-right/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">outpaced</a>&nbsp;by subsequent developments. Since then, the famously secretive company has been perceived as&nbsp;<a href="https://www.wsj.com/tech/ai/apple-ai-siri-development-behind-9ea65ee8?st=syyxevr53ucieoo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">falling behind</a>&nbsp;big-tech rivals in AI.<br /><br /><strong>Why it matters:</strong>&nbsp;While Apple’s big-tech competitors have largely put their AI cards on the table, Apple has held back. Now its strategy is on display: Proprietary foundation models, LoRA to fine-tune them to specific tasks, emphasis on the user experience over raw productivity, judicious use of edge and cloud computing, and deals with other model makers, all wrapped up in substantial privacy protections.<br />&nbsp;<br /><strong>We’re thinking:&nbsp;</strong>Apple’s control over its product ecosystem gives the company an extraordinary distribution channel. That’s why Google reportedly&nbsp;<a href="https://www.msn.com/en-us/money/other/court-documents-reveal-google-s-payments-to-apple-increased-to-an-eye-watering-20-billion-in-2022/ar-AA1o2J6w?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">paid</a>&nbsp;Apple $20 billion in 2022 to provide the default search engine in Apple’s Safari web browser. This advantage means that, whatever its pace of development and strategy in AI, Apple’s competitive edge remains sharp.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/STABLEAUDIOOPEN.png" width="1200" /></figure><h1 id="audio-generation-clear-of-copyrights">Audio Generation Clear of Copyrights</h1><p>Sonically minded developers gained a high-profile text-to-audio generator.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Stability AI&nbsp;<a href="https://stability.ai/news/introducing-stable-audio-open?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">released</a>&nbsp;Stable Audio Open, which takes text prompts and generates&nbsp;16kHz-resolution&nbsp;music or sound effects. The model’s code and weights are available for noncommercial use. You can listen to a few sample outputs&nbsp;<a href="https://stability.ai/news/introducing-stable-audio-open?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">here</a>.<br /><br /><strong>How it works:</strong>&nbsp;Stability AI promotes Stable Audio Open for generating not full productions but elements that will be assembled into productions. Although it’s similar to the earlier&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Stable Audio 2.0</a>, it has important differences.</p><ul><li>Stable Audio Open is available for download. In contrast, Stable Audio 2.0 is available via API or web user interface.</li><li>The new model accepts only text input, while Stable Audio 2.0 accepts text or audio. It generates stereo, clips up to 47 seconds long rather than Stability Audio 2.0’s three minutes.</li><li>Its training dataset was drawn from open source&nbsp;<a href="https://freesound.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">audio</a>&nbsp;<a href="https://freemusicarchive.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">databases</a>&nbsp;that anyone can use without paying royalties. In contrast, Stable Audio 2.0 was trained on a commercial&nbsp;<a href="https://www.audiosparx.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">dataset</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Stable Audio Open competes not only with Stable Audio 2.0 but also with a handful of recent models. ElevenLabs,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-cloned-voices-take-over-youtube-twitch-and-spotify/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">known</a>&nbsp;for voice cloning and generation,&nbsp;<a href="https://elevenlabs.io/sound-effects?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">introduced</a>&nbsp;Sound Effects, which generates brief sound effects from a text prompt. Users can input up to 10,000 prompt characters with a free account. For music generation,&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Udio and Suno</a>&nbsp;offer web-based systems that take text prompts and generate structured compositions including songs with lyrics, voices, and full instrumentation. Users can generate a handful of compositions daily for free.</p><p><strong>Why it matters:</strong>&nbsp;Stable Audio Open is pretrained on both music and sound effects, and it can be fine-tuned and otherwise modified. The fact that its training data was copyright-free guarantees that users won’t make use of proprietary sounds — a suitable option for those who prefer to steer clear of the music industry’s brewing intellectual property&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-music-accuses-ai-developers-of-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">disputes</a>.<br /><br /><strong>We’re thinking:</strong>&nbsp;We welcome Stability AI’s latest contribution, but we don’t consider it open source. Its license doesn’t permit commercial use and thus, as far as we know, doesn’t meet the definition established by the&nbsp;<a href="http://opensource.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Open Source Initiative</a>. We urge the AI community toward greater clarity and consistency with respect to the term “open source.”&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-12T145349.047.png" width="600" /></figure><h1 id="seoul-ai-summit-spurs-safety-agreements">Seoul AI Summit Spurs Safety Agreements</h1><p>At meetings in Seoul, government and corporate officials from dozens of countries agreed to take action on AI safety.<br /><br /><strong>What’s new:&nbsp;</strong>Attendees at the AI Seoul Summit and AI Global Forum, both held concurrently in Seoul, formalized the broad-strokes agreements to govern AI,&nbsp;<em>The Guardian</em>&nbsp;<a href="https://www.theguardian.com/technology/article/2024/may/28/techscape-ai-global-summit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">reported</a>. Presented as a sequel to November’s AI summit in Bletchley Park outside of London, the meetings yielded several multinational declarations and commitments from major tech firms.</p><p><strong>International commitments:</strong>&nbsp;Government officials hammered out frameworks for promoting innovation while managing risk.</p><ul><li>27 countries and the European Union&nbsp;<a href="https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agreed</a>&nbsp;to jointly develop risk thresholds in coming months. Thresholds may include a model’s ability to evade human oversight or help somebody create weapons of mass destruction. (Representatives from China didn’t join this agreement.)</li><li>10 of those 27 countries (Australia, Canada, France, Germany, Italy, Japan, the Republic of Korea, the Republic of Singapore, the United Kingdom, and the United States) and the European Union&nbsp;<a href="https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-seoul-summit-2024/seoul-declaration-for-safe-innovative-and-inclusive-ai-by-participants-attending-the-leaders-session-ai-seoul-summit-21-may-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">declared</a>&nbsp;a common aim to create shared policies while encouraging AI development.&nbsp;</li><li>In a separate statement, those 10 nations and the EU&nbsp;<a href="https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-seoul-summit-2024/seoul-statement-of-intent-toward-international-cooperation-on-ai-safety-science-ai-seoul-summit-2024-annex?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">laid out</a>&nbsp;more specific goals including exchanging information on safety tests, building an international AI safety research network, and expanding AI safety institutes beyond those currently established in the U.S., UK, Japan, and Singapore.</li></ul><p><strong>Corporate commitments:</strong>&nbsp;AI companies agreed to monitor their own work and collaborate on further measures.</p><ul><li>Established leaders (Amazon, Google, IBM, Meta, Microsoft, OpenAI, Samsung) and startups (Anthropic, Cohere, G42, Inflection, xAI) were among 16 companies that&nbsp;<a href="https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agreed</a>&nbsp;to evaluate advanced AI models continually for safety risks. They agreed to abide by clear risk thresholds developed in concert with their home governments, international agreements, and external evaluators. If they deem that a model has surpassed a threshold, and that risk can’t be mitigated, they agreed to stop developing that model immediately.</li><li>14 companies, including six that didn’t sign the agreement on risk thresholds,&nbsp;<a href="https://aiseoulsummit.kr/kor/press/?uid=43&amp;mod=document&amp;pageid=1&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">committed</a>&nbsp;to collaborate with governments and each other on AI safety, including developing international standards.</li></ul><p><strong>Behind the news:</strong>&nbsp;Co-hosted by the UK and South Korean governments at the Korea Advanced Institute of Science and Technology, the meeting followed an initial summit held at Bletchley Park outside London in November. The earlier summit&nbsp;<a href="https://www.deeplearning.ai/the-batch/countries-and-tech-giants-collaborate-on-global-ai-safety-regulation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">facilitated</a>&nbsp;agreements to create AI&nbsp;<a href="https://www.nist.gov/aisi?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">safety</a>&nbsp;<a href="https://www.gov.uk/government/organisations/ai-safety-institute?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">institutes</a>, test AI products before public release, and create an international panel akin to the&nbsp;<a href="https://www.ipcc.ch/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Intergovernmental Panel on Climate Change</a>&nbsp;to draft reports on the state of AI. The panel&nbsp;<a href="https://assets.publishing.service.gov.uk/media/66474eab4f29e1d07fadca3d/international_scientific_report_on_the_safety_of_advanced_ai_interim_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">published</a>&nbsp;an interim report in May. It will release its final report at the&nbsp;<a href="https://www.gov.uk/government/news/uk-and-france-to-deepen-research-and-ai-links-following-horizon-association?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">next summit</a>&nbsp;in Paris in November 2024.</p><p><strong>Why it matters:</strong>&nbsp;There was a chance that the Bletchley Park summit would be a one-off. The fact that a second meeting occurred is a sign that public and private interests alike want at least a seat at the table in discussions of AI safety. Much work remains to define terms and establish protocols, but plans for future summits indicate a clear appetite for further cooperation.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Andrew Ng spoke at the AI Global Forum on the importance of&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-252/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">regulating applications rather than technology</a>&nbsp;and chatted with many government leaders there. Discussions focused at least as much on promoting innovation as mitigating hypothetical risks. While some large companies continued to lobby for safety measures that would unnecessarily impede dissemination of cutting-edge foundation models and hamper open-source and smaller competitors, most government leaders seemed to give little credence to science-fiction risks, such as AI takeover, and express concern about concrete, harmful applications like the use of AI to interfere with democratic elections. These are encouraging shifts!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-12T145439.840.gif" width="600" /></figure><h1 id="the-llm-will-see-you-now">The LLM Will See You Now</h1><p>A critical step in diagnosing illnesses is a conversation between doctor and patient to assemble a medical history, discuss approaches to managing symptoms, and so on. Can a large language model play the doctor’s role? Researchers trained one to do surprisingly well.</p><p><strong>What's new:</strong>&nbsp;<a href="https://arxiv.org/abs/2401.05654?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Articulate Medical Intelligence Explorer</a>&nbsp;(AMIE), a chatbot built by Google researchers Tao Tu, Anil Palepu, Mike Schaekermann and colleagues, showed better diagnostic ability and bedside manner than doctors in conversations with patients. The conversations covered a range of complaints including cardiovascular, respiratory, gastroenterology, neurology, urology, obstetric, and gynecology conditions.</p><p><strong>Key insight:&nbsp;</strong>A pretrained LLM that’s fine-tuned on conversations between doctors and patients can learn to mimic the doctor’s role. However, such models are limited because available datasets of real-world medical conversations don’t cover the full range of medical scenarios and include ambiguities, interruptions, implicit references and the like, posing difficulties for learning. Conversations generated by a pretrained LLM can cover more conditions in more articulate language. After fine-tuning on real-world conversations, further tuning on generated conversations can improve performance. In addition, after a conversation, critiquing the “doctor’s” performance can improve its ability to render diagnoses, suggest plans for managing symptoms, empathize with patients, and otherwise perform its role.</p><p><strong>How it works:&nbsp;</strong>The authors fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2305.10403?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">PaLM-2</a>&nbsp;on medical&nbsp;<a href="https://github.com/jind11/MedQA?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">multiple-choice questions</a>&nbsp;that describe symptoms, possible causes, and evidence for the correct diagnosis, as well as datasets for tasks like summarizing and continuing medical dialogs. They further fine-tuned the model on its own output.</p><ul><li>Given a medical condition, the authors searched the web to retrieve background information about symptoms, management, and patient demographics. Using that information, they prompted PaLM-2 to generate a patient scenario like scenarios used to assess real-world medical interviewing skills.&nbsp;</li><li>The authors prompted separate instances of PaLM-2 to play doctor and patient. They fed the generated scenario to the patient and prompted the models to produce a conversation. After each turn, a third instance of PaLM-2 decided whether the conversation was over based on whether the doctor had given a diagnosis and the patient had further questions (or either had said “goodbye”).&nbsp;</li><li>Given the generated conversation, a fourth instance of PaLM-2 generated a critique of the doctor model’s empathy, professionalism, repetition, conversation flow, factual accuracy, and whether the doctor had asked questions that led to a diagnosis.&nbsp;&nbsp;</li><li>Given the critique, the doctor initiated a second iteration of its conversation with the patient.&nbsp;</li><li>The authors fine-tuned PaLM-2 to predict the next token in the second conversation. Then they repeated the process from the beginning a number of times, generating fresh conversations and fine-tuning the model.&nbsp;</li><li>At inference, users conversed with the doctor model. Once the conversation was complete, the authors prompted the model to list 10 potential diagnoses.</li></ul><p><strong>Results:</strong>&nbsp;Specialist physicians evaluated the doctor model’s performance in 149 conversations with human actors who played the roles of patients based on scenarios supplied by clinical providers. They compared the model’s output with those of 20 primary care physicians based on their own conversations with the actors.&nbsp;</p><ul><li>The model included the correct diagnosis among its top three in about 90 percent of cases. The physicians included the correct diagnoses among their top three in 77 percent of the scenarios.&nbsp;</li><li>Specialist physicians also rated the conversations on 32 subjective qualities including relationship fostering, responding to emotions, understanding patient concerns, and explaining relevant information accurately. Of the 32 qualities, AMIE rated higher on 28 of them. For instance, the physicians said AMIE responded to emotions favorably or very favorably about 83 percent of the time, while physicians responded to emotions favorably or very favorably 31 percent of the time.&nbsp;</li><li>The actors also rated the conversations they had with AMIE and the physicians on 26 qualities including whether they had explained the condition and treatment, appeared honest and trustworthy, expressed caring and commitment, and valued the patient as a person. Among those 26 qualities, AMIE outperformed the physicians on 24 of them. For instance, the actors said that AMIE valued them as people 79 percent of the time, while the physicians valued them as people 59 percent of the time.</li></ul><p><strong>Why it matters:</strong>&nbsp;LLMs can generate fine-tuning data that improves their own performance. By training on relevant, factually correct medical information from the web, LLMs can generate realistic conversations at scale — even in a highly technical, high-stakes discipline like medicine and despite their potential to generate potentially dangerous hallucinations. Used as fine-tuning data, this output enables LLMs to converse with humans more effectively.</p><p><strong>We're thinking:</strong>&nbsp;AI promises to spread intelligence far and wide. As the authors acknowledge, further work remains to demonstrate this work’s efficacy, ethics, security, and regulatory compliance in a clinical setting. Yet it’s an exciting glimpse of a world in which medical intelligence is fast, cheap, and widely available.</p>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 19:57:05 GMT</pubDate>
</item>
<item>
<title>The AI PC Arrives, OpenAI Used For Disinformation, U.S. and China Seek AI Agreement, Training Models to Reason</title>
<link>https://www.deeplearning.ai/the-batch/issue-252</link>
<guid>https://www.deeplearning.ai/the-batch/issue-252</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>The effort to protect innovation and open source continues. I believe we’re all better off if anyone can carry out basic AI research and share their innovations. Right now, I’m deeply concerned about California's proposed law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">SB-1047</a>.&nbsp;It’s a long, complex bill with many parts that require safety assessments, shutdown capability for models, and so on.</p><p>There are many things wrong with this bill, but I’d like to focus here on just one: It defines an unreasonable “hazardous capability” designation that may make builders of large AI models potentially liable if someone uses their models to do something that exceeds the bill’s definition of harm (such as causing $500 million in damage). That is practically impossible for any AI builder to ensure. If the bill is passed in its present form, it will stifle AI model builders, especially open source developers.&nbsp;</p><p>Some AI applications, for example in healthcare, are risky. But as I wrote&nbsp;<a href="https://www.deeplearning.ai/the-batch/keep-open-source-free/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">previously</a>, regulators should regulate&nbsp;<em>applications</em>&nbsp;rather than&nbsp;<em>technology</em>.&nbsp;</p><ul><li>Technology refers to tools that can be applied in many ways to solve various problems.</li><li>Applications are specific implementations of technologies designed to meet particular customer needs.</li></ul><p>For example, an electric motor is a technology. When we put it in a blender, an electric vehicle, dialysis machine, or guided bomb, it becomes an application. Imagine if we passed laws saying, if anyone uses a motor in a harmful way, the motor manufacturer is liable. Motor makers would either shut down or make motors so tiny as to be useless for most applications. If we pass such a law, sure, we might stop people from building guided bombs, but we’d also lose blenders, electric vehicles, and dialysis machines.&nbsp;In contrast, if we look at specific applications, like blenders, we can more rationally assess risks and figure out how to make sure they’re safe, and even ban classes of applications, like certain types of munitions.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--62--1.jpg" width="1200" /></figure><p>Safety is a property of applications, not a property of technologies (or models), as Arvind Narayanan and Sayash Kapoor have&nbsp;<a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">pointed out</a>. Whether a blender is a safe one can’t be determined by examining the electric motor. A similar argument holds for AI. &nbsp;</p><p>SB-1047 doesn’t account for this distinction. It ignores the reality that the number of beneficial uses of AI models is, like electric motors, vastly greater than the number of harmful ones. But, just as no one knows how to build a motor that can’t be used to cause harm, no one has figured out how to make sure an AI model can’t be adapted to harmful uses. In the case of open source models, there’s no known defense to fine-tuning to remove RLHF alignment. And jailbreaking work has shown that even closed-source, proprietary models that have been properly aligned can be attacked in ways that make them give harmful responses. Indeed, the sharp-witted&nbsp;<a href="https://x.com/elder_plinius?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Pliny the Prompter</a>&nbsp;regularly tweets about jailbreaks for closed models. Kudos also to Anthropic’s Cem Anil and collaborators for publishing their work on&nbsp;<a href="https://www.anthropic.com/research/many-shot-jailbreaking?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">many-shot jailbreaking</a>, an attack that can get leading large language models to give inappropriate responses and is hard to defend against.&nbsp;</p><p>California has been home to a lot of innovation in AI. I’m worried that this anti-competitive, anti-innovation proposal has gotten so much traction in the legislature. Worse, other jurisdictions often follow California, and it would be awful if they were to do so in this instance.</p><p>SB-1047 passed in a key vote in the State Senate in May, but it still has additional steps before it becomes law. I hope you will speak out against it if you get a chance to do so.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-04T083916.036.png" width="1680" /></a></figure><p>In this course, you’ll learn how to build and implement highly controllable AI agents with LangGraph and use agentic search to enhance your agents’ built-in knowledge.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll today</a>&nbsp;</p><hr /><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180415.022.png" width="600" /></figure><h1 id="rise-of-the-ai-pc">Rise of the AI PC</h1><p>Generative AI plays a starring role in the latest Windows PCs.</p><p><strong>What’s new:</strong>&nbsp;Microsoft&nbsp;<a href="https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">introduced</a>&nbsp;its Copilot+ PCs, an AI-first laptop specification that offers features unavailable to other Windows users. Copilot+ PCs will be available from Microsoft as well as Acer, Asus, Dell, HP, Lenovo, and Samsung starting in mid-June.<br /><br /><strong>How it works:</strong>&nbsp;Copilot+ PCs provide AI-powered generative and search functions thanks to unnamed AI models that run on-device.&nbsp;</p><ul><li>A feature called&nbsp;<a href="https://learn.microsoft.com/en-us/windows/ai/apis/recall?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Recall</a>&nbsp;enables users to search their activities in apps, documents, and websites to find, say, topics discussed in a text conversation or items viewed on a website. Every five seconds, the PC takes a screenshot of its current status. Users can browse the timeline of screenshots or call an unidentified AI model to find images and/or text via a&nbsp;<a href="https://learn.microsoft.com/en-us/microsoftsearch/semantic-index-for-copilot?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">semantic index</a>.</li><li>Other features include Cocreator, which generates images from text prompts using models that run on-device, and Live Captions, which generates subtitles for English-language audio in any of 40 languages.</li><li>Developers have access to these features via a software stack called Windows Copilot Runtime. This includes&nbsp;<a href="https://learn.microsoft.com/en-us/windows/ai/apis/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Copilot Library</a>, a set of APIs that call more than 40 models that run on-device, and&nbsp;<a href="https://github.com/microsoft/DiskANN?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">DiskANN</a>, a set of search algorithms that quickly sort through a vector database.</li><li>The first machines will be based on the&nbsp;<a href="https://www.tomsguide.com/computing/snapdragon-x-plus?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Qualcomm Snapdragon X</a>&nbsp;processor. The chip comes with 10 and 12 CPU cores, a&nbsp;<a href="https://www.qualcomm.com/products/features/adreno?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">GPU</a>&nbsp;and a&nbsp;<a href="https://www.qualcomm.com/developer/software/hexagon-npu-sdk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">neural processing unit</a>&nbsp;(NPU) that accelerates neural networks while using less energy and memory than a typical CPU or GPU.</li></ul><p><strong>Nvidia’s rejoinder:</strong>&nbsp;Nvidia&nbsp;<a href="https://www.theverge.com/2024/6/2/24169568/microsoft-copilot-plus-gaming-pc-nvidia-amd?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">plans</a>&nbsp;to launch Copilot+-compatible RTX AI PCs that run Nvidia’s own&nbsp;<a href="https://developer.nvidia.com/rtx/ai-toolkit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">toolkit</a>&nbsp;for calling and customizing models with on-device GPUs. These computers, initially built by Asus and MSI based on AMD CPUs, eventually will deliver all Copilot+ features. Nvidia&nbsp;<a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-criticizes-ai-pcs-says-microsofts-45-tops-requirement-is-only-good-enough-for-basic-ai-tasks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">criticized</a>&nbsp;Microsoft’s NPU specification, which calls for 45 trillion operations per second (TOPS), claiming that that speed is enough to process only basic AI workloads. Meanwhile, Nvidia’s game-focused GPUs&nbsp;<a href="https://www.theverge.com/2024/6/2/24169568/microsoft-copilot-plus-gaming-pc-nvidia-amd?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">deliver</a>&nbsp;more than 1,000 TOPS.</p><p><strong>Why it matters:</strong>&nbsp;Microsoft is betting that on-device AI will change the PC experience. The Copilot+ PC specification gives developers a versatile toolkit for adding AI to existing apps while opening the door to fundamentally new functionality like Recall.</p><p><strong>We’re thinking:</strong>&nbsp;As we&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-ai-will-move-to-edge-devices/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">wrote</a>&nbsp;earlier, makers of chips and operating systems alike have a strong incentive to promote on-device (or edge) AI. The growing presence of AI accelerators in consumer devices brings significant privacy benefits for consumers and opens exciting new opportunities for developers.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180448.900.png" width="600" /></figure><h1 id="disinformation-documented">Disinformation Documented</h1><p>OpenAI models were used in five disinformation campaigns, the company said.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/index/disrupting-deceptive-uses-of-AI-by-covert-influence-operations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">discovered</a>&nbsp;that operations based in Russia, China, Iran, and Israel had used the company’s models to create and/or revise text in attempts to influence international political opinion. The generated media failed to reach a mass audience, the company said. It banned the accounts.</p><p><strong>How it works:</strong>&nbsp;Most of the groups primarily used OpenAI’s language models to generate inauthentic social media comments for posting on dummy accounts intended to create the illusion of popular support for certain causes. Some groups used the company’s models to debug code, generate text for websites, and produce images such as political cartoons. Four of the five groups already were known to disinformation researchers.</p><ul><li>A Russian organization previously unknown to researchers generated large volumes of pro-Russia and anti-Ukraine comments in Russian and English and distributed them via messaging service Telegram. The comments often included poor grammar or telltale phrases such as, “As an AI model, . . .”&nbsp;</li><li>Another Russian group that researchers call&nbsp;<a href="https://www.disinfo.eu/doppelganger-operation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Doppelganger</a>&nbsp;generated pro-Russia social media comments in English, French, and German. It also used OpenAI models to translate articles from Russian into other languages for publication on websites. Doppelganger used a third-party API to circumvent OpenAI’s restrictions on Russian users. OpenAI has suspended the API.</li><li>A Chinese operation known to researchers as&nbsp;<a href="https://graphika.com/reports/spamouflage?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Spamouflage</a>&nbsp;generated Chinese-language social media comments that supported the Chinese government. It also used OpenAI technology to debug code for a website dedicated to criticizing opponents of the government.</li><li>An Iranian organization called the International Union of Virtual Media (IUVM) generated English and French articles, headlines, and other text for its website. IUVM is&nbsp;<a href="https://www.reuters.com/article/idUSKCN1LD2R7/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">considered</a>&nbsp;a mouthpiece for the Iranian government.</li><li>STOIC, an Israeli company that runs political social media campaigns, generated articles and social media comments. It also created fictitious bios for inauthentic social media accounts that included images apparently created by other AI models. STOIC created both pro-Israel and anti-Palestine comments as well as comments critical of India’s ruling Bharatiya Janata Party.</li></ul><p><strong>Behind the news:</strong>&nbsp;AI-produced misinformation on the internet — mostly images, videos, and audio clips — rose sharply starting in the first half of 2023, research&nbsp;<a href="https://arxiv.org/abs/2405.11697?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">found</a>&nbsp;at Google and several fact-checking organizations. By the end of that year, generative AI was responsible for more than 30 percent of media that was manipulated by computers.<br /><br /><strong>Why it matters:</strong>&nbsp;Many observers are concerned about potential proliferation of political disinformation as AI models that generate realistic text, images, video, and audio become widely available. This year will see elections in at least 64 countries including most of the world’s most populous nations — a rich opportunity for AI-savvy propagandists. While propagandists have taken advantage of OpenAI’s models, the company was able to detect them and shut them down. More such efforts are bound to follow.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Generative AI’s potential to fuel propaganda is worth tracking and studying. But it’s also worth noting that the accounts identified by OpenAI failed to reach significant numbers of viewers or otherwise have an impact. So far, at least, distribution, not generation, continues to be the limiting factor on disinformation.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180527.254.png" width="1200" /></figure><h1 id="us-and-china-seek-ai-agreement">U.S. and China Seek AI Agreement</h1><p>The United States and China opened a dialogue to avert hypothetical AI catastrophes.<br /><br /><strong>What’s new:</strong>&nbsp;Officials of the two nations met in Geneva for an initial conversation intended to prevent AI-driven accidents or worse,&nbsp;<em>The Washington Post</em>&nbsp;<a href="https://www.washingtonpost.com/technology/2024/05/13/us-china-ai-talks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;The meeting followed up on a November meeting between U.S. president Joe Biden and Chinese president Xi Jinping. The discussion was conceived as an opportunity for the nuclear-armed superpowers, both of which have pegged their strategic ambitions to AI technology, to air their concerns. It resulted in no public statements about concrete actions or commitments.</p><ul><li>The meeting aimed to prevent a “miscalculation” that might lead to unintended conflict,&nbsp;<a href="https://www.ft.com/content/e10b034d-ac25-476c-b3a5-c09aae8eb7f9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">U.S. officials</a>&nbsp;said. They ruled out the possibility that it might promote technical collaboration.</li><li>U.S. diplomats wished to discuss China’s “misuse” of AI, a U.S. government spokesperson&nbsp;<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/05/15/statement-from-nsc-spokesperson-adrienne-watson-on-the-u-s-prc-talks-on-ai-risk-and-safety-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">said</a>&nbsp;without further clarification. Chinese envoys expressed dissatisfaction with “U.S. restrictions and pressure in the field of artificial intelligence,” such as U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">restrictions</a>&nbsp;on the sale of AI chips to Chinese customers.</li><li>Neither side indicated whether or when further meetings would occur.</li></ul><p><strong>Behind the news:&nbsp;</strong>AI-related tensions between the two countries have intensified in recent years. The U.S. government, in an effort to maintain its technological advantage and hamper China’s AI development, has&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">imposed</a>&nbsp;controls on the export of specialized AI chips like the Nvidia A100 and H100 to Chinese customers. Restrictions on the development of models that bear on U.S. national security may&nbsp;<a href="https://www.reuters.com/technology/us-lawmakers-unveil-bill-make-it-easier-restrict-exports-ai-models-2024-05-10/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">follow</a>&nbsp;if further proposed export controls are enacted. Such controls have&nbsp;<a href="https://www.scmp.com/comment/opinion/article/3228220/china-fed-us-sanctions-hitting-back-export-controls-and-more-could-come?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">rankled</a>&nbsp;the Chinese government. Meanwhile,&nbsp;<a href="https://www.airandspaceforces.com/kendall-ai-piloted-flight-embrace-autonomy/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">both</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/meet-zhuhaiyun-the-chinese-navys-new-autonomous-ship/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">countries</a>&nbsp;have developed and deployed autonomous military vehicles, and autonomous weapons are&nbsp;<a href="https://www.nature.com/articles/d41586-024-01029-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">proliferating</a>. In November 2023, both countries signed the Bletchley Park&nbsp;<a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">declaration</a>&nbsp;to mitigate AI-related risks including cybersecurity, biotechnology, and misinformation.<br /><br /><strong>What they’re saying:</strong>&nbsp;“The real verdict on whether these talks were successful will be whether they continue into the future.” — Helen Toner, analyst at Georgetown University’s Center for Security and Emerging Technology and former OpenAI board member,&nbsp;<a href="https://apnews.com/article/artificial-intelligence-china-united-states-biden-xi-geneva-506da7b5fa72d5fe1bcd54fb8ec4f898?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">quoted</a>&nbsp;by Associated Press.</p><p><strong>Why it matters:</strong>&nbsp;Officials and observers alike worry that rivalry between the U.S. and China may lead to severe consequences. However, just as the&nbsp;<a href="https://en.wikipedia.org/wiki/Moscow%E2%80%93Washington_hotline?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">red telephone</a>&nbsp;enabled U.S. and Soviet leaders to communicate during emergencies in the Cold War, face-to-face dialogue can help bring the two countries into alignment around AI-related risks and ways to reduce them.</p><p><strong>We’re thinking:&nbsp;</strong>We support harmonious relations between the U.S. and China, but we’re deeply concerned that export controls could stifle open source software. This might slow down China’s progress in AI, but would also hurt the U.S. and its allies.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="400" src="https://dl-staging-website.ghost.io/content/images/2024/06/REASONv2-2.gif" width="600" /></figure><h1 id="better-teachers-make-better-students">Better Teachers Make Better Students</h1><p>A relatively small student LLM that learns to mimic a larger teacher model can perform nearly as well as the teacher while using much less computation. It can come even closer if the teacher also teaches reasoning techniques.</p><p><strong>What’s new:</strong>&nbsp;Arindam Mitra and colleagues at Microsoft proposed&nbsp;<a href="https://arxiv.org/abs/2311.11045?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Orca 2</a>, a technique that improves the output of student LLMs an order of magnitude smaller than their teachers.</p><p><strong>Key insight:</strong>&nbsp;Large language models can provide better output when they’re prompted to use a particular reasoning strategy such as think step by step, recall then generate, or explain then generate. Different reasoning strategies may yield better output depending on the task at hand. Moreover, given the same task, different models may perform better using different reasoning strategies. Consequently, in a teacher-student situation, the teacher and student models may need to use different strategies to achieve their highest performances on a given task. The student will achieve its best performance if it mimics the teacher's reasoning and response when the teacher uses not its own best-performing strategy, but the student’s best-performing strategy.</p><p><strong>How it works:</strong>&nbsp;The teacher, GPT-4, helped generate a fine-tuning dataset to improve the output of the student,&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Llama 2</a>&nbsp;(13 billion parameters), both of which had been pretrained. They created the fine-tuning dataset and fine-tuned Llama 2 as follows:</p><ul><li>The authors assembled an initial dataset that included examples (prompts and responses) of roughly 1,500 tasks. They drew from datasets including&nbsp;<a href="https://arxiv.org/abs/2109.01652?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">FLAN</a>&nbsp;(which includes text classification, math questions, logic questions, and multiple choice questions), math problems from 10 datasets not in FLAN, few-shot prompts in the&nbsp;<a href="https://arxiv.org/abs/2306.02707?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Orca</a>&nbsp;dataset, and summarizations generated using GPT-4.</li><li>The authors fed each prompt to Llama 2 using each of several reasoning strategies including direct answer, think step by step, explain then answer, and more. (The authors don’t specify all the strategies they used.) They measured its performance on each task per reasoning strategy.</li><li>For each task, they prompted GPT-4 with all examples of that task, specifying the reasoning strategy that had enabled Llama 2 to achieve its highest performance on that task. In this way, GPT-4 augmented the dataset to include, for each prompt, both the response and the reasoning it used to arrive at it.&nbsp;</li><li>They fine-tuned Llama 2, given a prompt — without specifying the reasoning strategy — to produce the detailed reasoning and response generated by GPT-4.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared their model to models of similar size including WizardLM-13B (also based on Llama 2) and larger models including GPT-3.5 Turbo (an order of magnitude larger) and GPT-4 (parameter count undisclosed). They evaluated the percentage of correct responses on average over six reasoning benchmarks such as&nbsp;<a href="https://arxiv.org/pdf/2304.06364.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">AGIEval</a>, which includes multiple-choice and fill-in-the-blank questions from the Scholastic Aptitude Test, American Mathematics Competitions, and other tests designed for humans. Their model exactly matched the correct answer 66.92 percent of the time compared to WizardLM-13B (50.32 percent). It performed nearly as well as the 10x larger GPT-3.5 Turbo (which achieved 67.65 percent) but much less well than GPT-4 (which achieved 79.03 percent).</p><p><strong>Why it matters:</strong>&nbsp;Learning how to reason is an important complement to learning facts and perspectives. A model that has been trained to reason using its most effective strategy generally will provide better output. Users don’t need to tell it which strategy to apply. They can simply enter a prompt, and the model will figure out how to reason its response.</p><p><strong>We’re thinking:</strong>&nbsp;Perhaps a similar approach could be used to prompt a model to improve its own output. In effect, this would be similar to an agentic workflow designed to enable a model to produce its own training data, as recently&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-247/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">described</a>&nbsp;in&nbsp;<em>The Batch</em>.</p>
]]></content:encoded>
<pubDate>Wed, 05 Jun 2024 23:09:39 GMT</pubDate>
</item>
<item>
<title>Heart-Risk Model Saves Lives, Self-Driving on Unruly Roads, Knowledge Workers Embrace AI, Richer Context for RAG</title>
<link>https://www.deeplearning.ai/the-batch/issue-251</link>
<guid>https://www.deeplearning.ai/the-batch/issue-251</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>A barrier to faster progress in generative AI is evaluations (evals), particularly of custom AI applications that generate free-form text. Let’s say you have a multi-agent research system that includes a researcher agent and a writer agent. Would adding a fact-checking agent improve the results? If we can’t efficiently evaluate the impact of such changes, it’s hard to know which changes to keep.</p><p>For evaluating general-purpose foundation models such as large language models (LLMs) — which are trained to respond to a large variety of prompts — we have standardized tests like MMLU (multiple-choice questions that cover 57 disciplines like math, philosophy, and medicine) and HumanEval (testing code generation). We also have the&nbsp;<a href="https://chat.lmsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">LMSYS Chatbot Arena</a>, which pits two LLMs’ responses against each other and asks humans to judge which response is superior, and large-scale benchmarking like&nbsp;<a href="https://crfm.stanford.edu/helm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">HELM</a>. These evaluation tools took considerable effort to build, and they are invaluable for giving LLM users a sense of different models’ relative performance. Nonetheless, they have limitations. For example, leakage of benchmarks datasets’ questions and answers into training data is a constant worry, and human preferences for certain answers does not mean those answers are more accurate.</p><p>In contrast, our current options for evaluating applications built using LLMs are far more limited. Here, I see two major types of applications.&nbsp;</p><ul><li>For applications designed to deliver unambiguous, right-or-wrong responses, we have reasonable options. Let’s say we want an LLM to read a resume and extract the candidate’s most recent job title, or read a customer email and route it to the right department. We can create a test set that comprises ground-truth labeled examples with the right responses and measure the percentage of times the LLM generates the right output. The main bottleneck is creating the labeled test set, which is expensive but surmountable.</li><li>But many LLM-based applications generate free-text output with no single right response. For example, if we ask an LLM to summarize customer emails, there’s a multitude of possible good (and bad) responses. The same holds for an agentic system to do web research and write an article about a topic, or a RAG system for answering questions. It’s impractical to hire an army of human experts to read the LLM’s outputs every time we tweak the algorithm and evaluate if the answers have improved; we need an automated way to test the outputs. Thus, many teams use an advanced language model to evaluate outputs. In the customer email summarization example, we might design an evaluation rubric (scoring criteria) for what makes a good summary. Given an email summary generated by our system, we might prompt an advanced LLM to read it and score it according to our rubric. I’ve found that the results of such a procedure, while better than nothing, can also be noisy — sometimes too noisy to reliably tell me if the way I’ve tweaked an algorithm is good or bad.</li></ul><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--61-.jpg" width="1200" /></figure><p>The cost of running evals poses an additional challenge. Let’s say you’re using an LLM that costs $10 per million input tokens, and a typical query has 1000 tokens. Each user query therefore costs only $0.01. However, if you iteratively work to improve your algorithm based on 1000 test examples, and if in a single day you evaluate 20 ideas, then your cost will be 20*1000*0.01 = $200. For many projects I’ve worked on, the development costs were fairly negligible until we started doing evals, whereupon the costs suddenly increased. (If the product turned out to be successful, then costs increased even more at deployment, but that was something we were happy to see!)&nbsp;</p><p>Beyond the dollar cost, evals have a significant time cost. Running evals on 1000 examples might take tens of minutes or even hours. Time spent waiting for eval jobs to finish also slows down the speed with which we can experiment and iterate over new ideas. In an earlier letter, I&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-we-need-more-compute-for-inference/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">wrote</a>&nbsp;that fast, inexpensive token generation is critical for agentic workflows. It will also be useful for evals, which involve nested for-loops that iterate over a test set and different model/hyperparameter/prompt choices and therefore consume large numbers of tokens.&nbsp;</p><p>Despite the limitations of today’s eval methodologies, I’m optimistic that our community will invent better techniques (maybe involving agentic workflows like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reflection</a>&nbsp;for getting LLMs to evaluate such output.&nbsp;</p><p>If you’re a developer or researcher and have ideas along these lines, I hope you’ll keep working on them and consider open sourcing or publishing your findings.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-22T112453.236.png" width="1680" /></a></figure><p>Learn how to build and customize multi-agent systems in “AI Agentic Design Patterns with AutoGen,” made in collaboration with Microsoft and Penn State University. Use the AutoGen framework and implement four agentic design patterns: Reflection, Tool Use, Planning, and Multi-Agent Collaboration.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for free</a>&nbsp;</p><hr /><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152617.317.png" width="1200" /></figure><h1 id="heart-risk-model-saves-lives">Heart-Risk Model Saves Lives</h1><p>A deep learning model significantly reduced deaths among critically ill hospital patients.</p><p><strong>What’s new:</strong>&nbsp;A system built by Chin-Sheng Lin and colleagues at Taiwan’s National Defense Medical Center analyzed patients’ heart signals and alerted physicians if it detected a high risk of death. It&nbsp;<a href="https://www.nature.com/articles/s41591-024-02961-4.epdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reduced</a>&nbsp;deaths of high-risk patients by 31 percent in a randomized clinical trial.</p><p><strong>How it works:</strong>&nbsp;Researchers&nbsp;<a href="https://journals.sagepub.com/doi/10.1177/20552076231187247?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">trained</a>&nbsp;a convolutional neural network, given an electrocardiogram (a measurement of the heart’s electrical activity), to&nbsp;<a href="https://en.wikipedia.org/wiki/Proportional_hazards_model?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">estimate</a>&nbsp;a risk score. The system compares a patient’s risk score against those of other patients. Scores that rank in the 95th percentile or higher are considered high risk of death within 90 days.</p><ul><li>The authors tested the system on 16,000 patients at two hospitals for 90 days.</li><li>Patients in the experimental group were measured by electrocardiograms, which were fed to the system. If the system identified a high-risk patient, it alerted their attending physician.</li><li>The control group received typical care. The model monitored their electrocardiograms, but physicians saw its output only after the trial was over.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;8.6 percent of patients in the control group and 8.9 percent of patients in the experimental group raised a high-risk alert during the trial. In the experimental group, 16 percent of high-risk patients died; in the control group, 23 percent of high-risk patients died. Overall, in the experimental group, 3.6 percent of patients died; in the control group, 4.3 percent of patients died. The model was trained to predict mortality from all causes, but it showed unusually strong predictive capability for heart-related deaths. Examining causes of death, the authors found that 0.2 percent of patients in the experimental group died from heart-related conditions such as cardiac arrest versus 2.4 percent in the control group.<br /><br /><strong>Behind the news:</strong>&nbsp;Hospitals use AI-powered alert systems to&nbsp;<a href="https://www.deeplearning.ai/the-batch/managing-medical-uncertainty/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">identify</a>&nbsp;patients in need of urgent medical attention. Such systems monitor emergency room patients for sepsis, predict whether those patients need intensive care, and predict the risk that discharged patients will require further care. They help hospitals to allocate resources by directing attention where it’s needed most urgently.<br /><br /><strong>Why it matters:</strong>&nbsp;It’s rare for any kind of medical intervention to reduce mortality in a subgroup by 31 percent. The authors speculate that the system not only helped direct attention to patients urgently in need of attention but also may have identified electrocardiogram features that doctors typically either don’t understand well or can’t detect.</p><p><strong>We’re thinking:</strong>&nbsp;This relatively low-cost AI system unambiguously saved lives over three months at different hospitals! We look forward to seeing it scale up.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152721.294.gif" width="600" /></figure><h1 id="self-driving-on-indian-roads">Self-Driving on Indian Roads</h1><p>Few makers of self-driving cars have braved the streets of India. Native startups are filling the gap.</p><p><strong>What’s new:</strong>&nbsp;Indian developers are testing autonomous vehicles on their nation’s disorderly local roads. To cope with turbulent traffic, their systems use different technology from their Western and East Asian counterparts,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/india-self-driving-car?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;In Indian cities, two-, three-, and four-wheelers share the road with trucks, pedestrians, and animals. Drivers often contend with debris and potholes, and many don’t follow rules. These conditions demand vehicles outfitted with technology that’s more flexible (and less expensive) than the interwoven sensors, models, and 3D maps employed by self-driving cars designed for driving conditions like those found in the United States.</p><ul><li>Where typical self-driving cars combine visible-light cameras, radar, lidar, and GPS, vehicles built by&nbsp;<a href="https://www.swaayattrobots.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Swaayatt Robots</a>&nbsp;view the world solely through off-the-shelf cameras. The company’s software creates a probabilistic representation of their environment. Although this is normally computationally intensive, Swaayatt claims to have found a low-cost way to do it. Trained via multi-agent reinforcement learning, its systems use game theory to model road interactions and computer vision to fill in missing lane markings. A&nbsp;<a href="https://www.youtube.com/watch?v=cdJ1ETCC6fY&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">video</a>&nbsp;shows one of the company’s SUVs navigating narrow roads in its home city of Bhopal.</li><li><a href="https://www.minuszero.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Minus Zero</a>&nbsp;focuses on highway driving. Its&nbsp;<a href="https://www.designboom.com/technology/autonomous-vehicle-zpod-self-driving-minus-zero-ai-artificial-intelligence-12-13-2023/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">zPod</a>&nbsp;vehicle navigates using cameras and a GPS sensor. Rather than a series of models dedicated to a single task such as object detection or motion planning, zPod employs a world model that recognizes important details in its surroundings and plans accordingly. The company&nbsp;<a href="https://www.reuters.com/business/autos-transportation/indias-ashok-leyland-partners-with-minus-zero-develop-self-driving-trucks-2024-03-19/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">partnered</a>&nbsp;with Indian truck manufacturer Ashok Leyland to deploy the technology in the next several years.</li><li><a href="https://rosh.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">RoshAI</a>&nbsp;specializes in retrofitting existing vehicles with autonomous capabilities. It offers separate systems that map a vehicle’s surroundings, control speed and steering, and generate simulations for testing. It aims to retrofit conventional vehicles at lower cost than the price of an integrated self-driving car.</li></ul><p><strong>Behind the news:</strong>&nbsp;Bringing self-driving cars to India has political as well as technical dimensions. Many Indians hire full-time drivers, and the country’s minister of roads and highways has&nbsp;<a href="https://www.hindustantimes.com/car-bike/around-80-lakh-drivers-will-become-jobless-gadkari-again-says-will-not-allow-autonomous-cars-in-india-101702884761198.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">resisted</a>&nbsp;approving the technology because of its potential impact on those jobs. Drivers cost as little as $150 per month, which puts self-driving car makers under pressure to keep their prices very low. Moreover, India’s government insists that vehicles sold there must be manufactured locally, posing a barrier to foreign makers of self-driving cars.</p><p><strong>Why it matters:</strong>&nbsp;Rather than starting with an assumption that traffic follows orderly patterns with many edge cases, Indian developers assume that traffic is essentially unpredictable. For them, events that most developers would consider outliers — vehicles approaching in the wrong lanes, drivers who routinely play chicken, domestic animals in the way — are common. This attitude is leading them to develop robust self-driving systems that not only may be better suited to driving in complex environments but also may respond well to a broader range of conditions.</p><p><strong>We’re thinking:</strong>&nbsp;Former Uber CEO Travis Kalanick&nbsp;<a href="https://www.firstpost.com/tech/news-analysis/uber-ceo-travis-kalanick-says-india-will-be-the-last-place-to-get-autonomous-cars-3694283.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">said</a>&nbsp;that India would be “the last one” to get autonomous cars. These developers may well prove him wrong!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152833.184.gif" width="1200" /></figure><h1 id="knowledge-workers-embrace-ai">Knowledge Workers Embrace AI</h1><p>AI could offer paths to promotion and relief from busywork for many knowledge workers.</p><p><strong>What’s new:</strong>&nbsp;75 percent of knowledge workers worldwide use AI even if they need to supply their own tools, according to&nbsp;<a href="https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">survey</a>&nbsp;conducted by Microsoft and Linkedin.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors questioned 3,800 workers in 31 countries throughout the Americas, Europe, Asia, and Australia, asking whether and how they used consumer-grade generative systems like Microsoft Copilot and OpenAI ChatGPT. Majorities of all age groups used AI at work, including 85 percent of respondents 28 or younger and 73 percent of those 58 or older.&nbsp;</p><ul><li>Of those who said they used AI at work, 46 percent had started within the past six months, and 78 percent had started without mandates from employers or managers. More than 80 percent said AI tools helped them save time, focus on the most important work, be more creative, and enjoy work more.</li><li>One motivation for using AI was to keep up with basic tasks such as replying to emails and summarizing meetings. In a separate survey, Microsoft found that, over six months, Copilot users spent more time working in creative applications than managing work communications and created or edited 10 percent more documents in Word, Excel, or PowerPoint.</li><li>The survey identified a group that had used AI several times a week and saved at least 30 minutes daily. These users were 68 percent more likely than average to experiment with different ways to use AI and 66 percent more likely to redesign their workflows. Such users were 53 percent more likely to have received encouragement and training in AI from their employer.&nbsp;</li><li>Some employees saw AI as a double-edged sword. 53 percent worried that it made them replaceable. 52 percent of AI users were reluctant to admit using AI for important tasks. Yet 69 percent said that AI could help them get promoted more quickly, and 76 percent said they needed AI skills to stay competitive in the job market.</li><li>66 percent of executives at the vice president level or above said they wouldn’t hire an applicant who didn’t know how to use basic generative AI tools. Junior and less-experienced candidates were more likely to get hired and receive increased responsibility if they had AI skills. Hiring managers reported updating job descriptions and requirements appropriately.</li></ul><p><strong>Behind the news:</strong>&nbsp;The survey results agree with those of other studies of AI’s impact on the workplace. In January, the International Monetary Fund&nbsp;<a href="https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">projected</a>&nbsp;that AI would affect 40 percent of all jobs worldwide (either complementing or replacing them), including 60 percent of jobs in countries like the UK and U.S. that have greater percentages of knowledge workers. A 2023 research paper&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-occupations-likely-to-be-most-affected-by-language-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">argued</a>&nbsp;that white-collar occupations were most likely to be affected by generative AI, in contrast to previous waves of automation that primarily affected blue-collar jobs. Automation driven by AI increased overall employment, evidence gathered by the European Central Bank&nbsp;<a href="https://www.deeplearning.ai/the-batch/european-central-bank-study-finds-surprising-growth-in-jobs-affected-by-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">shows</a>.</p><p><strong>Why it matters:</strong>&nbsp;AI is transforming work from the bottom up. Executives and managers want employees who know how to use the technology, but only 39 percent of the people who already do so received training from their employers. Company-wide encouragement to experiment with and take advantage of AI leads to the best outcomes.</p><p><strong>We’re thinking:</strong>&nbsp;Knowing how to use AI tools is a plus in the current job market. Knowing how to build applications using AI opens another world of doors.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="400" src="https://dl-staging-website.ghost.io/content/images/2024/06/RAPTORv2-1.gif" width="600" /></figure><h1 id="richer-context-for-rag">Richer Context for RAG</h1><p>Text excerpts used in retrieval augmented generation (RAG) tend to be short. Researchers used summarization to pack more relevant context into the same amount of text.</p><p><strong>What’s new:&nbsp;</strong>Parth Sarthi and colleagues at Stanford built&nbsp;<a href="https://arxiv.org/abs/2401.18059?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Recursive Abstractive Processing for Tree-Organized Retrieval</a>&nbsp;(RAPTOR), a retrieval system for LLMs. RAPTOR can choose to deliver original text or summaries at graduated levels of detail, depending on the LLM’s maximum input length.</p><p><strong>Key insight:</strong>&nbsp;RAG improves the output of large language models by gathering from documents and/or web pages excerpts that are relevant to a user’s prompt. These excerpts tend to be brief to avoid exceeding an LLM’s maximum input length. For instance, Amazon Bedrock’s default excerpt length is 200 tokens (words or parts of a word). But important details may be scattered throughout longer passages, so short excerpts can miss them. A summarizer can condense longer passages into shorter ones, and summarizing summaries can condense large amounts of text into short passages.</p><p><strong>How it works:</strong>&nbsp;RAPTOR retrieved material from&nbsp;<a href="https://arxiv.org/abs/2105.03011?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">QASPER</a>, a question answering corpus that contains around 1,600 research papers on natural language processing. The authors processed QASPER through an iterative cycle of summarizing, embedding, and clustering. The result was a graduated series of summaries at ever higher levels of abstraction.</p><ul><li>The authors divided the corpus into excerpts of 100 tokens each. The&nbsp;<a href="https://aclanthology.org/D19-1410.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">SBERT</a>&nbsp;encoder embedded the excerpts.&nbsp;</li><li>A&nbsp;<a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-73003-5_196?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Gaussian mixture model</a>&nbsp;(GMM) clustered the embeddings into groups of similar excerpts.&nbsp;<a href="https://platform.openai.com/docs/models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">GPT-3.5-turbo</a>&nbsp;summarized each group of excerpts.&nbsp;</li><li>This cycle repeated — SBERT embedded the summaries, GMM clustered the embeddings into groups, and&nbsp;<a href="https://platform.openai.com/docs/models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">GPT-3.5-turbo</a>&nbsp;&nbsp;summarized each group of summaries — until no further groups could be formed.&nbsp;</li><li>At inference, to retrieve passages relevant to a user’s prompt, the system computed the cosine similarity between SBERT’s embedding of the prompt and the embedding of each excerpt and summary. It ranked the excerpts and summaries according to their similarity to the prompt, retrieved the highest-scoring ones, and prepended them to the input. It stopped when adding another excerpt or summary would exceed the LLM’s maximum input length.&nbsp;</li><li>The LLM received the concatenated prompt plus excerpts and/or summaries and generated its response.</li></ul><p><strong>Results:</strong>&nbsp;Paired with a variety of LLMs, RAPTOR exceeded other retrievers in RAG performance on QASPER’s test set. Paired with the&nbsp;<a href="https://aclanthology.org/2020.findings-emnlp.171/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">UnifiedQA</a>&nbsp;LLM, RAPTOR achieved 36.7 percent&nbsp;<a href="https://aclanthology.org/D16-1264.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">F1 score</a>&nbsp;(here, the percentage of tokens in common between the output and ground truth), while SBERT (with access to only the 100-token excerpts) achieved 36.23 percent F1 score. Paired with GPT-4, RAPTOR achieved 55.7 percent F1 score (setting a new state of the art for QASPER),&nbsp;<a href="https://aclanthology.org/2020.emnlp-main.550/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">DPR</a>&nbsp;achieved 53.0 percent F1 score, and providing paper titles and abstracts achieved 22.2 percent F1 score.</p><p><strong>Why it matters:</strong>&nbsp;Recent LLMs can process very long inputs, notably&nbsp;<a href="https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Gemini 1.5</a>&nbsp;(up to 2 million tokens) and&nbsp;<a href="https://www.anthropic.com/news/claude-3-family?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Claude 3</a>&nbsp;(200,000 tokens). But it takes time to process so many tokens. Further, prompting with long inputs can be expensive, approaching a few dollars for a single prompt in extreme cases. RAPTOR enables models with tighter input limits to get more context from fewer tokens.</p><p><strong>We’re thinking:</strong>&nbsp;This may be the technique that developers who struggle with input context length have been long-ing for!</p>
]]></content:encoded>
<pubDate>Wed, 29 May 2024 20:31:32 GMT</pubDate>
</item>
<item>
<title>Music Industry Titan Targets AI, End-to-End Multimodality, Millions of Tokens of Context, More Responsive Text-to-Image</title>
<link>https://www.deeplearning.ai/the-batch/issue-250</link>
<guid>https://www.deeplearning.ai/the-batch/issue-250</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>A good way to get started in AI is to start with coursework, which gives a systematic way to gain knowledge, and then to work on projects. For many who hear this advice, “projects” may evoke a significant undertaking that delivers value to users. But I encourage you to set a lower bar and relish small, weekend tinkering projects that let you learn, even if they don’t result in a meaningful deliverable.&nbsp;</p><p>Recently, my son and daughter (ages 3 and 5) were building Lego vehicles. They built a beautiful ice-cream truck as well as a . . . umm . . . colorful and asymmetric dinosaur car, shown in the picture below. While most observers would judge the ice-cream truck as the superior creation, my kids built it by following Lego’s&nbsp;<a href="https://www.lego.com/en-us/product/creative-vehicles-11036?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">instructions</a>, and it is likely identical to thousands of ice-cream trucks built by others. In contrast, building the dinosaur car required creativity and novel thinking. The exercise helped them hone their ability to pick and assemble Lego building blocks.</p><p>There is, of course, room for both mimicking others’ designs (with permission) and coming up with your own. As a parent, I try to celebrate both. (To be honest, I celebrated the dinosaur car more.) When learning to build Lego, it’s helpful to start by following a template. But eventually, building your own unique projects enriches your skills.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145628.272-1.png" width="1200" /></figure><p>As a developer, too, I try to celebrate unique creations. Yes, it is nice to have beautiful software, and the impact of the output does matter. But good software is often written by people who spend many hours tinkering and building things. By building unique projects, you master key software building blocks. Then, using those blocks, you can go on to build bigger projects.</p><p>I routinely tinker with building AI applications, and a lot of my tinkering doesn’t result in anything useful. My latest example: I built a Streamlit app that would authenticate to Google docs, read the text in a doc, use a large language model to edit my text, and write the result back into the doc. I didn’t find it useful in the end because of friction in the user interface, and I’m sure a commercial provider will soon, if they haven’t already, build a better product than I was able to throw together in a couple of hours on a weekend. But such tinkering helps me hone my intuition and master software components (I now know how to programmatically interface with Google docs) that might be useful in future projects. &nbsp;</p><p>If you have an idea for a project, I encourage you to build it! Often, working on a project will also help you decide what additional skills to learn, perhaps through coursework. To sustain momentum, it helps to find friends with whom to talk about ideas and celebrate projects — large or small.&nbsp;</p><p>Keep tinkering!&nbsp;<br /><br />Andrew&nbsp;&nbsp;</p><p>P.S. On the heels of Microsoft’s announcement of the Copilot+ PC, which uses on-device AI optimized for a Qualcomm chip, we have a short course on deploying on-device AI created with Qualcomm! In “Introduction to On-Device AI,” taught by Qualcomm’s Senior Director of Engineering Krishna Sridhar, you’ll deploy a real-time image segmentation model on-device and learn key steps for on-device deployment: neural network graph capture, on-device compilation, hardware acceleration, and validating on-device numerical correctness.&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Please sign up here!</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145727.291.gif" width="1200" /></figure><h1 id="faster-cheaper-multimodality">Faster, Cheaper Multimodality</h1><p>OpenAI’s latest model raises the bar for models that can work with common media types in any combination.<br /><br /><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/index/hello-gpt-4o/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">introduced</a>&nbsp;GPT-4o, a model that accepts and generates text, images, audio, and video — the “o” is for omni — more quickly, inexpensively, and in some cases more accurately than its predecessors. Text and image input and text-only output are available currently via ChatGPT and API, with image output coming soon. Speech input and output will roll out to paying users in coming weeks. General audio and video will be available first to partners before rolling out more broadly.&nbsp;&nbsp;</p><p><strong>How it works:</strong>&nbsp;GPT-4o is a single model trained on multiple media types, which enables it to process different media types and relationships between them faster and more accurately than earlier GPT-4 versions that use separate models to process different media types. The context length is 128,000 tokens, equal to GPT-4 Turbo but well below the 2-million limit newly set by Google Gemini 1.5 Pro.&nbsp;</p><ul><li>The demos are impressive. In a&nbsp;<a href="https://www.youtube.com/watch?v=DQacCB9tDaw&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">video</a>, one of the model’s four optional voices — female, playful, and extraordinarily realistic — narrates a story while adopting different tones from robotic to overdramatic, translates fluidly between English and Italian, and interprets facial expressions captured by a smartphone camera.</li><li>API access to GPT-4o costs half as much as GPT-4 Turbo: $5 per million input tokens and $15 per million output tokens.</li><li>GPT-4o is 2x faster than GPT-4 Turbo on a per-token basis and expected to accelerate to 5x (10 million tokens per minute) in high volumes.&nbsp;</li><li>Audio processing is much faster. GPT-4o responds to audio prompts in 0.3 seconds on average, while ChatGPT’s previous voice mode took 2.8 or 5.4 seconds on average relying on a separate speech-to-text step and then GPT-3.5 or GPT-4, respectively.</li><li>An improved tokenizer makes text processing more token-efficient depending on the language. Gujarati, for instance, requires 4.4x fewer tokens, Telegu 3.5x fewer, and Tamil 3.3x fewer. English, French, German, Italian, Portuguese, and Spanish require between 1.1x and 1.3x fewer tokens.</li></ul><p>GPT-4o significantly outperforms Gemini Pro 1.5 at several benchmarks for understanding text, code, and images including&nbsp;<a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MMLU</a>,&nbsp;<a href="https://github.com/openai/human-eval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">HumanEval</a>,&nbsp;<a href="https://mmmu-benchmark.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MMMU</a>, and&nbsp;<a href="https://www.docvqa.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">DocVQA</a>. It outperformed OpenAI’s own&nbsp;<a href="https://huggingface.co/openai/whisper-large-v3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Whisper-large-v3</a>&nbsp;speech recognition model at speech-to-text conversion and&nbsp;<a href="https://arxiv.org/pdf/2007.10310?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">CoVoST 2</a>&nbsp;language translation.&nbsp;</p><p><strong>Aftershocks:&nbsp;</strong>As OpenAI launched the new model,&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">troubles</a>&nbsp;resurfaced that had led to November’s rapid-fire ouster and reinstatement of CEO Sam Altman. Co-founder and chief scientist Ilya Sutskever, who co-led a team that focused on mitigating long-term risks, resigned. He did not give a reason for his departure; previously he had&nbsp;<a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">argued</a>&nbsp;that Altman didn’t prioritize safety sufficiently. The team’s other co-leader Jan Leike followed,&nbsp;<a href="https://x.com/janleike/status/1791498185627865147?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">alleging</a>&nbsp;that the company had a weak commitment to safety. The company promptly&nbsp;<a href="https://www.wired.com/story/openai-superalignment-team-disbanded/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">dissolved</a>&nbsp;the team altogether and redistributed its responsibilities. Potential legal issues also flared when actress Scarlett Johansson, who had declined an invitation to supply her voice for a new OpenAI model, issued a&nbsp;<a href="https://x.com/yashar/status/1792682664845254683?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">statement</a>&nbsp;saying that one of GPT-4o’s voices sounded “eerily” like her own and demanding to know how the artificial voice was built. OpenAI denied that it had used or tried to imitate Johansson’s voice and withdrew that voice option.</p><p><strong>Why it matters:</strong>&nbsp;Competition between the major AI companies is putting more powerful models in the hands of developers and users at a dizzying pace. GPT-4o shows the value of end-to-end modeling for multimodal inputs and outputs, leading to significant steps forward in performance, speed, and cost. Faster, cheaper processing of tokens makes the model more responsive and lowers the barrier for powerful agentic workflows, while tighter integration between processing of text, images, and audio makes multimodal applications more practical.&nbsp;&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Between GPT-4o, Google’s Gemini 1.5, and Meta’s newly announced&nbsp;<a href="https://arxiv.org/html/2405.09818v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Chameleon</a>, the latest models are media omnivores. We’re excited to see what creative applications developers build as the set of tasks such models can perform continues to expand!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145823.262.gif" width="600" /></figure><h1 id="2-million-tokens-of-context-more">2 Million Tokens of Context &amp; More</h1><p>Google’s annual I/O developers’ conference brought a plethora of updates and new models.&nbsp;<br /><br /><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/developers/gemini-gemma-developer-updates-may-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">announced</a>&nbsp;improvements to its Gemini 1.5 Pro large multimodal model — notably increasing its already huge input context window — as well as new open models, a video generator, and a further step in digital assistants. In addition, Gemini models will power new features in&nbsp;<a href="https://www.euronews.com/next/2024/05/15/google-to-roll-out-ai-generated-summaries-at-top-of-search-engine?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Google Search</a>, Gmail, and Android.</p><p><strong>How it works:</strong>&nbsp;Google launched a variety of new capabilities.</p><ul><li>Gemini 1.5 Pro’s maximum input context window doubled to 2 million tokens of text, audio, and/or video — roughly 1.4 million words, 60,000 lines of code, 2 hours of video, or 22 hours of audio. The 2 million-token context window is available in a “private preview” via Google’s&nbsp;<a href="https://aistudio.google.com/app/waitlist/97595554?utm_source=blog&amp;utm_medium=referral&amp;utm_campaign=keyword&amp;utm_content=&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">AI Studio</a>&nbsp;and&nbsp;<a href="https://cloud.google.com/earlyaccess/cloud-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Vertex AI</a>. The 1 million-token context window ($7 per 1 million tokens) is generally available on those services in addition to the previous 128,000 window ($3.50 per 1 million tokens).</li><li><a href="https://deepmind.google/technologies/gemini/flash/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Gemini 1.5 Flash</a>&nbsp;is a faster distillation of Gemini 1.5 Pro that features a 1 million token context window. It’s available in preview via&nbsp;<a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-1.5-flash-preview-0514?pli=1&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Vertex AI</a>. Due to be generally available in June, it will cost $0.35 per million tokens of input for prompts up to 128,000 tokens or $0.70 per million tokens of input for longer prompts.</li><li>The&nbsp;<a href="https://deepmind.google/technologies/veo/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Veo</a>&nbsp;video generator can create videos roughly a minute long at 1080p resolution. It can also alter videos, for instance keeping part of the imagery constant and regenerating the rest. A web interface called VideoFX is available via a&nbsp;<a href="https://aitestkitchen.withgoogle.com/tools/video-fx?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">waitlist</a>. Google plans to roll out Veo to YouTube users.</li><li>Google&nbsp;<a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">expanded</a>&nbsp;the Gemma family of open models. PaliGemma, which is available now, accepts text and images and generates text. Gemma 2, which will be available in June, is a 27 billion-parameter large language model that aims to match the performance of Llama 3 70B at less than half the size.</li><li>Gemini Live is a smartphone app for real-time voice chat. The app can converse about photos or video captured by the phone’s camera — in the video demo shown above, it remembers where the user left her glasses! It’s part of&nbsp;<a href="https://deepmind.google/technologies/gemini/project-astra/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Project Astra</a>, a DeepMind initiative that aims to create real-time, multimodal digital assistants.</li></ul><p><strong>Precautionary measures:</strong>&nbsp;Amid the flurry of new developments, Google&nbsp;<a href="https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">published</a>&nbsp;protocols for evaluating safety risks. The “Frontier Safety Framework” establishes risk thresholds such as a model’s ability to extend its own capabilities, enable a non-expert to develop a potent biothreat, or automate a cyberattack. While models are in development, researchers will evaluate them continually to determine whether they are approaching any of these thresholds. If so, developers will make a plan to mitigate the risk. Google aims to implement the framework by early 2025.</p><p><strong>Why it matters:</strong>&nbsp;Gemini 1.5 Pro’s expanded context window enables developers to apply generative AI to multimedia files and archives that are beyond the capacity of other models currently available — corporate archives, legal testimony, feature films, shelves of books — and supports prompting strategies such as&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-249/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">many-shot learning</a>. Beyond that, the new releases address a variety of developer needs and preferences: Gemini 1.5 Flash offers a lightweight alternative where speed or cost is at a premium, Veo appears to be a worthy competitor for OpenAI’s Sora, and the new open models give developers powerful options.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Google’s quick iteration on its Gemini models is impressive. Gemini 1.0 was&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-you-need-to-know-about-gemini-googles-new-multimodal-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">announced</a>&nbsp;less than six months ago. White-hot competition among AI companies is giving developers more choices, faster speeds, and lower prices.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1043" src="https://dl-staging-website.ghost.io/content/images/2024/05/V3_DeepLearning_Qualcomm_C1_Banner_2070x1080--1-.png" width="2000" /></a></figure><p>In our new short course “Introduction to On-Device AI,” made in collaboration with Qualcomm, you’ll learn to deploy AI models on edge devices using local compute for faster inference and privacy. Join the next wave of AI as models go beyond the cloud!&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T150014.575.gif" width="1200" /></figure><h1 id="music-titan-targets-ai">Music Titan Targets AI</h1><p>The world’s second-largest music publisher accused AI developers of potential copyright violations.<br /><br /><strong>What’s new:</strong>&nbsp;Sony Music Group&nbsp;<a href="https://www.sonymusic.com/sonymusic/declaration-of-ai-training-opt-out/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">declared</a>&nbsp;that AI developers had trained models on Sony’s intellectual property without permission and that any method of collecting media or other data owned by the company violated its copyrights. Whether AI developers actually have violated copyrights has not been established.</p><p><strong>How it works:</strong>&nbsp;In a&nbsp;<a href="https://www.sonymusic.com/sonymusic/declaration-of-ai-training-opt-out/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">statement</a>&nbsp;posted on the company’s website and&nbsp;<a href="https://www.ft.com/content/c5b93b23-9f26-4e6b-9780-a5d3e5e7a409?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">letters</a>&nbsp;to developers, Sony forbade the use of its music or other media such as lyrics, music videos, album art for “training, developing, or commercializing any AI systems.”</p><ul><li>Sony Music Group sent letters to more than 700 AI developers and streaming services. Letters to AI developers demanded that they reveal which works they had used for training by the following week. Recipients included Google, Microsoft, and text-to-music startups Suno and Udio. Letters sent to streaming services, including Apple and Spotify, asked them to modify their terms of service to prohibit anyone from using streaming services to collect data owned by Sony, among other measures.</li><li>It reserved the right to grant specific developers permission to use its material as training data, asking interested parties to contact Sony by email if they wanted to make a deal.</li></ul><p><strong>Behind the news:</strong>&nbsp;In April, more than 200 music artists&nbsp;<a href="https://artistrightsnow.medium.com/200-artists-urge-tech-platforms-stop-devaluing-music-559fb109bbac?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">called</a>&nbsp;for streaming services and AI developers to stop using their work for training and stop generating music in the styles of specific musicians without compensation. Universal Music Group (UMG), which is Sony Music’s top competitor, has also opposed unrestricted AI-generated music.</p><p>Last year, UMG&nbsp;<a href="https://www.deeplearning.ai/the-batch/universal-music-group-targets-ai-generated-music/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">ordered</a>&nbsp;Apple Music and Spotify to block AI developers from downloading its recordings and issued takedown notices to YouTube and Spotify uploaders who generated music that sounds like artists who are under contract to Universal.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Sony Music Group’s warning comes as generated audio is&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">approaching</a>&nbsp;a level of quality that might attract a mainstream audience, and it could chill further progress. Although it is not yet clear whether training AI systems on music recordings without permission violates copyrights, Sony Music Group has&nbsp;<a href="https://www.nme.com/news/sony-awarded-more-than-800k-over-tiktok-copyright-infringement-3749902?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">demonstrated</a>&nbsp;its willingness to pursue both individuals and companies for alleged copyright violations. The company accounted for 22 percent of the global music market in 2023. (UMG accounted for 32 percent.) Its catalog includes many of the world’s most popular artists including AC/DC, Adele, Celine Dion, and Harry Styles.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>We believe that AI developers should be allowed to let their software learn from data that’s freely available on the internet, but uncertainty over the limits of copyright protection isn’t good for anyone.&nbsp;It’s high time to&nbsp;<a href="https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">update</a>&nbsp;to intellectual property laws for the era of generative AI.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T150103.924.gif" width="600" /></figure><h1 id="interpreting-image-edit-instructions">Interpreting Image Edit Instructions</h1><p>The latest text-to-image generators can alter images in response to a text prompt, but their outputs often don’t accurately reflect the text. They do better if, in addition to a prompt, they’re told the general type of alteration they’re expected to make.<br /><br /><strong>What’s new:&nbsp;</strong>Developed by Shelly Sheynin, Adam Polyak, Uriel Singer, Yuval Kirstain, Amit Zohar and colleagues at Meta,&nbsp;<a href="https://arxiv.org/abs/2311.10089?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Emu Edit</a>&nbsp;enriches prompts with task classifications that help the model interpret instructions for altering images. You can see examples&nbsp;<a href="https://emu-edit.metademolab.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">here</a>.<br /><br /><strong>Key insight:</strong>&nbsp;Typical training datasets for image-editing models tend to present, for each example, an initial image, an instruction for altering it, and a target image. To train a model to interpret instructions in light of the type of task it describes, the authors further labeled examples with a task. These labels included categories for regional alterations such as adding or removing an object or changing the background, global alterations such as changing an image’s style, and computer-vision tasks such as detecting or segmenting objects. &nbsp;<br /><br /><strong>How it works:</strong>&nbsp;Emu Edit comprises a pretrained&nbsp;<a href="https://arxiv.org/abs/2309.15807?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Emu</a>&nbsp;latent diffusion image generator and pretrained/fine-tuned Flan-T5 large language model. The system generates a novel image given an image, text instruction, and one of 16 task designations. The authors generated the training set through a series of steps and fine-tuned the models on it.</p><ul><li>The authors prompted a&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Llama 2</a>&nbsp;large language model, given an image caption from an unspecified dataset, to generate (i) an instruction to alter the image, (ii) a list of which objects to be changed or added, and (iii) a caption for the altered image. For example, given a caption such as, “Beautiful cat with mojito sitting in a cafe on the street,” Llama 2 might generate&nbsp;<em>{"edit": "include a hat", "edited object": "hat", "output": "Beautiful cat wearing a hat with mojito sitting in a cafe on the street"}</em>.</li><li>Given Llama 2’s output, the&nbsp;<a href="https://arxiv.org/abs/2208.01626?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Prompt-to-Prompt</a>&nbsp;image generator produced initial and target images.&nbsp;</li><li>The authors modified Prompt-to-Prompt with unique enhancements for each task. For instance, to alter only parts of an image, Prompt-to-Prompt usually computes and applies a mask to the initial image while generating the target image. The authors noted that the masks tend to be imprecise if original and target captions differ by more than simple word substitutions. To address this, they modified the method for computing masks. In the change-an-object task, a multi-step procedure involving&nbsp;<a href="https://arxiv.org/abs/2304.02643?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">SAM</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2303.05499?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Grounding DINO</a>&nbsp;(a DINO variant fine-tuned for object recognition) generated a mask of the list of objects to be changed.</li><li>Following the typical diffusion process for generating images, Emu learned to remove noise from noisy versions of the target images, given the initial image, the instruction, and the task label.&nbsp;</li><li>The authors fine-tuned Flan-T5. Given a generated instruction, Flan-T5 learned to classify the task. At inference, given the instruction, Flan-T5 provided the task to Emu Edit.</li></ul><p><strong>Results:</strong>&nbsp;Judges compared altered images produced by the authors’ method,&nbsp;<a href="https://www.deeplearning.ai/the-batch/instructpix2pix-for-text-to-image-editing-explained/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">InstructPix2Pix</a>, and&nbsp;<a href="https://arxiv.org/abs/2306.10012?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MagicBrush</a>&nbsp;using the MagicBrush test set. Evaluating how well the generated images aligned with the instruction, 71.8 percent of the time, the judges preferred Emu Edit over InstructPix2Pix, and 59.5 percent of the time, they preferred Emu Edit over MagicBrush. Evaluating how well the generated images preserve elements from the input images, 71.6 percent preferred Emu Edit over InstructPix2Pix, and 60.4 percent preferred Emu Edit over MagicBrush.<br /><br /><strong>Why it matters:</strong>&nbsp;Richer data improves machine learning results. Specifying tasks and generating images that reflect them improved Emu Edit’s data compared to other works, enabling it to achieve better results.&nbsp;<br /><br /><strong>We’re thinking:&nbsp;</strong>Text-to-image generators are amazing and fun to use, but their output can be frustratingly unpredictable. It’s great to see innovations that make them more controllable.</p><hr /><h2 id="a-message-from-fourthbrain">A MESSAGE FROM FOURTHBRAIN</h2><figure class="kg-card kg-image-card"><a href="https://fourthbrain.ai/programs/?utm_campaign=Spring%20Workshops&amp;utm_source=email"><img alt="" class="kg-image" height="972" src="https://dl-staging-website.ghost.io/content/images/2024/05/FourthBrain-Batch-Ad-05222024.png" width="1728" /></a></figure><p>Join FourthBrain's two live workshops next week! In these interactive sessions, you’ll build useful applications with large language models and walk away with practical skills. Enroll as an individual or register as a team for a group discount.&nbsp;<a href="https://fourthbrain.ai/programs/?utm_campaign=Spring%20Workshops&amp;utm_source=email" rel="noreferrer">Learn more</a></p>
]]></content:encoded>
<pubDate>Wed, 22 May 2024 20:05:31 GMT</pubDate>
</item>
<item>
<title>OpenAI’s Rules for Model Behavior, Better Brain-Controlled Robots, AlphaFold 3 Covers All Biochemistry, AI Oasis in the Desert</title>
<link>https://www.deeplearning.ai/the-batch/issue-249</link>
<guid>https://www.deeplearning.ai/the-batch/issue-249</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>In the last couple of days, Google announced a doubling of Gemini Pro 1.5's input context window from 1 million to 2 million tokens, and OpenAI released GPT-4o, which generates tokens 2x faster and 50% cheaper than GPT-4 Turbo and natively accepts and generates multimodal tokens. I view these developments as the latest in an 18-month trend. Given the improvements we've seen, best practices for developers have changed as well.</p><p>Since the launch of ChatGPT in November 2022, with key milestones that include the releases of GPT-4, Gemini 1.5 Pro, Claude 3 Opus, and Llama 3-70B, many model providers have improved their capabilities in two important ways: (i) reasoning, which allows LLMs to think through complex concepts and and follow complex instructions; and (ii) longer input context windows.&nbsp;</p><p>The reasoning capability of GPT-4 and other advanced models makes them quite good at interpreting complex prompts with detailed instructions. Many people are used to dashing off a quick, 1- to 2-sentence query to an LLM. In contrast, when building applications, I see sophisticated teams frequently writing prompts that might be 1 to 2 pages long (my teams call them “mega-prompts”) that provide complex instructions to specify in detail how we’d like an LLM to perform a task. I still see teams not going far enough in terms of writing detailed instructions. For an example of a moderately lengthy prompt, check out&nbsp;<a href="https://twitter.com/AmandaAskell/status/1765207842993434880?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Claude 3’s system prompt</a>. It’s detailed and gives clear guidance on how Claude should behave.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--59--1.jpg" width="1200" /></figure><p>This is a very different style of prompting than we typically use with LLMs’ web user interfaces, where we might dash off a quick query and, if the response is unsatisfactory, clarify what we want through repeated conversational turns with the chatbot.</p><p>Further, the increasing length of input context windows has added another technique to the developer’s toolkit. GPT-3 kicked off a lot of research on few-shot in-context learning. For example, if you’re using an LLM for text classification, you might give a handful — say 1 to 5 examples — of text snippets and their class labels, so that it can use those examples to generalize to additional texts. However, with longer input context windows — GPT-4o accepts 128,000 input tokens, Claude 3 Opus 200,000 tokens, and Gemini 1.5 Pro 1 million tokens (2 million just announced in a limited preview) — LLMs aren’t limited to a handful of examples. With&nbsp;<a href="https://arxiv.org/abs/2404.11018?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">many-shot learning</a>, developers can give dozens, even hundreds of examples in the prompt, and this works better than few-shot learning.&nbsp;</p><p>When building complex workflows, I see developers getting good results with this process:&nbsp;</p><ul><li>Write quick, simple prompts and see how it does.</li><li>Based on where the output falls short, flesh out the prompt iteratively.&nbsp;This often leads to a longer, more detailed, prompt, perhaps even a mega-prompt.</li><li>If that’s still insufficient, consider few-shot or many-shot learning (if applicable) or, less frequently, fine-tuning.</li><li>If that still doesn’t yield the results you need, break down the task into subtasks and apply an agentic workflow.</li></ul><p>I hope a process like this will help you build applications more easily. If you’re interested in taking a deeper dive into prompting strategies, I recommend the Medprompt&nbsp;<a href="https://arxiv.org/abs/2311.16452?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">paper</a>, which lays out a complex set of prompting strategies that can lead to very good results.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p>P.S. Two new short courses:</p><ul><li>“Multi AI Agent Systems with crewAI” taught by crewAI Founder and CEO João Moura: Learn to take a complex task and break it into subtasks for a team of specialized agents. You’ll learn how to design agent roles, goals, and tool sets, and decide how the agents collaborate (such as which agents can delegate to other agents). You'll see how a multi-agent system can carry out research, write an article, perform financial analysis, or plan an event. Architecting multi-agent systems requires a new mode of thinking that's more like managing a team than chatting with LLMs.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agent-workflows-with-crewai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up here!</a></li><li>“Building Multimodal Search and RAG” taught by Weaviate's Sebastian Witalec: In this course, you'll create RAG systems that reason over contextual information across text, images and video. You will learn how to train multimodal embedding models to map similar data to nearby vectors, so as to carry out semantic search across multiple modalities, and learn about visual instruction tuning to add image capabilities to large language models.&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up here!</a></li></ul><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164130.114.gif" width="1200" /></figure><h1 id="why-chatgpt-acts-that-way">Why ChatGPT Acts That Way</h1><p>OpenAI pulled back the curtain on revised rules that will guide its models.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI published its&nbsp;<a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Model Spec</a>, high-level guidelines for use by human labelers to steer model behavior. The company is inviting public&nbsp;<a href="https://openai.com/form/model-spec-feedback?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">comments</a>&nbsp;on the spec until May 22. It has not stated whether or how it will incorporate comments.</p><p><strong>How it works:</strong>&nbsp;During training, human labelers rate a model’s responses so it can be fine-tuned to conform with human preferences in the process known as&nbsp;<a href="https://arxiv.org/pdf/2203.02155?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">reinforcement from human feedback</a>&nbsp;(RLHF). The Model Spec outlines the principles — some new, some previously in use — that will drive those ratings. The principles are arranged hierarchically, and each category will override those below it.</p><ul><li>Three top-level objectives describe basic principles for model behavior: (i) “Assist the developer and end user” defines the relationship between humans and the model. (ii) “Benefit humanity” guides the model to consider both benefits and harms that may result from its behavior. (iii) “Reflect well on OpenAI” reinforces the company’s brand identity as well as social norms and laws.</li><li>Six rules govern behavior. In order, models are to prioritize platform rules above requests from developers, users, and tools; follow laws; withhold hazardous information; respect intellectual property; protect privacy; and keep their output “safe for work.” (These rules can lead to contradictions. For instance, the model will comply if a user asks ChatGPT to translate a request for drug-related information because the directive to follow requests from users precedes the one to withhold hazardous information.)</li><li>What OpenAI calls&nbsp;<em>defaults</em>&nbsp;govern the model’s interaction style. These include “ask clarifying questions when necessary,” “express uncertainty,” “assume an objective point of view,” and “don't try to change anyone's mind.” For example, if a user insists the Earth is flat, the model may respond, “Everyone's entitled to their own beliefs, and I'm not here to persuade you!”</li><li>The spec will evolve in response to the AI community’s needs. In the future, developers may be able to customize it. For instance, the company is considering allowing developers to lift prohibitions on “not safe for work” output such as erotica, gore, and some profanity.</li></ul><p><strong>Behind the news:&nbsp;</strong>OpenAI’s use of the Model Spec and RLHF contrasts with<strong>&nbsp;</strong>Anthropic’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/toward-safer-more-helpful-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Constitutional AI</a>. To steer the behavior of Anthropic models,&nbsp;that company’s engineers define a constitution, or list of principles, such as “Please choose the response that is the most helpful, honest, and harmless” and “Do NOT choose responses that are toxic, racist, or sexist, or that encourage or support illegal, violent, or unethical behavior.” Rather than human feedback, Anthropic relies on&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">AI feedback</a>&nbsp;to interpret behavioral principles and guide reinforcement learning.</p><p><strong>Why it matters:</strong>&nbsp;AI developers require a degree of confidence that the models they use will behave as they expect and in their users’ best interests. OpenAI’s decision to subject its guidelines to public scrutiny could help to instill such confidence, and its solicitation of public comments might make its models more responsive to social and market forces.</p><p><strong>We’re thinking:</strong>&nbsp;OpenAI’s openness with respect to its Model Spec is a welcome step toward improving its models’ safety and performance.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164233.811.gif" width="600" /></figure><h1 id="alphafold-3-embraces-all-biochemistry">AlphaFold 3 Embraces All Biochemistry&nbsp;</h1><p>The latest update of DeepMind’s AlphaFold model is designed to find the structures of not just proteins but all biologically active molecules as well as interactions between them.</p><p><strong>What’s new:&nbsp;</strong>Google&nbsp;<a href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">announced</a>&nbsp;AlphaFold 3, which models the 3D shapes of biomolecules including proteins, DNA, RNA, and ligands (molecules that bind to proteins or DNA, which includes antibodies and many drugs) in any combination. AlphaFold Server&nbsp;<a href="https://golgi.sandbox.google.com/about?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">provides</a>&nbsp;access for noncommercial uses (with some limitations). Unlike earlier versions, AlphaFold 3 is not open source.<br /><br /><strong>Key insight:</strong>&nbsp;Given a sequence of amino acids (the building blocks of proteins), the previous version of AlphaFold drew on an existing knowledge of amino acid structures, computed their locations and angles, and assembled them like Lego blocks. To adapt the system for molecules that aren’t made of amino acids, AlphaFold 3 represents them as collections of individual atoms and uses a generative model to find their positions in space.<br /><br /><strong>How it works:</strong>&nbsp;Given a list of molecules, AlphaFold 3 generates their joint 3D structure, revealing how they fit together. Several transformers hone embeddings of proteins and amino acids, while a diffusion model (also a transformer) processes embeddings of atoms. The team trained the system on five datasets including ground truth protein, DNA, and RNA structures interactions in the&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/10592235/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Protein Data Bank</a>. They also trained it on protein shapes computed by AlphaFold 2; that model’s explicit knowledge of amino acid structures helped overcome AlphaFold 3’s tendency to hallucinate in some instances. Among the key processes:</p><ul><li>Given a protein’s amino acid sequence, a molecule’s set of atoms, or any combination thereof, AlphaFold 3 first represents each common amino acid, nucleotide, and individual atom (that isn’t a part of a common amino acid or nucleotide) with a single token.&nbsp;</li><li>For each token, the system draws on existing databases to compute a variety of features, which fall into five categories: (i) per-token features like position, (ii) features of proteins in the Protein Data Bank, (iii) features of a given molecule, (iv) features derived from a genetic search (for example, whether two amino acid sequences appear to be related evolutionarily) and (v) features that describe chemical bonds between two tokens.&nbsp;</li><li>Given these features, a transformer produces a single embedding that represents all tokens and pairwise embeddings that represent relationships between each pair of tokens. A second transformer refines the pairwise embeddings based on known molecules that share subsequences of amino acids or nucleotides with the input. A third transformer further refines the embeddings.</li><li>Given the features, embeddings, and a noisy point cloud of atoms, the diffusion model removes the noise. (That is, it learned to modify the atoms’ positions to match those in their dataset.)</li><li>AlphaFold 3 learned to optimize seven additional loss terms, including one that minimized the difference between the predicted and actual length of bonds between molecules and another that minimized the difference between predicted and actual distances between pairs of atoms.</li></ul><p><strong>Results</strong>: On&nbsp;<a href="https://github.com/maabuu/posebusters?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">PoseBusters</a>, a database of protein and protein-molecule shapes, AlphaFold 3 successfully found the shapes of about 77 percent of examples, while AutoDock Vina (a non-learning program that models molecular interactions) achieved about 53 percent. On a Protein Data Bank evaluation set, AlphaFold 3 successfully found about 84 percent of protein shapes, while AlphaFold Multimer 2.3 (an update of AlphaFold 2) found 83 percent. Modeling protein-protein interactions, AlphaFold 3 achieved 77 percent, while AlphaFold Multimer 2.3 achieved 67 percent, according to&nbsp;<a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0161879&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">DockQ</a>&nbsp;(a metric for the quality of such interactions).<br /><br /><strong>Behind the news:</strong>&nbsp;The original AlphaFold solved one of the most challenging problems in molecular biology by figuring out how long chains of amino acids would fold, giving scientists clear targets for designing new bioactive molecules. Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/deepmind-isomorphic-alphafold/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">spun off</a>&nbsp;Isomorphic Labs to apply AlphaFold 2 to drug discovery. That company will use AlphaFold 3 and control commercial access to it.<br /><br /><strong>Why it matters:&nbsp;</strong>AlphaFold 3 is a triumph of machine learning. It extends the utility of the previous version beyond proteins, and it computes with unprecedented accuracy how biological molecules will combine, allowing for a more comprehensive understanding of how drugs interact with the body. Its ability to predict how antibodies will bind to proteins could help stave off future pandemics and other illnesses.<br /><br /><strong>We’re thinking:</strong>&nbsp;Although Isomorphic Labs retains control of AlphaFold 3, biologists&nbsp;<a href="https://www.nature.com/articles/d41586-024-01383-z?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">said</a>&nbsp;the information in the paper is enough for other researchers to develop similar systems. We look forward to open versions!</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-14T170959.188.png" width="1680" /></a></figure><p>Learn to develop smarter search, retrieval augmented generation (RAG), and recommender systems for multimodal retrieval and generation in this short course, built in collaboration with Weaviate.&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVG04x6mmDF0W4ZDjnP4LvKh1W4xGMq_5f6rl-N6ybcYq3qgyTW8wLKSR6lZ3mYW4SSkjQ5g9lFJW60DtnC325gKfW1Zq1QN5s92lCW73RYh38tB0mfW4lcNQP7VmHYqW2HRyWZ8nQg2xN5VKrkldDqHYW40GMWb1ws47FW6J9CtY7YQDrHN8cqrdmW0CwRN76_QHhgZrtTW2-k2R-20FYfyMjp31LByGNdW7cK6KR1XqlgkW3BWmDj2vxv6rW4Cm69g6L1fQ1W1h1RV596pQyrW6ztG1-98xX4cW7Kpz9k3QNmVSW5YLMRX2-b_ZqN6lJNhNK8TLBW6cnZCc60jk97W48dxGz3tRHcnW1Kb3cf15wCmsW1rKFgC19Qb_GW8HL9ZM8Y23_dW90sVxk298rm6W3NYsXN4SkX_5f5D3jz-04?ref=dl-staging-website.ghost.io" rel="noopener">Enroll today!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164459.448.png" width="1200" /></figure><h1 id="building-an-ai-oasis">Building an AI Oasis</h1><p>Saudi Arabia plans to spend billions of dollars to become a global AI hub.&nbsp;</p><p><strong>What's new:</strong>&nbsp;The desert kingdom has allocated $100 billion to invest in AI and other technologies,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/04/25/technology/to-the-future-saudi-arabia-spends-big-to-become-an-ai-superpower.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">reported</a>. The massive potential outlay is attracting AI giants and startups alike.</p><p><strong>How it works:</strong>&nbsp;Saudi Arabia, whose economy is based on large reserves of oil, aims to channel its considerable wealth into more sustainable industries. AI is a major target.&nbsp;</p><ul><li>The state-owned Public Investment Fund (PIF) established a subsidiary, Alat, that plans to invest $100 billion in technology broadly by 2030. Alat has joined with partners to commit as much as $200 million to security and surveillance and $150 million to fully automated manufacturing.&nbsp;</li><li>PIF is&nbsp;<a href="https://www.nytimes.com/2024/03/19/business/saudi-arabia-investment-artificial-intelligence.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">negotiating</a>&nbsp;to establish a $40 billion AI fund with Silicon Valley venture capital firm Andreessen Horowitz. The Saudi government also&nbsp;<a href="https://gaia.newnative.ai/news-blog/gaia-launch?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">established</a>&nbsp;GAIA, a $1 billion partnership with U.S. venture capital firm NewNative, to offer startups with seed funding and compute resources provided by Amazon and Google. GAIA-supported companies must register in Saudi Arabia and spend 50 percent of their investment in the country.</li><li>In March, attendees at the third annual LEAP technology conference, held near the Saudi capital of Riyadh, inked more than $10 billion worth of technology deals. For instance, Amazon&nbsp;<a href="https://press.aboutamazon.com/2024/3/aws-to-launch-an-infrastructure-region-in-the-kingdom-of-saudi-arabia?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">committed</a>&nbsp;$5.3 billion to Saudi cloud computing infrastructure and AI training.&nbsp;</li><li>The Saudi government spent considerable resources building an AI research hub at King Abdullah University of Science and Technology. The university has hired foreign AI researchers and arranged to&nbsp;<a href="https://www.datacenterdynamics.com/en/news/report-saudi-arabia-acquires-3000-nvidia-gpus-uae-buys-thousands/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">buy</a>&nbsp;more than 3,000 Nvidia H100 chips.</li></ul><p><strong>Behind the news:</strong>&nbsp;Where AI is concerned, Saudi Arabia is competing with the neighboring United Arab Emirates (UAE). In March, UAE member state Abu Dhabi&nbsp;<a href="https://www.reuters.com/breakingviews/middle-east-ai-dream-depends-luring-brainpower-2024-03-22/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">established</a>&nbsp;its own multibillion-dollar investment fund, MGX, which aims to secure deals in AI models, data centers, and semiconductors. One of MGX’s founding partners (and a cornerstone in the UAE’s AI efforts) is G42, a conglomerate with ties to the Emirati government that owns numerous AI research labs and other assets. G42 recently&nbsp;<a href="https://news.microsoft.com/2024/04/15/microsoft-invests-1-5-billion-in-abu-dhabis-g42-to-accelerate-ai-development-and-global-expansion/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">received</a>&nbsp;$1.5 billion from Microsoft. Last year, it&nbsp;<a href="https://www.deeplearning.ai/the-batch/nvidias-competitor-cerebras-secured-a-contract-with-a-major-tech-conglomerate/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">paid</a>&nbsp;U.S. chip designer Cerebras an initial $100 million to build up to nine supercomputers.<br /><br /><strong>Yes, but:</strong>&nbsp;Saudi investments have not always arrived on the expected schedule. Founders of startups that were promised GAIA funding have&nbsp;<a href="https://www.forbes.com/sites/iainmartin/2024/04/16/saudi-arabia-promised-ai-founders-billions-in-investment-some-are-still-waiting-to-get-paid/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">complained</a>&nbsp;of delays and nonpayments. Moreover, U.S. partners such as Microsoft have drawn&nbsp;<a href="https://www.hrw.org/news/2023/05/23/saudi-arabia-microsoft-should-suspend-data-center-plans?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">criticism</a>&nbsp;for working with Saudi Arabia, which has been&nbsp;<a href="https://en.wikipedia.org/wiki/Human_rights_in_Saudi_Arabia?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">accused</a>&nbsp;of violating human rights. The U.S. government&nbsp;<a href="https://www.dw.com/en/us-china-tech-war-ai-sparks-first-battle-in-middle-east/a-66968886?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">blocked</a>&nbsp;fulfillment of the King Abdullah University’s purchase of Nvidia chips because it may help researchers associated with the Chinese military to circumvent U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">restrictions</a>&nbsp;on the export of advanced semiconductors. Earlier this year, U.S.-based generative AI startup Anthropic&nbsp;<a href="https://www.cnbc.com/2024/03/22/anthropic-lining-up-a-new-slate-of-investors-ruled-out-saudi-arabia.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">rejected</a>&nbsp;potential investment from PIF citing national security concerns.</p><p><strong>Why it matters:</strong>&nbsp;AI is fast becoming a source of national power, and many countries are eager to build their capabilities. Saudi Arabia’s investment could go a long way toward building facilities and talent in a part of the world that has not been known for high tech. For the country itself, it could bring economic growth and geopolitical advantage. For foreign companies and talent, it’s an immense new source of funding to pursue valuable projects and gain practical experience.</p><p><strong>We're thinking:</strong>&nbsp;We are happy to see AI hubs emerge around the world, especially in places that can provide more opportunities for people who live outside of established AI centers.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164549.473.gif" width="600" /></figure><h1 id="brain-controlled-robots-get-more-versatile">Brain-Controlled Robots Get More Versatile</h1><p>Brain-to-computer interfaces that enable users to control robots with their thoughts typically execute a single type of task such as reaching and grasping. Researchers designed a system that responds to a variety of intentions.</p><p><strong>What's new:</strong>&nbsp;Ruohan Zhang and colleagues at Stanford introduced&nbsp;<a href="https://arxiv.org/abs/2311.01454?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Neural Signal Operated Intelligent Robots (NOIR)</a>. Their method commands a robot to perform practical tasks, such as ironing a cloth or making a sandwich, via signals from an electroencephalogram (EEG), a non-invasive way to measure brain waves via electrodes attached to the scalp.</p><p><strong>Key insight:</strong>&nbsp;Currently neuroscientists can derive from EEG signals only simple thoughts, such as the intention to move a limb. However, a sequence of simple thoughts can drive an arbitrarily complex action. Specifically, simple thoughts (such as the intention to move a hand) can drive a robot to perform complex actions by repeatedly (i) selecting an object, (ii) selecting an action to apply to the object, and (iii) selecting the part of the object to act upon. For instance, to iron a cloth, the initial sequence would be: (i) select the iron and (ii) grasp it (iii) by the handle. This sequence might be followed by (i) select the cloth and (ii) slide the iron across it (iii) starting at the nearest portion. And so on.</p><p><strong>How it works:</strong>&nbsp;Users who wore EEG electrodes concentrated on specific sequences of thoughts to execute tasks as they watched a screen that displayed the output of a camera attached to either a&nbsp;<a href="https://franka.de/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">robotic arm</a>&nbsp;or&nbsp;<a href="https://pal-robotics.com/robots/tiago/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">wheeled robot with two arms</a>.&nbsp;</p><ul><li>Prior to attempts to control a robot, the authors recorded EEG signals to train the system for each individual user. Users spent 10 minutes imagining grasping a ball in their right or left hand, pushing a pedal with both feet, or focusing on a cross displayed on the screen (a resting state). The authors used the resulting data to train two&nbsp;<a href="https://en.wikipedia.org/wiki/Quadratic_classifier?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Quadratic Discriminant Analysis</a>&nbsp;(QDA) classifiers for each user.</li><li>To enable users to select objects, a pretrained&nbsp;<a href="https://arxiv.org/abs/2205.06230?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">OWL-ViT</a>&nbsp;segmented the camera image to mark individual objects on the screen. Objects available to be manipulated flickered at different frequencies between 6 and 10 times per second. When a user concentrated on an object, the resulting brainwaves synchronized with the frequency of its flickering. The system selected the object that corresponded to the most prominent frequency.&nbsp;</li><li>Once the user had selected an object, the system presented up to four possible actions, such as “pick from top,” “pick from side,” and “push.” Each action was accompanied by an image of a right or left hand, feet, or a cross. To select an action, the user imagined using the designated body part or focusing on the cross. Given the EEG signal, one classifier selected the action.</li><li>To select a location on the object, the other classifier helped the user to point at it using a cursor. To move the cursor in one direction, the user imagined using one hand. To move it in the opposite direction, the user focused on a cross. The user repeated this process for each of three axes of motion (horizontal, vertical, and depth).</li><li>In case the system didn’t read a selection correctly, the user could reset the process by clenching their jaw.</li><li>To make the system easier to use, the authors adapted an&nbsp;<a href="https://arxiv.org/abs/2203.12601?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">R3M</a>&nbsp;embedding model to suggest commonly selected objects and actions. R3M was pretrained to generate similar embeddings of paired robot instructions and camera views and dissimilar embeddings of mismatched robot instructions and camera views. The authors added several fully connected layers and trained them on the individual-user data to produce similar embeddings of images from the camera with the same object-action combination and dissimilar embeddings of images with other object-action combinations. Given an image from the camera, the model returned the object-action that corresponded to the most similar image.</li></ul><p><strong>Results:&nbsp;</strong>Three users controlled the two robots to execute 20 everyday tasks. On average, the system selected objects with 81.2 percent accuracy, actions with 42.2 percent accuracy, and locations with 73.9 percent accuracy. Users took an average of about 20 minutes to complete each task.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Brain signals are enormously complex, yet relatively simple statistical techniques — in this case, QDA — can decode them in useful ways.</p><p><strong>We're thinking:</strong>&nbsp;Sometimes the simplest solution to a difficult problem is not to train a larger model but to break down the problem into manageable steps.</p><hr /><h2 id="new-from-deeplearningai-1">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-14T171114.198.png" width="1680" /></a></figure><p>In “Multi AI Agent Systems with crewAI,” you’ll learn key principles for designing AI agents and organizing teams of agents to perform complex, multi-step tasks. You’ll apply these concepts to automate six common business processes.&nbsp;<a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up for free!</a></p>
]]></content:encoded>
<pubDate>Wed, 15 May 2024 21:51:45 GMT</pubDate>
</item>
<item>
<title>OpenAI Licenses News Archives, Generative Coding From Plan to Pull Request, Recognizing Landmines, Streamlined Inference</title>
<link>https://www.deeplearning.ai/the-batch/issue-248</link>
<guid>https://www.deeplearning.ai/the-batch/issue-248</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Last week, I spoke about AI and regulation at the U.S. Capitol at&nbsp;an event that was attended by legislative and business leaders. I’m encouraged by the progress the open source community has made fending off regulations that would have stifled innovation. But opponents of open source are continuing to shift their arguments, with the latest worries centering on open source's impact on national security. I hope we’ll all keep protecting open source!&nbsp;</p><p>Based on my conversations with legislators, I’m encouraged by the progress the U.S. federal government has made getting a realistic grasp of AI’s risks. To be clear, guardrails are needed. But they should be applied to AI applications, not to general-purpose AI technology.&nbsp;</p><p>Nonetheless, as I&nbsp;<a href="https://www.deeplearning.ai/the-batch/keep-open-source-free/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">wrote</a>&nbsp;previously, some companies are eager to limit open source, possibly to protect the value of massive investments they’ve made in proprietary models and to deter competitors. It has been fascinating to watch their arguments change over time.</p><p>For instance, about 12 months ago, the Center For AI Safety’s “<a href="https://www.safe.ai/work/statement-on-ai-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Statement on AI Risk</a>” warned that AI could cause human extinction and stoked fears of AI taking over. This alarmed leaders in Washington. But many people in AI pointed out that this dystopian science-fiction scenario has little basis in reality. About six months later, when I&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-doomsday-scenarios-and-how-to-guard-against-them/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">testified</a>&nbsp;at the U.S. Senate’s AI Insight forum, legislators no longer worried much about an AI takeover.</p><p>Then the opponents of open source shifted gears. Their leading argument shifted to the risk of AI helping to create bioweapons. Soon afterward,&nbsp;<a href="https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">OpenAI</a>&nbsp;and&nbsp;<a href="https://www.rand.org/news/press/2024/01/25.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">RAND</a>&nbsp;showed that current AI does not significantly increase the ability of malefactors to build bioweapons. This fear of AI-enabled bioweapons has diminished. To be sure, the possibility that bad actors could use bioweapons — with or without AI — remains a topic of great international concern.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T152327.782-1.png" width="1200" /></figure><p>The latest argument for blocking open source AI has shifted to national security. AI is useful for both economic competition and warfare, and open source opponents say the U.S. should make sure its adversaries don’t have access to the latest foundation models. While I don’t want authoritarian governments to use AI, particularly to wage unjust wars, the LLM cat is out of the bag, and authoritarian countries will fill the vacuum if democratic nations limit access. When, some day, a child somewhere asks an AI system questions about democracy, the role of a free press, or the function of an independent judiciary in preserving the rule of law, I would like the AI to reflect democratic values rather than favor authoritarian leaders’ goals over, say, human rights.&nbsp;</p><p>I came away from Washington optimistic about the progress we’ve made. A &nbsp;year ago, legislators seemed to me to spend 80% of their time talking about guardrails for AI and 20% about investing in innovation. I was delighted that the ratio has flipped, and there was far more talk of investing in innovation.</p><p>Looking beyond the U.S. federal government, there are many jurisdictions globally. Unfortunately, arguments in favor of &nbsp;regulations that would stifle AI development continue to proliferate. But I’ve learned from my trips to Washington and other nations’ capitals that talking to regulators does have an impact. If you get a chance to talk to a regulator at any level, I hope you’ll do what you can to help governments better understand AI.&nbsp;</p><p>Keep learning,<br />Andrew</p><p>P.S. Two new short courses!</p><ul><li>I’m thrilled to announce our first short course focused on agentic workflows: “<a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9rsco1t53WrNq8oTk-wX4HAtWVypFA6VFpC58cihdUR6gTq4FHeMdGGzcO3FCdxtzMHScF" rel="noopener">Building Agentic RAG with LlamaIndex</a>,” taught by LlamaIndex CEO Jerry Liu. This covers an important shift in RAG. Rather than having a developer write explicit routines to retrieve information to feed into an LLM’s context, we can build a RAG agent that has access to tools to retrieve information. This lets it decide what information to fetch, and lets it answer more complex questions using multi-step reasoning.</li><li>Additionally, I’m delighted to launch “<a href="https://www.deeplearning.ai/short-courses/quantization-in-depth/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9rsco1t53WrNq8oTk-wX4HAtWVypFA6VFpC58cihdUR6gTq4FHeMdGGzcO3FCdxtzMHScF" rel="noopener">Quantization in Depth</a>,” taught by Hugging Face’s&nbsp;Marc Sun and Younes Belkada. Quantization is a key technique for making large models accessible. You’ll learn about implementing linear quantization variants, quantizing at different granularities, and compressing deep learning models to 8-bit and 2-bit precision.</li></ul><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T152519.838-1.gif" width="1200" /></figure><h1 id="coding-assistance-start-to-finish">Coding Assistance Start to Finish</h1><p>GitHub Copilot’s latest features are designed to help manage software development from plan to pull request.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;GitHub&nbsp;<a href="https://github.blog/2024-04-29-github-copilot-workspace/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">unveiled</a>&nbsp;a preview of Copilot Workspace, a generative development environment that’s designed to encompass entire projects. Users can sign up for a&nbsp;<a href="https://githubnext.com/projects/copilot-workspace?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">waitlist</a>&nbsp;to gain access to Workspace until the preview ends. Afterward, Copilot Workspace will be available to subscribers to GitHub Copilot (which starts at $10 per month for individuals and $19 per month for businesses).</p><p><strong>How it works:&nbsp;</strong>Copilot Workspace is based on GPT-4 Turbo and integrated with GitHub code repositories and libraries. Where GitHub Copilot previously generated code snippets and provided suggestions for editing code segments, Copilot Workspace integrates these tasks within a larger plan.&nbsp;</p><ul><li>Users begin by providing a known bug, feature request, or codebase and then prompting the system. For instance, a user can provide code for a simple Pong-style video game and request a feature, such as an automated opponent to play against.</li><li>Given the request, the system determines the current state of the codebase, then proposes goals the code will meet once the new feature has been implemented. For example, the system might propose, “the computer controls the left paddle automatically, allowing for a single-player game against the computer” and “the game mechanics and logic for the computer’s movement have been added to index.jsx.”</li><li>The goals function as a new prompt, spurring the system to plan intermediate steps to reach them. For instance, the revised plan might include, “add computer player logic for paddle 1 that blocks the ball 95% of the time” and “remove logic for player control of paddle 1.”&nbsp;</li><li>Users can edit all of this before telling the system to carry out the plan. Afterward, the resulting code can be edited, previewed, shared, and subjected to new tests.&nbsp;</li><li>Once the code has passed the tests, users can upload it directly to GitHub as a pull request or fork in the code repository or library.</li></ul><p><strong>Yes, but:&nbsp;</strong>Initial users&nbsp;<a href="https://every.to/chain-of-thought/i-spent-24-hours-with-github-copilot-workspaces?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">noted</a>&nbsp;that Copilot Workspace is best at solving straightforward, well defined problems and struggles with more complex ones. Choices can be difficult to unwind later on, and the system is slower than simpler AI coding assistants.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Generative coding assistants quickly have become central tools for software development. Copilot has&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-04-17/microsoft-s-ai-copilot-is-starting-to-automate-the-coding-industry?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">attracted</a>&nbsp;1.3 million paid subscribers as of April 2024, including 50,000 businesses. Amazon’s&nbsp;<a href="https://aws.amazon.com/q/developer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Q Developer</a>&nbsp;(formerly CodeWhisperer), Google’s&nbsp;<a href="https://cloud.google.com/products/gemini/code-assist?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Gemini Code Assist</a>&nbsp;(formerly Duet AI), and&nbsp;<a href="https://cursor.sh/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Cursor</a>&nbsp;offer coding companions that integrate with or fork popular integrated development environments like Microsoft’s VSCode. On the frontier are&nbsp;<a href="https://www.deeplearning.ai/the-batch/next-generation-coding-tools-empower-developers-with-agent-style-interactions/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">agentic tools</a>&nbsp;that plan and carry out complex, multi-step coding tasks.<br /><br /><strong>Why it matters:</strong>&nbsp;Copilot Workspace attempts to extend Copilot’s code-completion and chat capabilities to a wider swath of the software development cycle. Simpler coding assistants have been shown to&nbsp;<a href="https://dl.acm.org/doi/pdf/10.1145/3633453?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">boost</a>&nbsp;productivity markedly. Bringing natural-language prompting to tasks like planning, testing, and reading documentation is a natural step.</p><p><strong>We’re thinking:</strong>&nbsp;There are many ways to use AI in coding. To learn about a few more, check out our short course, “<a href="https://www.deeplearning.ai/short-courses/pair-programming-llm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Pair Programming With a Large Language Model</a>,” taught by Google AI advocate Laurence Moroney.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--58-.jpg" width="1200" /></figure><h1 id="openai-licenses-news-archives">OpenAI Licenses News Archives</h1><p>OpenAI has been making deals with publishers to gain access to high-quality training data. It added&nbsp;<em>Financial Times</em>&nbsp;to the list.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://www.ft.com/content/33328743-ba3b-470f-a2e3-f41c3a366613?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">licensed</a>&nbsp;the archive of business news owned by&nbsp;<em>Financial Times&nbsp;</em>(<em>FT</em>) for an undisclosed sum. The agreement lets OpenAI train its models on the publisher’s articles and deliver information gleaned from them. This is OpenAI’s fifth such agreement with major news publishers in the past year.</p><p><strong>How it works:&nbsp;</strong>Although the parties didn’t disclose the length of their agreement, OpenAI’s other news licensing deals will end within a few years. The limited commitment suggests that these arrangements are experimental rather than strategic. The deal includes articles behind the publisher’s paywall; that is, not freely available on the open internet. This enables OpenAI to train its models on material that competitors may not have. Other deals have given OpenAI exclusive access, shutting competitors out.</p><ul><li>The deal with&nbsp;<em>FT</em>&nbsp;gives OpenAI nonexclusive rights to search, index, and train its models on the publisher’s articles, including articles behind its paywall. It also lets OpenAI enable ChatGPT to cite, summarize, and link to the publishers’ works. The parties&nbsp;<a href="https://aboutus.ft.com/press_release/openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">called</a>&nbsp;the deal a “strategic partnership” as well as a licensing agreement, although it’s unclear whether OpenAI will share technology or data with&nbsp;<em>FT</em>.</li><li>In March, OpenAI&nbsp;<a href="https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">announced</a>&nbsp;multi-year agreements with French newspaper&nbsp;<em>Le Monde</em>&nbsp;and Prisa Media (Spanish owner of the newspapers&nbsp;<em>El País</em>,&nbsp;<em>Diario AS</em>, and&nbsp;<em>Cinco Días</em>). The agreements give OpenAI rights to summarize and train AI models on their articles and make the publishers, respectively, OpenAI’s exclusive providers of French- and Spanish-language news.</li><li>In December 2023, OpenAI&nbsp;<a href="https://www.axelspringer.com/en/ax-press-release/axel-springer-and-openai-partner-to-deepen-beneficial-use-of-ai-in-journalism?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">signed</a>&nbsp;a three-year, nonexclusive deal with German publisher Axel Springer, owner of German-language newspapers&nbsp;<em>Bild</em>&nbsp;and&nbsp;<em>Die Welt</em>&nbsp;as well as English-language websites&nbsp;<em>Politico</em>&nbsp;and&nbsp;<em>Business Insider</em>. The deal allows OpenAI to train on, summarize, and link to Axel Springer’s articles, including paywalled content, and makes the publisher OpenAI’s exclusive supplier of German-language news. It was worth “tens of millions of euros,”&nbsp;<a href="https://finance.yahoo.com/news/openai-axel-springer-ink-deal-145333092.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">according to</a>&nbsp;<em>Bloomberg</em>.</li><li>In July 2023, OpenAI&nbsp;<a href="https://www.ap.org/media-center/press-releases/2023/ap-open-ai-agree-to-share-select-news-content-and-technology-in-new-collaboration/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">gained</a>&nbsp;nonexclusive rights for two years to train its models on some of the text of the&nbsp;<em>Associated Press</em>&nbsp;(<em>AP</em>) archive of news articles, which freely is available on the open web. In return,&nbsp;<em>AP</em>&nbsp;received undisclosed access to OpenAI’s “technology and product expertise.” Unlike the other agreements, the deal with&nbsp;<em>AP</em>&nbsp;(which does not have a paywall) does not grant OpenAI specific rights to summarize or link to&nbsp;<em>AP</em>’s stories.</li></ul><p><strong>Behind the news:</strong>&nbsp;Archives of news articles may be handy if OpenAI proceeds with a rumored search service&nbsp;<a href="https://www.theinformation.com/articles/openai-develops-web-search-product-in-challenge-to-google?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">reported</a>&nbsp;by in February by&nbsp;<em>The Information</em>. Licensing is a way to get such material that is unambiguously legal. Although AI researchers commonly scrape data from the web and use it for training models without obtaining licenses for copyrighted works, whether a license is required to train AI models on works under copyright in the U.S. has yet to be determined. Copyright owners lately have challenged this practice in court. In December 2023,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">sued</a>&nbsp;OpenAI and Microsoft, claiming that OpenAI infringed its copyrights by training models on its articles. In April 2024, eight U.S. newspapers owned by Alden Global Capital, a hedge fund,&nbsp;<a href="https://www.theguardian.com/technology/2024/apr/30/us-newspaper-openai-lawsuit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">filed</a>&nbsp;a lawsuit against the same defendants on similar grounds. Licensing material from publishers gives OpenAI access to their works while offering them incentives to negotiate rather than sue.<br /><br /><strong>Why it matters:</strong>&nbsp;AI developers need huge amounts of media to train larger and larger models. News publishers have huge archives with high-quality text, relatively well written and fact-checked, that’s relevant to current events of interest to a broad audience. Licensing those archives gives developers access to what they need without incurring legal risk. Furthermore, making news archives available for retrieval augmented generation makes chatbots more capable and reliable.</p><p><strong>We’re thinking:&nbsp;</strong>We support efforts to clarify the legal status of training AI models on data scraped from the web. It makes sense to treat the open web pages and paywalled content differently, but we advocate that AI models be free to learn from the open internet just as humans can.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/4--3-.png" width="1680" /></a></figure><p>Explore the newest additions to our short courses with “<a href="https://www.deeplearning.ai/short-courses/quantization-in-depth/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m">Quantization in Depth</a>,” where you’ll build a quantizer in PyTorch, and “<a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m">Building Agentic RAG with LlamaIndex</a>,” which teaches how to build agents capable of tool use, reasoning, and making decisions based on your data.&nbsp;<a href="https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up now!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T164752.068.png" width="1200" /></figure><h1 id="landmine-recognition">Landmine Recognition</h1><p>An AI system is scouring battlefields for landmines and other unexploded ordnance, enabling specialists to defuse them.</p><p><strong>What’s new:</strong>&nbsp;The military hardware firm Safe Pro Group developed Spotlight AI, a computer vision system that identifies mines based on aerial imagery,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/ukraine-drones?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">reported</a>. Nongovernmental organizations that remove landmines, including the Norwegian People's Aid and the HALO Trust, are using the system in Ukraine.&nbsp;</p><p><strong>How it works:</strong>&nbsp;SpotlightAI processes visual-light imagery taken by flying drones. The system provides centimeter-resolution maps that guide mine-removal teams through the territory.</p><ul><li>The system includes an unidentified vision model trained to recognize 150 types of explosive munitions, primarily of U.S. and Russian origin. In a test, the model detected 87 percent of munitions scattered across a munitions test range in Hungary.</li><li>With sufficient computational resources, the system can analyze an image in around 0.5 seconds. A human reviewer typically takes three minutes.</li><li>The system struggles to identify explosives concealed by earth or dense vegetation. To address this limitation, Safe Pro Group has begun to test it with infrared, lidar, magnetometry, and other types of imagery. In addition, the company has developed a system that converts drone imagery into a heat map that shows a machine learning model’s estimated probability that it can detect explosives in a given location. A patch of grass, for example, may have a higher estimated probability than a dense thicket of trees and bushes.</li><li>The company aims to fine-tune its model to detect unexploded ordnance in other current or former conflict zones such as Angola, Iraq, and Laos.</li></ul><p><strong>Behind the news:</strong>&nbsp;In addition to drones, satellites can help machine learning models to find deadly remnants of warfare. In 2020, Ohio State University researchers&nbsp;<a href="https://www.deeplearning.ai/the-batch/where-are-the-live-bombs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">estimated</a>&nbsp;the number of undetonated explosives in Cambodia by collating bomb craters in satellite images identified by a computer vision model with records of U.S. military bombing campaigns in that country in the 1960s and 1970s.</p><p><strong>Why it matters:</strong>&nbsp;Unexploded mines, bombs, and other types of munitions&nbsp;<a href="https://www.the-monitor.org/media/3389440/landmine-monitor-2023_web.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">killed or injured</a>&nbsp;more than 4,700 people — 85 percent of them civilians and half of them children where military status and age were known — in 2022 alone. Efforts to remove every last mine from a former battlefield likely will continue to rely on traditional methods — manual analysis of overhead imagery along with sweeps by human specialists and explosive-sniffing dogs — but machine learning can significantly reduce the hazard and accelerate the work.</p><p><strong>We’re thinking:</strong>&nbsp;Although this system locates unexploded mines and shells, removing them often still falls to a brave human. We hope for speedy progress in robots that can take on this work as well.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T164933.555.gif" width="600" /></figure><h1 id="streamlined-inference">Streamlined Inference</h1><p>It’s not necessary to activate all parts of a large language model to process a given input. Using only the necessary parts saves processing.</p><p><strong>What’s new:</strong>&nbsp;Zichang Liu and collaborators at Rice University, Zhe Jiang University, Stanford, University of California San Diego, ETH Zürich, Adobe, Meta, and Carnegie Mellon proposed&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFv3qgyTW7lCdLW6lZ3q4W7jY3WF8hg_kcW26q5z22x1L8sW2M0rg84-DZ9SW2GR61_2BkmYLW2nQvXX66qh5dW8Q_Str879wCbW3qQ6QW6bdyhCW8YnJmq1ZtLZVW5JtVGY4K1hb5W3nnL886btGhKW2J_Yr15YB_qCW11nQQY5RMWB-W1tfHhv7xH4fyW5SrZq_2HzkDkW8phBJW2_NsMVN7mrmCgskvN3W1rWVJ47hYf2qVq7VV743fqjwN1-BYcgjlYQ8VHf78S4_WwW2VXJSpw1TcMl6W12GC-H3Rhn0MVrJfj55wjc6VW63lj1j1hx8dbf4kFFlR04?ref=dl-staging-website.ghost.io" rel="noopener">Deja Vu</a>, an algorithm that accelerates inferencing of large language models (LLMs) by using small vanilla neural networks to predict which parts of it to use.</p><p><strong>Key insight:</strong>&nbsp;Transformer-based neural networks can save a lot of time at inference by activating only a fraction of (i) attention heads and (ii) neurons in fully connected layers. But it’s necessary to activate the right neurons, because different parts of the network learn about different patterns of inputs. By using the input to decide which parts of the network to activate, the network can maintain accuracy using only the parts relevant for the current input.</p><p><strong>How it works:</strong>&nbsp;The authors used pretrained&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3nTW4LydH91RLl6QW3BJN4R84l_7GW2-h6c54swtF0W6tLHpN8Y4KjGW7nk2Sp18W-LWN3MBhL7d5q1sN5y8GBsfTgV5W5kWbf27p7NwlW8dQcf84cQWbPW3b1CDc7qlj64N6P7Nqm6bgm3W91PtwH5CvWh-W5GfbS_3w6XQcW6sYRS-6rzLy9N6ypWg4CC9-vW4nt-ss9gwkSWW8wbSzR3H2zMxW2Q8XDp8mYRs1VkT-LZ9m1-KSVLDv4f2wMGkcW756bRY8mhsGWN4CSFxvBRG-Pf7F36SF04?ref=dl-staging-website.ghost.io" rel="noopener">OPT</a>&nbsp;models of various sizes (175, 66, and 30 billion parameters). They built a dataset by feeding examples from&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3pjW6KTZKm1LxSrMN8BSzzM_lBD-VG39nC44SkC7W6NNBQw4869bZMC7Wc1b5bhTN8n85VLCy1RZW1NzTVN52JMDDW3ZfhHJ3wrr7gW4npQwR3PvF_hW6cdM3H332WwyW6n96fp7l1BbPW4dqL8-2z96tcW1vBXC-5ZQ84LVc9PbD5CYmKmW7N_CKx8tLjVnW2ChCqF4s-G3pW6JQWZZ4CFD8QW546gW65qhm9vW6HZxss3WMCPqW77FWkB47V5jKW5f5sj01N-QkNW8lxCqd8-TLycf8Kkvr604?ref=dl-staging-website.ghost.io" rel="noopener">OpenBookQA</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3lZW7-CP1c80tXv7W5M89jq3TtQrrW8_DBX285mpmPW4dWr1c8nnpYVVJ5_j_2hnMXhW2sJGXF2BYWrmW8B6TTb2SznlfW4p1QJF78-52mW5RW1Q72W3tzvN808-tLVXQckW5VGP_K2txgbsW3qd0cX5009TNW4pSTBZ8vKG-gW6h85Xs2VqmQlN7qQ8sZ9L7xCW2bxGLf7tQ1mSW3vZ01V1ydWBqW6h-3mW3Z6-8gW2nPv9y6-VGflVg37m17NrJmHW7zzxLx74m-1FW6JZF0s7_RBz7f7_V4DF04?ref=dl-staging-website.ghost.io" rel="noopener">Wiki-Text</a>&nbsp;to the OPTs and recording the outputs of all attention heads and fully-connected-layer neurons. By activating various portions of these networks, they learned that, for a given input, they could discard most of an OPT’s lowest-output attention heads and fully-connected-layer neurons without degrading its performance.</p><ul><li>The authors used their dataset to train a sparsity predictor for each of an OPT’s fully connected layers. This small vanilla neural network classified which neurons in a fully connected layer to activate (because they produced large outputs), given the output of the previous fully connected layer.</li><li>Using the same dataset, they trained, for each attention layer, a small vanilla neural network to classify which attention heads to activate (because they produced large outputs), given the output of the previous attention layer.</li><li>At inference, an OPT and its predictor networks ran in parallel. While the OPT computed an attention layer, a predictor network predicted the neurons to activate in the following fully connected layer. Similarly, while the OPT computed each fully connected layer, a predictor network predicted the heads to activate in the following attention layer.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;Deja Vu (175 billion parameters) produced a sequence of 128 tokens in 20 milliseconds, while an Nvidia implementation of OPT of the same size needed 40 milliseconds and a Hugging Face implementation of OPT of the same size needed 105 milliseconds. Moreover, Deja Vu achieved these speedups without reducing accuracy. On&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3n4MS_20LqRzYMW2N2tvW6wD-6qW53fkQ13WcsckN4TPKQGvkSLwW5trlwt7C1k6hW1HvJfy7Kzc9lW9kSBDr25gbtRN2xzGHGHf9LSW28fFCh4jkcQSW5jJ1T81qjS0ZW39J8lw1m2FkfW5_4Xxg2KKkXjW50x3dt8XK_p_W1mjl-V8kctbJW8XGmfG1-D0QVW8s2qlr4Gs2WyW2c5ldV4t-1ByN1mKr9PmyGlDW2lV9Z_6Y_HMnW1CYy0-6C53ZsW1MjY894kFp62W1Sb4rz18fCFlf3T1FBq04?ref=dl-staging-website.ghost.io" rel="noopener">WikiText</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFv3qgyTW7lCdLW6lZ3mWW2RGtFv15PkrPW5kKSPx8r1tQbW32DK6Y6WyJ1BW5kHknw2dXhfDW1tNBgZ4YX730W88WwrD8L2wCqN91s699wWHrwW8N0MR46JyyQ1W2DVrwk6vXTGWW9fyl0H7D3q_3W6Hvs95447nHJW675RTN7677pvW4nHqkQ5R0clcVLNLHC19sQXkN1f3hmsM2vkxW24PV7x1gWY4zVQC0823KZtxlW41f2G26y0VMyN8Ck-slpnJPNVhq71_2jBhrfW16JVdd3WHw8ZVvD_pX8FQPdnW6rN34C2JV-Y0W8CL3xM4PkdH9f2jffrv04?ref=dl-staging-website.ghost.io" rel="noopener">C4</a>, Deja Vu’s ability to predict the next word held steady while activating 25 percent of attention heads and fully-connected-layer neurons. On datasets such as&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3p3W9g72g641Kg1jW5PbLvF15zT9WW7NmR0t49L4PrW7DxP3G4nYPLxW2VV9KW8wMbTfW77D_sK8-ZhgyW52dSmC44TCbcW6bC6Cr19FhBgW1qWyP965C_2tW1t0_Nc9lPxyBW7G2Z2Z3pvQzcW95v4Vx7z_P8-W381LGB7Vm2BJW8XBRjR50HjvNW7jYG522nQmhHW5lNRxC2r7h61W3c3QWF4360qLW29jRYv48g3VqW1_HlyV1qSZQ_W7P_fGb4V_012W35J7j366CHRxW40-86d7Dx0b_f44FQ1g04?ref=dl-staging-website.ghost.io" rel="noopener">WinoGrande</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3mjW8mb41M5Q2xtvW6vn9Rc8Gd8MvVFtcsP1yy5NvW3hhrMn3sW51mW39m6Ty7l1hqLW5CMnts8stl8zMnMBJbWZ9-YW98nR7s7lqrRDN1T39gpGp6ymW8-T5t94qK5v1VnHHRJ4V05vZW2dgmk17HZ0G3W7Z6sZ-863_PdW6Y1RFF9bzZQ3W7sGt7l3SF-LJW44d7bX1RGdXvW9hjRl_1HdHS_W8YZskJ6bq5ftW8wnSWB1dzt2rW2F6hkK7H--cqW1qhQVP8c10G1W2VbR4N59dPJNf83b0fF04?ref=dl-staging-website.ghost.io" rel="noopener">OpenBookQA</a>, it maintained its accuracy while activating 35 percent of attention heads and fully-connected-layer neurons.</p><p><strong>Why it matters:</strong>&nbsp;Efficient use of processing power becomes increasingly important as models become larger. Moreover, faster token generation benefits agentic workflows, which can consume large numbers of tokens.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Deja Vu’s design is in the spirit of the mixture of experts (MoE) architecture: For each transformer layer, MoE uses a neural-network layer to choose which fully connected layer to use. In contrast, for each attention head and fully-connected-layer neuron, Deja Vu uses small neural networks to decide which to activate.</p><hr /><h2 id="new-from-deeplearningai-1">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1043" src="https://dl-staging-website.ghost.io/content/images/2024/05/V4_Waitlist_DeepLearning_Qualcomm_C1_Banner_2070x1080.png" width="2000" /></a></figure><p>New course with Qualcomm coming soon! In “Introduction to On-Device AI,” you’ll learn how to deploy AI models on edge devices using local computation for faster inference and privacy. Join the next wave of AI as models go beyond the cloud.&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for the waitlist</a>!</p>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 22:07:00 GMT</pubDate>
</item>
<item>
<title>Apple’s Tiny LLMs, Amazon Rethinks Cashier-Free Stores, Predicting Scientific Discoveries</title>
<link>https://www.deeplearning.ai/the-batch/issue-247</link>
<guid>https://www.deeplearning.ai/the-batch/issue-247</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Inexpensive token generation and agentic workflows for large language models (LLMs) open up intriguing new possibilities for training LLMs on synthetic data. Pretraining an LLM on its own directly generated responses to prompts doesn't help. But if an agentic workflow implemented with the LLM results in higher quality output than the LLM can generate directly, then training on that output becomes potentially useful.</p><p>Just as humans can learn from their own thinking, perhaps LLMs can, too. For example, imagine a math student who is learning to write mathematical proofs. By solving a few problems — even without external input — they can reflect on what does and doesn’t work and, through practice, learn how to more quickly generate good proofs.&nbsp;</p><p>Broadly, LLM training involves (i) pretraining (learning from unlabeled text data to predict the next word) followed by (ii) instruction fine-tuning (learning to follow instructions) and (iii) RLHF/DPO tuning to align the LLM’s output to human values. Step (i) requires many orders of magnitude more data than the other steps. For example,&nbsp;<a href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Llama 3</a>&nbsp;was pretrained on over 15 trillion tokens, and LLM developers are still hungry for more data. Where can we get more text to train on?&nbsp;</p><p>Many developers train smaller models directly on the output of larger models, so a smaller model learns to mimic a larger model’s behavior on a particular task. However, an LLM can’t learn much by training on data it generated directly, just like a supervised learning algorithm can’t learn from trying to predict labels it generated by itself. Indeed, training a model repeatedly on the output of an earlier version of itself can result in&nbsp;<a href="https://www.deeplearning.ai/the-batch/study-reveals-serious-defects-in-models-trained-on-their-own-content/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">model collapse</a>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--57-.jpg" width="1200" /></figure><p>However, an LLM wrapped in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">agentic workflow</a>&nbsp;may produce higher-quality output than it can generate directly. In this case, the LLM’s higher-quality output might be useful as pretraining data for the LLM itself.&nbsp;</p><p>Efforts like these have precedents:</p><ul><li>When using&nbsp; reinforcement learning to play a game like chess, a model might learn a function that evaluates board positions. If we apply game tree search along with a low-accuracy evaluation function, the model can come up with more accurate evaluations. Then we can train that evaluation function to mimic these more accurate values.</li><li>In the alignment step, Anthropic’s&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">constitutional AI</a>&nbsp;method uses RLAIF (RL from AI Feedback) to judge the quality of LLM outputs, substituting feedback generated by an AI model for human feedback.&nbsp;</li></ul><p>A significant barrier to using LLMs prompted via agentic workflows to produce their own training data is the cost of generating tokens. Say we want to generate 1 trillion tokens to extend a pre-existing training dataset. Currently, at publicly announced prices, generating 1 trillion tokens using GPT-4-turbo ($30 per million output tokens), Claude 3 Opus ($75), Gemini 1.5 Pro ($21), and Llama-3-70B on Groq ($0.79) would cost, respectively, $30M, $75M, $21M and $790K. Of course, an agentic workflow that uses a design pattern like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Reflection</a>&nbsp;would require generating more than one token per token that we would use as training data. But budgets for training cutting-edge LLMs easily surpass $100M, so spending a few million dollars more for data to boost performance is quite feasible.</p><p>That’s why I believe agentic workflows will open up intriguing new opportunities for high-quality synthetic data generation.&nbsp;</p><p>Keep learning!</p><p>Andrew</p><p>P.S. In “Prompt Engineering for Vision Models,” taught by Abby Morgan, Jacques Verré, and Caleb Kaiser of Comet, you’ll learn how to prompt and fine-tune a variety of vision models for image generation, image editing, object detection, and&nbsp; segmentation. For example, you’ll use OWL-ViT to detect an object you describe in a text prompt, pass the bounding box to SAM to create a segmentation mask, and feed the mask into Stable Diffusion with a text prompt to replace the original object with a new one. Controlling vision models can be tricky, and this course will teach you the techniques to control their output. Get started&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152036.759.gif" width="1200" /></figure><h1 id="think-different-small">Think<strong>&nbsp;<s>Different</s>&nbsp;</strong>Small</h1><p>Apple is thinking small — very small — with a new family of open large language models.</p><p><strong>What's new:&nbsp;</strong>Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, and colleagues at Apple released&nbsp;<a href="https://arxiv.org/abs/2404.14619?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open Source Efficient LLM</a>&nbsp;(OpenELM), a family of smaller large language models. OpenELM ranges from 270 million parameters — plenty small enough to fit on a phone — to 3 billion parameters.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenELM comes in pretrained and instruction-tuned versions with parameter counts of 270 million, 450 million, 1.1 billion, and 3 billion. They can process 2,048 tokens of context. The&nbsp;<a href="https://github.com/apple/corenet?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">release</a>&nbsp;includes weights, code for training and inference, and code for running the models on Apple chips.&nbsp;</p><ul><li>The authors pretrained OpenELM on 1.8 trillion tokens drawn from subsets of&nbsp;<a href="https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">publicly</a>&nbsp;<a href="https://www.together.ai/blog/redpajama?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">available</a>&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">text</a>&nbsp;<a href="https://arxiv.org/abs/2402.00159?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">datasets</a>.</li><li>They fine-tuned the instruction-tuned models on the&nbsp;<a href="https://arxiv.org/abs/2310.01377?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">UltraFeedback</a>&nbsp;dataset of 60 thousand prompts.</li><li>OpenELM follows most of the architecture choices of current state-of-the-art transformer models with a major exception: The number of attention heads and size of fully connected layers increase the deeper in the network they are, following the idea that layers later in the network learn more complex representations of the input than early ones. This architecture contrasts to the current common practice, in which a transformer’s number of attention heads and size of fully connected layers remains consistent throughout the network.</li></ul><p><strong>Results:&nbsp;</strong>OpenELM beat a number of other open-source models trained solely on publicly available data.</p><ul><li>For example, on average across five tasks on the&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open LLM Leaderboard</a>, a 1.08 billion parameter OpenELM beat a 1.18 billion parameter&nbsp;<a href="https://arxiv.org/abs/2402.00838?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">OLMo</a>&nbsp;45.93 percent to 43.57 percent, although OLMo trained on twice as much data. The 270 million-parameter OpenELM achieved 38.72 percent.</li><li>Comparing speed between OpenELM models that ran on consumer-grade computers, the 270 million-parameter model was over twice as fast as the 3 billion-parameter version. Apple did not present results obtained on phones.</li><li>OpenELM fell short on&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a><strong>&nbsp;</strong>(multiple choice questions from mathematics to microeconomics), achieving within 2.05 percent of random chance (25 percent) for all model sizes. To be fair, the other models chosen for comparison didn’t do much better. It’s possible that publicly available data isn’t sufficient for learning to solve MMLU. By comparison, Microsoft’s Phi-3-mini (3.8 billion parameters trained on web data filtered according to “educational level” plus generated data) achieved 68.8 percent accuracy.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;After years of becoming only larger, neural networks lately have also been getting smaller. The smallest OpenELMs are tiny compared to, say, Microsoft’s Phi-3-mini. Apple has an extra incentive to make models capable of running on edge devices like phones. The company makes a major selling point of user privacy, and models run entirely on a smartphone (as opposed to in the cloud) keep the user’s activity under wraps.</p><p><strong>We're thinking:</strong>&nbsp;<a href="https://arxiv.org/pdf/2008.00623?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">DeLighT</a>&nbsp;introduced this layer-scaling approach in 2020. Sometimes it takes a while for good ideas to catch on!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/AIINDEX_1200px_14secHolds--1-.gif" width="1200" /></figure><h1 id="ai-trends-in-depth">AI Trends in Depth</h1><p>More expensive models, superhuman performance, growing impacts on society — an extensive report takes stock of developments in machine learning over the past year.&nbsp;</p><p><strong>What's new:</strong>&nbsp;Stanford’s Institute for Human-Centric AI&nbsp;<a href="https://aiindex.stanford.edu/report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">published</a>&nbsp;the seventh “AI Index Report,” its annual overview of the state of AI. The report documents rising costs and capabilities, a shift from academic to corporate dominance, and the public’s anxiety as the technology becomes ever more embedded in daily life.</p><p><strong>Themes and findings:</strong>&nbsp;The 500-page report collates a wide variety of papers, benchmarks, market research, and surveys published in 2023. It delves deeply into AI technology, economics, governance, and impact. Among its key conclusions:&nbsp;</p><ul><li>Foundation models, defined as versatile models trained on very large datasets, ballooned in number and cost. The Index counted 149 foundation models released in 2023 (including Google’s Gemini Ultra, which cost $191.4 million to train). That’s up from 32 foundation models in 2022, 9 in 2021, and 2 in 2020 (when OpenAI’s GPT-3 175B cost an estimated $4.3 million to train).</li><li>Open foundation models, too, are on the rise: 66 percent of last year’s foundation models were open, up from 33 percent in 2021.</li><li>State-of-the-art models approached or surpassed human performance on several popular benchmarks. These include&nbsp;<a href="https://arxiv.org/pdf/2009.03300v3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a>&nbsp;(multitask language understanding),&nbsp;<a href="https://arxiv.org/pdf/2308.06595?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">VisIT-Bench</a>&nbsp;(vision-language instructions), and&nbsp;<a href="https://arxiv.org/pdf/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MATH</a>&nbsp;(difficult math problems).&nbsp;</li><li>Industry was the primary driver of innovation, contributing 57 percent of “notable” machine learning models. Partnerships between industry and academia accounted for 23 percent and academia alone for 17 percent. Corporate dominance in model building was a significant shift from previous years; in 2016, academia and industry contributed AI models equally.</li><li>New models have achieved dramatic results in the sciences. For instance,&nbsp;<a href="https://www.nature.com/articles/s41586-023-06004-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaDev</a>&nbsp;found superior sorting algorithms.&nbsp;<a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GraphCast</a>&nbsp;generated mid-range weather forecasts more accurately than conventional methods.&nbsp;<a href="https://www.nature.com/articles/s41586-023-06735-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GNoME</a>&nbsp;discovered new materials, and&nbsp;<a href="https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaMissense</a>&nbsp;pinpointed genetic mutations that cause human diseases.</li></ul><p><strong>Behind the news:</strong>&nbsp;The differences between the new one and the initial, 2018 edition highlight the field’s rapid pace of change. For instance, the 2018 report opened by trumpeting the nearly 9x growth of AI research papers published between 2000 and 2017. The new one opened not with the annual rate of research publications (though it has roughly doubled since 2017) but with a graph of industry’s growing dominance in innovation.&nbsp;<em>The Batch</em>&nbsp;has&nbsp;<a href="https://www.deeplearning.ai/the-batch/tag/ai-index/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">covered</a>&nbsp;several editions.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The “AI Index Report” offers a detailed snapshot of AI as it advances at an unprecedented rate and shows potential to revolutionize virtually every field of human endeavor. It dives deeply into areas of special concern to researchers (such as Gemini’s nearly $200 million training cost), practitioners (for instance, the slightly narrowing gender gap among computer science PhDs), businesses (the sharply rising number of regulations), and users (half of those who are aware of ChatGPT use it weekly). This year’s report includes new emphases on public opinion and geopolitics.</p><p><strong>We're thinking:</strong>&nbsp;It’s heartening to see AI thriving. The field faces daunting challenges, yet the report highlights achievements in foundation models, science, medicine, and elsewhere that portend greater benefits directly ahead. What an exciting time for AI!</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-04-29T162119.517.png" width="1680" /></a></figure><p>Expand your prompting skills with our new short course, “Prompt Engineering for Vision Models.” Learn how to prompt and fine-tune vision models to accomplish tasks from image generation to object detection.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io" rel="noreferrer">Start learning today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152511.553.png" width="1200" /></figure><h1 id="amazon-rethinks-cashier-free-stores">Amazon Rethinks Cashier-Free Stores</h1><p>Amazon is removing grab-and-go shopping from its cart.</p><p><strong>What’s new:</strong>&nbsp;Amazon withdrew Just Walk Out, an AI-driven checkout service, from most of its Amazon Fresh grocery stores,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/amazons-grocery-stores-to-drop-just-walk-out-checkout-tech?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">reported</a>. Instead, the stores will provide smart shopping carts. (Disclosure: Andrew Ng is a member of Amazon’s Board of Directors.)<br /><br /><strong>Checking out:</strong>&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Just Walk Out</a>&nbsp;enables shoppers to scan a payment method upon entering a store, take items from shelves tracked by computer vision and weight-detection sensors, and simply exit with their purchases, bypassing the checkout counter. Amazon had installed the system in 47 Amazon Fresh stores in the U.S. and UK. In most of those locations. Amazon will replace Just Walk Out with&nbsp;<a href="https://www.aboutamazon.com/news/retail/amazon-dash-cart-new-features-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Dash Cart</a>, a shopping cart that enables customers to scan purchases as they shop. Amazon will retain Just Walk Out in its Amazon Go convenience stores and an unspecified number of smaller, UK-based Amazon Fresh stores. It has licensed the system to other retailers including Hudson Markets and plans to install in more third-party stores this year.</p><ul><li>Just Walk Out isn’t well suited to grocery shopping, in which customers may buy large numbers of items, since customers may not be aware of their total spending until they receive a receipt via email after leaving the store, Amazon executive Tony Hoggett said. Dash Cart enables users to see the bill in real time.</li><li>Just Walk Out&nbsp;<a href="https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">relied on</a>&nbsp;more than 1,000 remote employees to label video for training and review cases where it failed, and Amazon wasn’t able to improve the system as quickly as it expected, according to an earlier report by&nbsp;<em>The Information</em>. As of mid-2022, the system required about 700 human reviews per 1,000 sales, compared to a target between 20 and 50 per 1,000 sales. Amazon said the percentage of sales that require human review has declined since then.</li><li>Training the models required 2,000 technologists and cost hundreds of millions of dollars in cloud computing resources to train and run.</li><li>Just Walk Out’s cameras and sensors can be difficult to install in existing stores and sometimes requires extensive remodeling. The system also&nbsp;<a href="https://www.theverge.com/2019/9/10/20857921/amazon-go-rollout-delay-cashierless-convenience-stores-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">requires</a>&nbsp;high ceilings, which existing stores may not have.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon&nbsp;<a href="https://www.deeplearning.ai/the-batch/retailers-spend-on-smarter-stores/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">introduced</a>&nbsp;Just Walk Out in 2016 at its first Amazon Go convenience store in Seattle. It&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">extended</a>&nbsp;the system to Amazon Fresh in 2020. Between September 2020 and September 2022, Amazon opened 44 Fresh stores in the U.S. and 19 in the UK, most of which included Just Walk Out. But Amazon’s brick-and-mortar locations&nbsp;<a href="https://www.cnbc.com/2022/02/19/amazons-sprawling-grocery-business-has-become-an-expensive-hobby.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">suffered</a>&nbsp;during the COVID-19 pandemic. From September 2022 to mid-2024, amid broader cost-cutting efforts, the company&nbsp;<a href="https://www.theinformation.com/articles/zombie-amazon-grocery-stores-pile-up-as-openings-grind-to-a-halt?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">paused</a>&nbsp;opening new grocery stores.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Grab-and-go shopping seems like a solid bet, given the increasing focus of retailing on immediate gratification. Yet Amazon’s retreat from Just Walk Out in larger stores suggests that the technology is less well suited to such environments. In addition, shoppers may not have adjusted easily to grab-and-go behavior, which removes social interactions with cashiers and encourages customers to spend without reviewing the bill.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;AI has the potential to revolutionize every field, including retailing, and it’s important to find productive uses for it. Not all experiments will succeed, but patient investment and experimentation can illuminate productive paths forward.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/SCIENCE-FIX.gif" width="600" /></figure><h1 id="predicting-scientific-discoveries">Predicting Scientific Discoveries</h1><p>A new AI method directs scientists toward promising avenues of inquiry.</p><p><strong>What's new:</strong>&nbsp;Jamshid Sourati and James A. Evans at University of Chicago proposed a&nbsp;<a href="https://www.nature.com/articles/s41562-023-01648-z?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">method to predict new scientific discoveries</a>&nbsp;by building a graph that connects researchers, their objects of study, and the scientific properties thereof. They evaluated their approach using data from materials science.</p><p><strong>Key insight:</strong>&nbsp;Overlapping interests among researchers may indicate areas where further research would be fruitful. For example, if one group of researchers studies a material A and its property P, a second group studies materials A and B, and another group studies materials B and C, it may turn out that material C exhibits property P.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors tried to predict whether certain inorganic materials have certain electrical properties based on&nbsp;<a href="https://europepmc.org/article/med/31270483?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">scientific literature</a>&nbsp;through the year 2000. From 1.5 million articles that described 100,000 inorganic compounds, they extracted the author names, materials mentioned (for example, sodium nitrite), and their properties (for example, thermoelectricity, the ability to convert heat into electricity and vice versa). They used this data to construct a graph whose nodes were authors, materials, and properties. Edges connected the nodes that appeared in the same paper, for example a particular author whose paper covered specific material or property.</p><ul><li>The authors conducted random walks through the graph, stepping from node to node, to produce sequences of authors, materials, and properties. Then they removed the authors from the sequences, because they were interested mainly in establishing possible connections between materials and properties.&nbsp;</li><li>They trained&nbsp;<a href="https://arxiv.org/abs/1301.3781?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Word2Vec</a>, which computes word embeddings, on their sequences, treating materials and properties as words and sequences as documents. This yielded an embedding for each material and property.</li><li>To predict possible discoveries — that is, which material might exhibit a given property — the authors scored each material based on (i) the similarity between the material’s embedding and the given property’s embedding and (ii) the smallest number of edges in the path that connected each material and the property. Then they summed scores (i) and (ii). The 50 highest-scoring materials were predicted to have the property (that weren’t directly connected in the graph; that is, excluding materials that already were known to have the property).&nbsp;&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;The authors predicted which materials possessed each of three properties. They compared their results with predictions obtained in a similar way using a Word2Vec model trained exclusively on text from scientific papers. They used papers from 2001 through 2018 to evaluate the predictions. For thermoelectricity, the cumulative precision (percentage of predicted discoveries proven correct) was 76 percent, while the cumulative precision of the alternative method was 48 percent. The cumulative precision of random guesses was about 3 percent. The authors obtained similar results for the other two properties.</p><p><strong>Why it matters:</strong>&nbsp;Science is a social endeavor, where the connections between people and their work can be represented as a graph that reflects the collective attention of the scientific community. The collective attention acts as a signal that predicts promising avenues for further research — a signal that machine learning can help to tease out.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;The authors also predicted drug discoveries with similarly good results. Their method may be useful for identifying fruitful directions in other scientific areas, and perhaps in other domains entirely.</p><hr /><h1 id="data-points">Data Points</h1><p>This week's <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> features these highlights: Adobe's latest Firefly Image 3 model, enhanced smart glasses with Meta’s AI assistant, an AI-powered gene editor, and more.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-247/?ref=dl-staging-website.ghost.io" rel="noreferrer">Catch up on the latest in AI now.</a></p>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 20:39:36 GMT</pubDate>
</item>
<item>
<title>Pop Song Generators, 3D Mesh Generators, Real-World Benchmarks, AI for Manufacturing</title>
<link>https://www.deeplearning.ai/the-batch/issue-246</link>
<guid>https://www.deeplearning.ai/the-batch/issue-246</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Much has been said about many companies’ desire for more compute (as well as data) to train larger foundation models. I think it’s under-appreciated that we have nowhere near enough compute available for inference on foundation models as well.</p><p>Years ago, when I was leading teams at Google, Baidu, and Stanford that focused on scaling up deep learning algorithms, many semiconductor manufacturers, data center operators, and academic researchers asked me whether I felt that AI technology would continue to make good use of more compute if they kept on delivering it. For many normal desktop processing workloads, like running a web browser or a text editor, having a faster CPU doesn’t help that much beyond a certain point. So do we really need faster and faster AI processors to train larger and larger models? Each time, I confidently replied “yes!” and encouraged them to keep scaling up compute. (Sometimes, I added half-jokingly that I had never met a machine learning engineer who felt like they had enough compute. 😀)</p><p>Fortunately, this prediction has been right so far.&nbsp;However, beyond training, I believe we are also far from exhausting the benefits of faster and higher volumes of inference.</p><p>Today, a lot of LLM output is primarily for human consumption. A human might read around 250 words per minute, which is around 6 tokens per second (250 words/min / (0.75 words/token) / (60 secs/min)). So it might initially seem like there’s little value to generating tokens much faster than this. &nbsp;</p><p>But in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">agentic workflow</a>, an LLM might be prompted repeatedly to reflect on and improve its output, use tools, plan and execute sequences of steps, or implement multiple agents that collaborate with each other. In such settings, we might easily generate hundreds of thousands of tokens or more before showing any output to a user. This makes fast token generation very desirable and makes slower generation a bottleneck to taking better advantage of existing foundation models.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/TOKEN-GENERATION.png" width="1200" /></figure><p>That’s why I’m excited about the work of companies like&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Groq</a>, which can generate hundreds of tokens per second. Recently,&nbsp;<a href="https://fast.snova.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">SambaNova</a>&nbsp;published an impressive demo that hit hundreds of tokens per second.</p><p>Incidentally, faster, cheaper token generation will also help make running evaluations (evals), a step that can be slow and expensive today since it typically involves iterating over many examples, more palatable. Having better evals will help many developers with the process of tuning models to improve their performance.</p><p>Fortunately, it appears that both training and inference are rapidly becoming cheaper. I recently spoke with Cathie Wood and Charles Roberts of the investment firm ARK, which is famous for its bullish predictions on tech. They&nbsp;<a href="https://www.ark-invest.com/big-ideas-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">estimate</a>&nbsp;that AI training costs are falling at 75% a year. If they are right, a foundation model that costs $100M to train this year might cost only $25M to train next year. Further, they report that for “enterprise scale use cases, inference costs seem to be falling at an annual rate of ~86%, even faster than training costs.”</p><p>I don’t know how accurate these specific predictions will turn out to be, but with improvements in both semiconductors and algorithms, I do see training and inference costs falling rapidly. This will be good for application builders and help AI agentic workflows lift off.</p><p>Keep learning!</p><p>Andrew</p><p>P.S. New short course with Mistral AI! Mistral’s open-source Mixtral 8x7B model uses a mixture of experts (MoE) architecture. Unlike a standard transformer, MoE uses multiple expert feed-forward networks with a gating network that selects a number of experts at inference time. This enables MoE to match the performance of larger models but with faster inference. Mixtral 8x7B has 46.7B parameters but activates only 12.9B at inference time to predict the next token. In “Getting Started with Mistral,” taught by Sophia Yang, you’ll explore Mistral’s open-source (Mistral 7B, Mixtral 8x7B) and commercial models, learn about function calling for tool use with Mistral, and build a Mistral-powered chat interface that can reference external documents. Please sign up&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134335.199.gif" width="1200" /></figure><h1 id="songs-made-to-order">Songs Made to Order</h1><p>A new breed of audio generator produces synthetic performances of songs in a variety of popular styles.</p><p><strong>What’s new:</strong>&nbsp;Udio&nbsp;<a href="https://www.udio.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a web-based, text-to-song generator that creates songs in styles from barbershop to heavy metal.&nbsp;<a href="https://suno.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Suno</a>, which debuted its service late last year with similar capabilities, upgraded to its offering.</p><p><strong>How it works:</strong>&nbsp;Both services take text prompts and generate full-band productions complete with lyrics, vocals, and instrumental solos, two separate generations per prompt. Users can generate lyrics to order or upload their own words, and they can download, share, and/or post the results for others to hear. Leaderboards rank outputs according to plays and likes.&nbsp;</p><ul><li>Founded by alumni of Google’s DeepMind division, Udio lets registered users generate up to 1,200 songs monthly for free and expects to offer paid services at an unspecified future date. Users enter a text prompt and/or choose style tags. The system automatically replaces artist names with stylistic descriptions but sometimes produces results that sound uncannily&nbsp;<a href="https://youtu.be/7U57R_icuOg?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">like</a>&nbsp;the artists requested. Users can choose to generate an instrumental track or add lyrics, allocating them to verse, chorus, or background vocals. Udio generates audio segments 33 seconds long, which users can extend, remix, and modify. The company has not released information about the underlying technology.&nbsp;</li><li>Suno lets users generate 10 songs daily for free or pay to generate more. Enter a prompt, and the system generates complete songs up to 2 minutes long; alternatively, users can specify lyrics, style, and title in separate prompts. The system refuses to generate music from prompts that include the name of a real-world artist. Suno hasn’t disclosed technical information, but last year it&nbsp;<a href="https://github.com/suno-ai/bark?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">released</a>&nbsp;an open-source model called Bark that turns a text prompt into synthetic music, speech, and/or sound effects.</li></ul><p><strong>Behind the news:</strong>&nbsp;Most earlier text-to-music generators were designed to produce relatively free-form instrumental compositions rather than songs with structured verses, choruses, and vocals. Released earlier this month,&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Audio 2</a>&nbsp;generates instrumental tracks up to three minutes long that have distinct beginnings, middles, and endings. Users can also upload audio tracks and use Stable Audio 2.0 to modify them.</p><p><strong>Yes, but:&nbsp;</strong>Like text-to-image generators circa last year, current text-to-music models offer little ability to steer their output. They don’t respond consistently to basic musical terminology such as “tempo” and “harmony,” and requesting a generic style like “pop” can summon a variety of subgenres from the last 50 years of popular music.</p><p><strong>Why it matters:</strong>&nbsp;With the advent of text-to-music models that produce credible songs, audio generation seems primed for a Midjourney moment, when the public realizes that it can produce customized music at the drop of a prompt. Already Udio’s and Suno’s websites are full of whimsical paeans to users’ pets and hobbies. The technology has clear implications for professional performers and producers, who, regrettably, have little choice but to&nbsp;<a href="https://www.deeplearning.ai/the-batch/grimes-released-a-voice-cloning-tool/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">adapt</a>&nbsp;to increasing automation. But for now fans have fun, new toys to play with.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;You can dance to these algo-rhythms!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/VALS-4Leaderboards_1200px--1-.gif" width="1200" /></figure><h1 id="benchmarks-for-industry">Benchmarks for Industry</h1><p>How well do large language models respond to professional-level queries in various industry domains? A new company aims to find out.</p><p><strong>What’s new:</strong>&nbsp;<a href="https://www.vals.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Vals.AI</a>, an independent model testing service, developed benchmarks that rank large language models’ performance of tasks associated with income taxes, corporate finance, and contract law; it also maintains a pre-existing legal benchmark. Open AI’s GPT-4 and Anthropic’s Claude 3 Opus did especially well in recent tests.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Vals AI hosts leaderboards that compare the performance of several popular large language models (LLMs) with respect to accuracy, cost, and speed, along with with analysis of the results. The company worked with independent experts to develop multiple-choice and open-ended questions in industrial domains. The datasets are not publicly available.&nbsp;</p><ul><li><a href="https://www.vals.ai/contractlaw?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">ContractLaw</a>&nbsp;includes questions related to contracts. They ask models to retrieve parts of contracts that are relevant to particular terms, edit excerpts, and determine whether excerpts meet legal standards.</li><li><a href="https://www.vals.ai/corpfin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">CorpFin</a>&nbsp;tests accuracy in answering corporate finance questions. It feeds to models a public commercial credit agreement — terms of a business loan or a line of credit — and poses questions that require extracting information and reasoning over it.</li><li><a href="https://www.vals.ai/taxeval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">TaxEval</a>&nbsp;tests accuracy on tax-related prompts. Half of the questions test skills like calculating taxable income, marginal rate, and the like. The other half cover knowledge such as how different accounting methods impact taxes or how taxes apply to various types of assets.</li><li>Vals AI also tracks&nbsp;<a href="https://www.vals.ai/legalbench?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">performance</a>&nbsp;on&nbsp;<a href="https://arxiv.org/abs/2308.11462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">LegalBench</a>, an open benchmark that evaluates legal reasoning.</li></ul><p><strong>Results:</strong>&nbsp;Among 15 models, GPT-4 and Claude 3 Opus dominated Vals.AI’s leaderboards as of April 11, 2024. GPT-4 topped CorpFin and TaxEval, correctly answering 64.8 and 54.5 percent of questions, respectively. Claud 3 Opus narrowly beat GPT-4 on ContractLaw and LegalBench, achieving 74.0 and 77.7 percent, respectively. The smaller Claude 3 Sonnet took third place in ContractLaw, CorpFin, and TaxEval with 67.6, 61.4, and 37.1 percent. Google’s Gemini Pro 1.0 took third place in LegalBench with 73.6 percent.</p><p><strong>Behind the news:</strong>&nbsp;Many practitioners in&nbsp;<a href="https://www.deeplearning.ai/the-batch/new-report-on-the-ai-capabilities-of-major-banks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">finance</a>&nbsp;and&nbsp;<a href="https://www.clio.com/blog/lawyer-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">law</a>&nbsp;use LLMs in applications that range from processing documents to&nbsp;<a href="https://www.deeplearning.ai/the-batch/jpmorgan-trained-ai-to-interpret-the-federal-reserves-intent/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">predicting interest rates</a>. However, LLM output in such applications requires oversight. In 2023, a New York state judge&nbsp;<a href="https://www.deeplearning.ai/the-batch/attorney-faces-disciplinary-action-for-using-chatgpts-fictional-brief/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">reprimanded</a>&nbsp;a lawyer for submitting an AI-generated brief that referred to fictitious cases.</p><p><strong>Why it matters:</strong>&nbsp;Typical AI benchmarks are designed to evaluate general knowledge and cognitive abilities. Many developers would like to measure more directly performance in real-world business contexts, where specialized knowledge may come into play.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Open benchmarks can benefit from public scrutiny, and they’re available to all developers. However, they can be abused when developers cherry-pick benchmarks on which their models perform especially well. Moreover, they may find their way into training sets, making for unfair comparisons. Independent testing on proprietary benchmarks is one way to address these issues.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-23T091059.531.png" width="1680" /></a></figure><p>Join “Getting Started with Mistral” and access Mistral AI’s open source and commercial models via API calls. Learn to select the right model for your use case and get hands-on with features like JSON mode, function calling, and effective prompting techniques.&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Enroll for free</a>!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/MANUFACTURING_14-SecHolds_1200px--1---1-.gif" width="1200" /></figure><h1 id="ai-progress-report-manufacturing">AI Progress Report: Manufacturing</h1><p>Manufacturers are embracing AI even as they struggle to find the talent and data required.</p><p><strong>What’s new:</strong>&nbsp;The market-research arm of&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/04/09/1090880/taking-ai-to-the-next-level-in-manufacturing/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">surveyed</a>&nbsp;manufacturers’ use of AI in engineering, design, procurement, and production. All respondents were at least experimenting with AI, and many expect to launch their first deployments in the next year or two. Microsoft sponsored the research.</p><p><strong>How it works:</strong>&nbsp;The authors interviewed executives at 300 manufacturers in aerospace, automotive, chemicals, electronics, and heavy equipment. All were either applying or considering AI in product design or factory operations.&nbsp;</p><ul><li>The most common uses of AI in production involved designing products, creating content such as technical documentation, and building chatbots. The most common uses in earlier stages were knowledge management and quality control.</li><li>35 percent of respondents had deployed AI in production. Another 37 percent were experimenting with AI, while 27 percent were conducting preliminary research.</li><li>45 percent of respondents in electronics and 39 percent in automotive had deployed AI in production. Larger companies were more likely to have deployed AI (77 percent of companies with revenues over $10 billion compared to 4 percent of those with revenues under $500 million). Larger companies were also more likely to forecast increases in AI spending in the next two years.</li><li>Asked to name the biggest challenges to scaling up uses of AI, respondents most often pointed to shortages of skills and talent. Asked to name challenges their company faced with respect to data, they pointed to maintaining data quality, integrating data from different parts of an organization, and governing data.</li></ul><p><strong>Behind the news:</strong>&nbsp;Manufacturers are using AI to help&nbsp;<a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/generative-ai-fuels-creative-physical-product-design-but-is-no-magic-wand?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">design products</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/super-human-quality-control/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">visually inspect goods</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/if-it-aint-broke-fix-it/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">maintain equipment</a>. The field has attracted major players: Last year, Microsoft and Siemens&nbsp;<a href="https://www.deeplearning.ai/the-batch/siemens-and-microsoft-launch-gpt-powered-copilot-for-manufacturing-machinery/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a pilot of Industrial Copilot, which enables users to interact in natural language with software that drives assembly lines.</p><p><strong>Why it matters:</strong>&nbsp;Manufacturers want to use AI, but many face obstacles of talent and data. That spells opportunities for budding practitioners as well as for manufacturers that lack infrastructure for collecting and managing data.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;One key to successful implementation of AI in manufacturing is tailoring systems to the unique circumstances of each individual facility. The highly heterogeneous tasks, equipment, and surroundings in different factories mean that one model doesn’t fit all. Developers who can solve this long-tail problem stand to reap rewards.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134817.631.gif" width="600" /></figure><h1 id="a-3d-model-from-one-2d-image">A 3D Model From One 2D Image</h1><p>Video diffusion provides a new basis for generating 3D models.<br /><strong>What's new:&nbsp;</strong>Vikram Voleti, Chun-Han Yao, Mark Boss, Varun Jampani, and colleagues at Stability AI produced a&nbsp;<a href="https://arxiv.org/abs/2403.12008?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">method</a>&nbsp;that generates a 3D model from a single image based on Stability’s video diffusion model. You can see its output&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>.<br /><br /><strong>Key insight:</strong>&nbsp;The approach known as a&nbsp;<a href="https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Neural Radiance Field</a>&nbsp;(NeRF) learns to create a 3D model from images of the same object shot at various angles. Given a single image of an object, a video diffusion model can learn to generate videos that orbit around it. The frames from such orbital videos give NeRF the information it needs to produce a 3D model.&nbsp;<br /><br /><strong>How it works:</strong>&nbsp;To generate an image, the authors took one step before and two steps during inference. Before inference: Learn to generate an orbital video. During inference: (i) Train a NeRF model on an orbital video. (ii) Improve the 3D model using diffusion following&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-dreamfusion-generates-3d-images-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">DreamFusion</a>.&nbsp;</p><ul><li>The authors fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2311.15127?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Video Diffusion</a>, given an image of an object, to generate an orbital video. They fine-tuned the model on orbital views of synthetic objects in the&nbsp;<a href="https://arxiv.org/abs/2212.08051?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Objaverse</a>&nbsp;dataset, first without and then with information about the camera’s orbit. They called the fine-tuned model Stable Video 3D (SV3D).</li><li>At inference, SV3D generated an orbital video from an image, where the orbit periodically went up and down to ensure the top and bottom of the object were visible. From these images, the authors trained an&nbsp;<a href="https://arxiv.org/abs/2201.05989?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Instant-NGP</a>&nbsp;NeRF model, which learned to represent the object as a 3D model and generate pictures from new camera angles based on different views of the same object.&nbsp;</li><li>To improve the 3D model, the authors first represented it using DMTet&nbsp;instead of Instant-NGP. DMTet is a system of networks built to refine 3D shapes from rough point clouds or low-resolution 3D models. The authors rendered images of DMTet’s 3D model along random camera orbits. For each image, the authors added noise to the image’s representation and removed it using SV3D. DMTet learned to update its 3D model to minimize the difference between the rendered image and the updated version from SV3D.</li></ul><p><strong>Results:</strong>&nbsp;The authors produced 3D models from images of 50 objects in&nbsp;<a href="https://arxiv.org/abs/2204.11918?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">GSO</a>, a 3D object dataset of scanned household items. They compared their 3D models to those produced by other methods including&nbsp;<a href="https://arxiv.org/abs/2402.03908?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">EscherNet</a>, a method that uses an image diffusion model to generate images of an object from different angles that are used to train a&nbsp;<a href="https://arxiv.org/abs/2106.10689?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">pair of vanilla neural networks</a>&nbsp;to produce a 3D model. Evaluated according to Chamfer distance, a measure of the distance between the points on the ground truth and generated 3D models (lower is better), their method achieved .024, while EscherNet achieved .042.</p><p><strong>Why it matters:</strong>&nbsp;Video diffusion models must generate different views of the same object, so they require a greater understanding of 3D objects than image diffusion models, which need to generate only one view at a time. Upgrading from an image diffusion model to a video diffusion model makes for better 3D object generation.<br /><br /><strong>We’re thinking:</strong>&nbsp;Building 3D models used to be difficult, but with models like this, it's becoming less of a mesh.</p>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 18:50:15 GMT</pubDate>
</item>
<item>
<title>AI Agents With Low/No Code, Hallucinations Create Security Holes, Tuning for RAG Performance, GPT Store’s Lax Moderation</title>
<link>https://www.deeplearning.ai/the-batch/issue-245</link>
<guid>https://www.deeplearning.ai/the-batch/issue-245</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Multi-agent collaboration is the last of the four&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">key AI agentic design patterns</a>&nbsp;that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.</p><p>Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..”&nbsp;</p><p>It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:</p><ul><li>It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.&nbsp;</li><li>Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.</li><li>Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.</li></ul><figure class="kg-card kg-image-card"><img alt="Proposed ChatDev architecture, illustrated." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T155856.845-1.png" width="1200" /></figure><p>In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.&nbsp;</p><p>While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to "hire" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!&nbsp;</p><p>Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their&nbsp;<a href="https://github.com/OpenBMB/ChatDev?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GitHub repo</a>&nbsp;and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.&nbsp;</p><p>Like the design pattern of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Planning</a>, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Tool Use</a>&nbsp;are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!&nbsp;</p><p>If you're interested in learning more, I recommend:&nbsp;</p><ul><li>“<a href="https://arxiv.org/abs/2307.07924?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Communicative Agents for Software Development</a>,” Qian et al. (2023) (the ChatDev paper)</li><li>“<a href="https://arxiv.org/abs/2308.08155?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a>,” Wu et al. (2023)&nbsp;</li><li>“<a href="https://arxiv.org/abs/2308.00352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework</a>,” Hong et al. (2023)</li></ul><p>Keep learning!</p><p>Andrew</p><p>P.S. Large language models (LLMs) can take gigabytes of memory to store, which limits your ability to run them on consumer hardware. Quantization can reduce model size by 4x or more while maintaining reasonable performance. In our new short course “Quantization Fundamentals,” taught by Hugging Face's Younes Belkada and Marc Sun, you’ll learn how to quantize LLMs and how to use int8 and bfloat16 (Brain Float 16) data types to load and run LLMs using PyTorch and the Hugging Face Transformers library. You’ll also dive into the technical details of linear quantization to map 32-bit floats to 8-bit integers. I hope you’ll&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">check it out</a>!&nbsp;</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T160143.589.gif" width="1200" /></figure><h1 id="custom-agents-little-coding">Custom Agents, Little Coding</h1><p>Google is empowering developers to build autonomous agents using little or no custom code.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://cloud.google.com/blog/products/ai-machine-learning/build-generative-ai-experiences-with-vertex-ai-agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">introduced</a>&nbsp;Vertex AI Agent Builder, a low/no-code toolkit that enables Google’s AI models to run external code and ground their responses in Google search results or custom data.<br /><br /><strong>How it works:</strong>&nbsp;Developers on Google’s Vertex AI platform can build agents and integrate them into multiple applications. The service&nbsp;<a href="https://cloud.google.com/products/agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">costs</a>&nbsp;$12 per 1,000 queries and can use Google Search for $2 per 1,000 queries.</p><ul><li>You can set an agent’s goal in natural language (such as “You are a helpful assistant. Return your responses in markdown format.”) and provide instructions (such as “Greet the user, then ask how you can help them today”).&nbsp;</li><li>Agents can ground their outputs in external resources including information retrieved from Google’s&nbsp;<a href="https://cloud.google.com/enterprise-search?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Enterprise Search</a>&nbsp;or&nbsp;<a href="https://cloud.google.com/bigquery?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">BigQuery</a>&nbsp;data warehouse. Agents can generate a confidence score for each grounded response. These scores can drive behaviors such as enabling an agent to decide whether its confidence is high enough to deliver a given response.</li><li>Agents can use tools, including a code interpreter that enables agents to run Python scripts. For instance, if a user asks about popular tourist locations, an agent can call a tool that retrieves a list of trending attractions near the user’s location. Developers can define their own tools by providing instructions to call a function, built-in&nbsp;<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">extension</a>, or external API.</li><li>The system integrates custom code via the open source library<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua"><u>&nbsp;</u>LangChain</a>&nbsp;including the&nbsp;<a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">LangGraph</a>&nbsp;extension for building multi-agent workflows. For example, if a user is chatting with a conversational agent and asks to book a flight, the agent can route the request to a subagent designed to book flights.</li></ul><p><strong>Behind the news:&nbsp;</strong>Vertex AI Agent Builder consolidates agentic features that some of Google’s competitors have rolled out in recent months. For instance, OpenAI’s&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?context=with-streaming&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Assistants API</a>&nbsp;lets developers build agents that respond to custom instructions, retrieve documents (limited by file size), call functions, and access a code interpreter. Anthropic recently&nbsp;<a href="https://docs.anthropic.com/claude/docs/tool-use?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">launched</a>&nbsp;Claude Tools, which lets developers instruct Claude language models to call customized tools. Microsoft’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-extends-copilot-365-windows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Windows Copilot</a>&nbsp;and&nbsp;<a href="https://support.microsoft.com/en-us/topic/microsoft-copilot-gpt-builder-overview-65499971-a502-4a96-a5c3-265cb59c012d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Copilot Builder</a>&nbsp;can call functions and retrieve information using Bing search and user documents stored via Microsoft Graph.</p><p><strong>Why it matters:&nbsp;</strong>Making agents practical for commercial use can require grounding, tool use, multi-agent collaboration, and other capabilities. Google’s new tools are a step in this direction, taking advantage of investments in its hardware infrastructure as well as services such as search. As tech analyst Ben Thompson&nbsp;<a href="https://stratechery.com/2024/gemini-1-5-and-googles-nature/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">writes</a>, Google’s combination of scale, interlocking businesses, and investment in AI infrastructure makes for a compelling synergy.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>Big-tech offerings like Vertex Agent Builder compete with an expanding universe of open source tools such as AutoGen, CrewAI, and LangGraph. The race is on to provide great agentic development frameworks!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T170803.947.png" width="1200" /></figure><h1 id="hallucination-creates-security-holes">Hallucination Creates Security Holes</h1><p>Language models can generate code that erroneously points to software packages, creating vulnerabilities that attackers can exploit.</p><p><strong>What’s new:</strong>&nbsp;A cybersecurity researcher noticed that large language models, when used to generate code, repeatedly produced a command to install a package that was not available on the specified path,&nbsp;<em>The Register</em>&nbsp;<a href="https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">reported</a>. He created a dummy package of the same name and uploaded it to that path, and developers duly installed it.<br /><br /><strong>How it works:</strong>&nbsp;Bar Lanyado, a researcher at Lasso Security, found that the erroneous command&nbsp;<em>pip install huggingface-cli</em>&nbsp;appeared repeatedly in generated code. The package&nbsp;<em>huggingface-cli</em>&nbsp;does exist, but it is installed using the command&nbsp;<em>pip install -U “huggingface_hub[cli]"</em>. The erroneous command attempts to download a package from a different repository. Lanyado published some of his findings in a&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">blog post</a>.&nbsp;</p><ul><li>Lanyado uploaded a harmless package with that name. Between December 2023 and March 2024, the dummy package was downloaded more than 15,000 times. It is not clear whether the downloads resulted from generated code, mistaken advice on bulletin boards, or user error.&nbsp;</li><li>Several repositories on Github used or recommended the dummy package, including&nbsp;<a href="https://github.com/alibaba/graphtranslator?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GraphTranslator</a>, which has been updated to remove the reference. Hugging Face itself called the package in one of its own projects; the company&nbsp;<a href="https://github.com/huggingface/diffusers/commit/56b68459f50f7d3af383a53b02e298a6532f3084?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">removed</a>&nbsp;the call after Lanyado notified it.</li><li>In research published last year, Lanyado&nbsp;<a href="https://vulcan.io/blog/ai-hallucinations-package-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">described</a>&nbsp;ChatGPT’s tendency to recommend a nonexistent Node.js package called arangodb. (<a href="https://arangodb.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ArangoDB</a>&nbsp;is a real database query system, but its official Node.js package is arangojs.) Lanyado demonstrated that it was possible to create a new package with the erroneous name and install it using ChatGPT’s instructions.</li></ul><p><strong>Testing:</strong>&nbsp;Lanyado&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">tested</a>&nbsp;Cohere AI’s Coral, Google’s Gemini Pro, and OpenAI’s GPT-4 and GPT-3.5. His aim was to determine how often they hallucinated packages and how often they referred repeatedly to the same hallucinated package. First he collected roughly 47,000 “how to” questions related to over 100 subjects in Go, .NET, Node.js, Python, and Ruby. Then he identified questions that produced hallucinated packages from a zero-shot prompt. He selected 20 of these questions at random and prompted each model 100 times to see whether it would refer to the same package every time.</p><ul><li>Of the models tested, Gemini Pro hallucinated packages most often, while Coral hallucinated packages most repeatedly. Here's (a) how often each model hallucinated packages and (b) how often it hallucinated the same package repeatedly. Coral: (a) 29.1 percent, (b) 24.2 percent. Gemini Pro: (a) 64.5 percent, (b) 14 percent. GPT-4: (a) 24.2 percent, (b) 19.6 percent. GPT-3.5 (a) 22.2 percent, (b) 13.6 percent.</li><li>The percentage of references to hallucinated packages also varied depending on the programming language. Using GPT-4, for example, 30.9 percent of Go queries referred to a hallucinated package compared to 28.7 percent of .NET queries, 19.3 percent of Node.js queries, 25 percent of Python queries, and 23.5 percent of Ruby queries.</li><li>Generally, Python and Node.js are more vulnerable to this type of attack than Go and .NET, which block access to certain paths and filenames. Of the Go and .NET prompts that returned a hallucinated package name, 2.9 percent and 21.2 percent were exploitable, respectively.</li></ul><p><strong>Why it matters:</strong>&nbsp;Lanyado’s method is not known to have been used in an attack, but it may be only a matter of time given its similarity to&nbsp;<a href="https://blog.gitguardian.com/protecting-your-software-supply-chain-understanding-typosquatting-and-dependency-confusion-attacks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">hacks</a>&nbsp;like typosquatting, dependency confusion, and masquerading.</p><p><strong>We’re thinking:</strong>&nbsp;Improved AI-driven coding tools should help to address this issue. Meanwhile, the difference between a command like pip install huggingface-cli and pip install -U "huggingface_hub[cli]" is subtle. In cases like this, package providers can look out for potential doppelgangers and warn users from being misled.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-16T091800.593.png" width="1680" /></figure><p>In the short course “Quantization Fundamentals with Hugging Face,” you’ll learn how to cut the computational and memory costs of AI models through quantization. Learn to quantize nearly any open source model!&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Join today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171422.978.gif" width="600" /></figure><h1 id="gpt-store-shows-lax-moderation">GPT Store Shows&nbsp;Lax Moderation</h1><p>OpenAI has been moderating its GPT Store with a very light touch.</p><p><strong>What’s new:</strong>&nbsp;In a survey of the GPT Store’s offerings,&nbsp;<em>TechCrunch</em>&nbsp;<a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">found</a>&nbsp;numerous examples of custom ChatGPT instances that appear to violate the store’s own&nbsp;<a href="https://openai.com/policies/usage-policies?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">policies</a>.</p><p><strong>How it works:</strong>&nbsp;The GPT Store has a low bar for entry by design — any paid ChatGPT user can create a custom-prompted variation of the chatbot, known as a GPT, and include it in the store. The store lists GPTs in several categories, such as Writing, Productivity, Programming, and Lifestyle. While many are useful, some are questionable.</p><ul><li>Some GPTs purported to jailbreak ChatGPT. In&nbsp;<em>TechCrunch</em>’s survey, some of them were able to circumvent OpenAI’s own guardrails. Since then, they have been tamed. The GPT Store’s terms of use prohibit efforts to thwart OpenAI’s safeguards and safety measures.</li><li>GPTs like Humanizer Pro, the second-ranked instance in the Writing category at the time of writing, purport to rewrite text and make it undetectable to programs designed to detect generated text. These GPTs may violate OpenAI’s ban on GPTs that enable academic dishonesty.</li><li>Many GPTs purport to allow users to chat with trademarked characters without clear authorization from the trademark owners. The store prohibits use of content owned by third parties without their permission.</li><li>Other GPTs purport to represent real-life figures such as Elon Musk, Donald Trump, and Joe Rogan, or companies such as Microsoft and Apple (many of them obviously satirical). OpenAI allows GPTs to respond in the style of a real person if they do not impersonate that person. However, many such GPTs don’t indicate that they are not associated with the genuine person.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI&nbsp;<a href="https://www.deeplearning.ai/the-batch/openai-releases-the-gpt-store-a-curated-chatbot-marketplace/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">launched</a>&nbsp;the GPT Store in January. Since then, users have uploaded more than 3 million GPTs that include enhanced search engines, creative writing aids, and tools that produce short videos. The most popular GPTs have millions of downloads. Despite its “store” name, the GPT Store’s contents are free to download. OpenAI is&nbsp;<a href="https://help.openai.com/en/articles/9119255-monetizing-your-gpt-faq?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">piloting</a>&nbsp;a program in which U.S.-based uploaders of popular GPTs can earn money.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The GPT Store is the chatbot era’s answer to Apple’s App Store or Android’s Google Play Store. If it succeeds, it could democratize chatbot development just as the App Store helped to popularize building smartphone applications. How OpenAI moderates the store may have real financial and reputational impacts on developers in the years ahead.<br /><br /><strong>We’re thinking:</strong>&nbsp;The GPT Store’s low barrier to entry is a boon to well-meaning developers, but it may encourage less responsible actors to take advantage of lax moderation. We applaud OpenAI’s willingness to execute an ambitious vision and hope it finds a workable balance.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171539.453.gif" width="600" /></figure><h1 id="tuning-llms-for-better-rag">Tuning LLMs for Better RAG</h1><p>Retrieval-augmented generation (RAG) enables large language models to generate better output by retrieving documents that are relevant to a user’s prompt. Fine-tuning further improves RAG performance.</p><p><strong>What’s new:</strong>&nbsp;Xi Victoria Lin, Xilun Chen, Mingda Chen, and colleagues at Meta proposed&nbsp;<a href="https://arxiv.org/abs/2310.01352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">RA-DIT</a>, a fine-tuning procedure that trains an LLM and retrieval model together to improve the LLM’s ability to capitalize on retrieved content.</p><p><strong>Retrieval augmented generation (RAG) basics:</strong>&nbsp;When a user prompts an LLM, RAG supplies documents that are relevant to the prompt. A separate retrieval model computes the probability that each chunk of text in a separate dataset is relevant to the prompt. Then it grabs the chunks with the highest probability and provides them to the LLM to append to the prompt. The LLM generates each token based on the chunks plus the prompt and tokens generated so far.</p><p><strong>Key insight:</strong>&nbsp;Typically LLMs are not exposed to retrieval-augmented inputs during pretraining, which limits how well they can use retrieved text to improve their output.&nbsp;<a href="https://proceedings.mlr.press/v119/guu20a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Such</a>&nbsp;<a href="https://proceedings.mlr.press/v162/borgeaud22a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">methods</a>&nbsp;have been proposed, but they’re costly because they require processing a lot of data. A more data-efficient, and therefore compute-efficient, approach is to (i) fine-tune the LLM to better use retrieved knowledge and then (ii) fine-tune the retrieval model to select more relevant text.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Llama 2</a>&nbsp;(65 billion parameters) and&nbsp;<a href="https://arxiv.org/abs/2302.07452?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">DRAGON+</a>, a retriever. They call the system RA-DIT 65B.</p><ul><li>The authors fine-tuned Llama 2 on prompts that consist of retrieved text and a question or instruction. They used 20 datasets including&nbsp;<a href="https://arxiv.org/abs/2304.0732?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">dialogue</a>,&nbsp;<a href="https://huggingface.co/datasets/yahoo_answers_qa?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">question-answering</a>,&nbsp;<a href="https://arxiv.org/abs/1806.03822?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">answering questions about a given text passage</a>,&nbsp;<a href="https://proceedings.neurips.cc/paper/2015/hash/afdec7005cc9f14302cd0474fd0f3c96-Abstract.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">summarization</a>, and datasets in which the model must answer questions and&nbsp;<a href="https://aclanthology.org/P17-1015/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">explain its reasoning</a>.&nbsp;</li><li>They fine-tuned DRAGON+’s encoder to increase the probability that it retrieved a given chunk if the chunk improved the LLM’s chance of generating the correct answer. Fine-tuning was supervised for the tasks listed above. Fine-tuning was self-supervised for completion of&nbsp;<a href="https://arxiv.org/abs/2208.03299?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">37 million text chunks</a>&nbsp;from Wikipedia and 362 million text chunks from&nbsp;<a href="https://commoncrawl.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">CommonCrawl</a>.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;On average, across four collections of questions from datasets such as&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MMLU</a>&nbsp;that cover topics like elementary mathematics, United States history, computer science, and law, RA-DIT 65B achieved 49.1 percent accuracy, while the combination of LLaMA 2 65B and DRAGON+ without fine-tuning achieved 45.1 percent accuracy, and LLaMA 2 65B without retrieval achieved 32.9 percent accuracy. When the input included five examples that showed the model how to perform the task, RA-DIT 65B achieved 51.8 percent accuracy, LLaMA 2 65B combined with DRAGON+ achieved 51.1 percent accuracy, and LLaMA 2 65B alone achieved 47.2 percent accuracy. On average, over eight common-sense reasoning tasks such as&nbsp;<a href="https://arxiv.org/abs/1803.05457?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ARC-C</a>, which involves common-sense physics such as the buoyancy of wood, RA-DIT 65B achieved 74.9 percent accuracy, LLaMA 2 65B with DRAGON+ achieved 74.5 percent accuracy, and LLaMA 2 achieved 72.1 percent accuracy.</p><p><strong>Why it matters:</strong>&nbsp;This method offers an inexpensive way to improve LLM performance with RAG.</p><p><strong>We’re thinking:</strong>&nbsp;Many developers have found that putting more effort into the retriever, to make sure it provides the most relevant text, improves RAG performance. Putting more effort into the LLM helps, too.</p><hr /><h1 id="data-points">Data Points</h1><p>In this week’s <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, find new model and feature releases from Google, Microsoft, Mistral, OpenAI, and Spotify, plus AI art projects and government investments.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-245/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read your short-form digest of this week’s AI news now</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:19:54 GMT</pubDate>
</item>
<item>
<title>Autonomous Coding Agents, Instability at Stability AI, Mamba Mania, What Users Do With GenAI</title>
<link>https://www.deeplearning.ai/the-batch/issue-244</link>
<guid>https://www.deeplearning.ai/the-batch/issue-244</guid>
<content:encoded><![CDATA[
<p>Dear friends,</p><p>Planning is a key&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">agentic AI design pattern</a>&nbsp;in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.&nbsp;</p><p>Many people had a “ChatGPT moment” shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar “AI Agentic moment,” I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.&nbsp;</p><p>I had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool — which I had forgotten I’d given it — and completed the task using Wikipedia instead of web search.&nbsp;</p><p>This was an AI Agentic moment of surprise for me. I think many people who haven’t experienced such a moment yet will do so in the coming months. It’s a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!</p><p>Many tasks can’t be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like&nbsp;<em>"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}"</em>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T140722.194.png" width="1200" /></figure><p>This structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)&nbsp;</p><p>Admittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you aren’t able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.&nbsp;</p><p>On one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="http://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Tool use</a>&nbsp;to work reliably and improve my applications’ performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I'm confident that Planning abilities will improve quickly.&nbsp;</p><p>If you’re interested in learning more about Planning with LLMs, I recommend:</p><ul><li>“<a href="https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>,” Wei et al. (2022)</li><li>“<a href="https://arxiv.org/abs/2303.17580?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a>,” Shen et al. (2023)</li><li>“<a href="https://arxiv.org/pdf/2402.02716.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Understanding the planning of LLM agents: A survey</a>,” by Huang et al. (2024)</li></ul><p>Keep learning!<br /><br />Andrew<br /><br />P.S. Making sure your RAG system has access to the data it needs to answer questions is an important, but often laborious, step for good performance. Our new short course “Preprocessing Unstructured Data for LLM Applications,” taught by Matt Robinson of Unstructured, teaches you how to build systems that can easily ingest data from a wide range of formats (like text, images, and tables) and from many different sources (like PDF, PowerPoint, and HTML). You’ll learn practical ways to extract and normalize content from diverse formats, enrich your content with metadata to enable more powerful retrieval and reasoning, and use document layout analysis and vision transformers to process embedded images and tables. Putting these components together, you’ll build a RAG bot that draws from multiple document types, demonstrating how high-quality data ingestion and preprocessing affect the quality of RAG output. <a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/DEVIN-PLUS-v6_1200px.gif" width="1200" /></figure><h1 id="coding-agents-proliferate">Coding Agents Proliferate</h1><p>New coding tools act like agents to automate software programming tasks.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;A wave of open source software-development tools based on large language models take advantage of the ability of large language models to plan, critique their own work, and extend themselves by calling functions.&nbsp;</p><p><strong>How it works:</strong>&nbsp;These projects follow hot on the heels of Cognition’s&nbsp;<a href="https://www.cognition-labs.com/introducing-devin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Devin</a>, a commercial system billed as a semi-autonomous software developer that’s available to selected customers upon request. Some, like Devin, provide sandboxed chat for natural-language commands, command line shell, code editor, and/or a web browser through which the agent can test code or find documentation. Given a prompt, they generate a step-by-step plan and execute it. They may ask for further information or instructions, and users can interrupt to modify their requests.&nbsp;</p><ul><li><a href="https://github.com/stitionai/devika?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">Devika</a>&nbsp;uses Anthropic’s Claude 3, OpenAI’s GPT-4 and GPT-3.5, and models supported by&nbsp;<a href="https://ollama.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Ollama</a>, a tool that runs large language models locally. Like Devin, Devika runs in a web browser and includes an agent that performs planning and reasoning. A persistent knowledge base and database recalls active projects.</li><li><a href="https://github.com/opendevin/opendevin?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">OpenDevin</a>&nbsp;is based on GPT-4 but has access to more than 100 models via&nbsp;<a href="https://github.com/BerriAI/litellm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">litellm</a>, a package that simplifies API calls. OpenDevin’s developers aim to match Devin’s user interface and enable the system to evaluate its own accuracy.&nbsp;</li><li><a href="https://swe-agent.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-agent</a>&nbsp;addresses bugs and issues in Github repositories. It can use any language model. Using GPT-4, it resolved 12.3 percent of tasks in the&nbsp;<a href="https://www.swebench.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-bench</a>&nbsp;dataset of real-world GitHub issues. (Devin&nbsp;<a href="https://www.cognition-labs.com/post/swe-bench-technical-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">resolved</a>&nbsp;13.9 percent of SWE-bench tasks. Claude 3, the highest-scoring model not specifically trained for coding, resolved 4.8 percent of SWE-bench tasks.)</li></ul><p><strong>Behind the News:&nbsp;</strong>Code-completion tools like Github Copilot and Code Llama quickly have become&nbsp;<a href="https://www.deeplearning.ai/the-batch/code-generation-services-took-off-in-2022?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">ubiquitous</a>.&nbsp;<a href="https://docs.agpt.co/autogpt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">AutoGPT</a>, released in 2023, is an open-source generalist AI agent based on GPT-4 that has been used to write and debug code. Recently Replit, known for its Ghostwriter code-completion and chatbot applications, began building&nbsp;<a href="https://blog.replit.com/code-repair?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">its own LLMs</a>&nbsp;for automated code repair.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Agentic coding tools are distinguished by&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">techniques</a>&nbsp;that enable large language models to plan, reflect on their work, call tools, and collaborate with one another. Users&nbsp;<a href="https://leaddev.com/process/what-devin-and-can-it-really-replace-developers?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">report</a>&nbsp;that, unlike previous coding assistants, the new tools are better at sustaining extended tasks and correcting their own work.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Many software developers worry that large language models will make human coders obsolete. We doubt that AI will replace coders, but we believe that coders who use AI will replace those who don’t. Agent-based tools still have a long way to go, but they seem likely to augment programmers’ abilities in a larger development pipeline.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141020.606.png" width="1200" /></figure><h1 id="what-users-do-with-generative-ai">What Users Do With Generative AI</h1><p>Generative AI is being used mostly to generate ideas.</p><p><strong>What’s new:</strong>&nbsp;The tech consultancy Filtered&nbsp;<a href="https://hbr.org/2024/03/how-people-are-really-using-genai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">studied</a>&nbsp;the most common uses for generative AI. While most gen AI users produced text, the study surprisingly found that users were slightly more likely to generate videos than images.<br /><br /><strong>How it works:&nbsp;</strong>The analysts sifted through tens of thousands of posts on popular online forums for anecdotes that described uses of generative AI. The analysts grouped the posts into a list of 100 most popular uses of generative AI and ranked each one by reach and value added.&nbsp;</p><ul><li>Most often, individuals used generative AI as an aid to brainstorming, both at work and otherwise. They also turned to generative AI for specific suggestions, like recommending movies, suggesting holiday destinations, and generating characters for role-playing games.</li><li>Other uses in the top five: text editing, emotional support, deep dives into niche subjects, and searching for information. (One poster used a chatbot to track down the brand of cookie his grandmother liked.)</li><li>Many users employed generative AI to revise their own work, for example troubleshooting or optimizing code, editing emails before sending them, improving marketing copy, or tweaking images.</li><li>Workplace-related uses included drafting cover letters, creating notes in preparation for meetings, summarizing meetings after they happened, and analyzing sales data. Many students found generative AI useful as a learning aid to review course materials or create personalized ways to learn.</li><li>Many users found that generative AI helped them better understand technical information, such as legal advice or medical expertise. Users relied on chatbots for tasks that might have required them to consult a human expert, like drafting legal complaints, summarizing jargon-filled documents, and seeking information on medical test results.</li></ul><p><strong>Behind the news:</strong>&nbsp;The range of use cases reflects the huge number of people, from all walks of life and all parts of the world, who are using generative AI tools. In a given week in November 2023, more than 100 million people&nbsp;<a href="https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">used</a>&nbsp;ChatGPT, the most popular of these tools. Independently, in February 2024, Pew Research&nbsp;<a href="https://www.pewresearch.org/short-reads/2024/03/26/americans-use-of-chatgpt-is-ticking-up-but-few-trust-its-election-information/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">found</a>&nbsp;that 23 percent of U.S. adults had used ChatGPT at least once, including 43 percent of respondents under 30 years old and 37 percent of those with postgraduate degrees. According to the Pew report, 20 percent of all Americans had used ChatGPT for work, and 17 percent had used it for entertainment, with younger and more educated users leading the way.<br /><br /><strong>Why it matters:</strong>&nbsp;It’s clear that millions of people use generative AI but less clear how they use it. Understanding how and where they actually apply it is helpful for anyone who aims to develop new generative AI products and services or plans to integrate the tech into their organization.</p><p><strong>We’re thinking:</strong>&nbsp;While it’s encouraging that more than a fifth of U.S. adults have tried ChatGPT,&nbsp; it also suggests huge room for growth in generative AI at large.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-09T091357.311.png" width="1680" /></a></figure><p>Integrate diverse data types into your LLM applications in our new short course built in collaboration with Unstructured. Learn techniques to extract and normalize data from PDFs, tables, and images into a structured format.&nbsp;<a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141216.341.gif" width="1200" /></figure><h1 id="instability-at-stability-ai">Instability at Stability AI</h1><p>The CEO of Stability AI resigned as the company faces an increasingly competitive market.</p><p><strong>What’s new:</strong>&nbsp;Emad Mostaque stepped down from Stability AI, developer of the Stable Diffusion image generator among other models, amid financial woes, uncertain direction, and sinking confidence from investors and employees alike,&nbsp;<em>Forbes</em>&nbsp;<a href="https://www.forbes.com/sites/kenrickcai/2024/03/29/how-stability-ais-founder-tanked-his-billion-dollar-startup/?sh=2e53d2e3e630&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">reported</a>. Mostaque’s departure followed the exits of numerous executives and key employees.</p><p><strong>How it works:&nbsp;</strong>Stability&nbsp;<a href="https://stability.ai/news/stabilityai-announcement?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">confirmed</a>&nbsp;Mostaque’s departure in a blog post. The company’s chief operating officer Shan Shan Wong and chief technology officer Christian Laforte will act as co-CEOs until its directors find a permanent replacement. They inherit a company with troubles beyond leadership.&nbsp;</p><ul><li>Stability faces serious cash-flow issues. In 2023, it projected $11 million in revenue against $153 million in costs. Currently it&nbsp;<a href="https://www.ft.com/content/d7bbb769-20f1-4242-bd15-201741c90720?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">spends</a>&nbsp;$8 million monthly compared to revenue of $3 million in November and $5.4 million in February.</li><li>The company’s bill for processing power provided by Amazon Web Services, Google, and CoreWeave amounts to $99 million annually. It often failed to pay on time. Stability contemplated reselling access to its leased GPUs to make up for its revenue shortfall.</li><li>Stability struggled to commercialize its models. It tried to strike deals with companies such as Samsung, Snap, and Canva and governments such as Singapore, but the parties couldn’t agree on terms.</li><li>Throughout 2023, it tried to raise funds by courting investors like Nvidia and Google. Negotiations failed partly over questions about the company’s finances. Ultimately it sought a buyer, but no deal emerged.</li><li>Stability faces unpredictable liabilities due to&nbsp;<a href="https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">lawsuits</a>&nbsp;over its alleged use of copyrighted images as training data and its models’ ability to produce images in the styles of human artists.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Despite its troubles, Stability continued to release new models. In February, it&nbsp;<a href="https://stability.ai/news/stable-diffusion-3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">opened</a>&nbsp;the waitlist for the third-generation version of Stable Diffusion. Last month, it&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Video 3D, a project in which the team produced three-dimensional objects from images. This month, it&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Audio 2.0, which can produce music files up to three minutes long from a text prompt.<br /><br /><strong>Why it matters:</strong>&nbsp;Stability has been a standard bearer for open-source AI in a field where tech giants aim to dominate with closed models. Effective leadership could have a major impact on the models available to developers in the years ahead.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Stability helped capture the public imagination during the generative AI boom of 2022, and its open models, particularly its diffusion models, have been a huge benefit to the AI community. We hope new leadership puts the company on firm footing.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141759.545.gif" width="1200" /></figure><h1 id="a-transformer-alternative-emerges">A Transformer Alternative Emerges</h1><p>An architectural innovation improves upon transformers — up to 2 billion parameters, at least.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Albert Gu at Carnegie Mellon University and Tri Dao at Princeton University developed the&nbsp;<a href="https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Mamba</a>&nbsp;architecture, a refinement of the earlier state space sequence architecture. A relatively small Mamba produced tokens five times faster and achieved better accuracy than a vanilla transformer of similar size while processing input up to a million tokens long.</p><p><strong>Structured State Space Sequence (S4) basics:</strong>&nbsp;<a href="https://arxiv.org/abs/2111.00396?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">S4s</a>, also known as structured SSMs, can be functionally similar to recurrent neural networks (RNNs): They can accept one token at time and produce a linear combination of the current token and an embedding that represents all previous tokens. Unlike RNNs and their extensions including LSTMs — but like transformers — they can also perform an equivalent computation in parallel during training. In addition, they are more computationally efficient than transformers. An S4’s computation and memory requirements rise linearly with input size, while a vanilla transformer’s rise quadratically — a heavy burden with long input sequences.</p><p><strong>Key insight:</strong>&nbsp;S4s are more efficient than transformers but, while a transformer’s input length is limited only by processing and memory, an S4’s input length is limited by how well its hidden state can represent previously input tokens as new tokens arrive. A&nbsp;<a href="https://arxiv.org/abs/1612.08083?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">gating mechanism</a>&nbsp;that lets the model process the most important parts of an input and ignore the rest can enable it to process longer inputs. One viable gate: Typically S4s apply the same mathematical function to all input tokens, whose parameters consist of four learned matrices. Changing the matrices for each input enables the model to learn which tokens or parts of tokens are least important and can be ignored (set to zero). This condenses the input, enabling the modified S4 to process very long input sequences.</p><p><strong>How it works:</strong>&nbsp;Mamba is made up of blocks, each of which includes a modified S4 (which the authors call a selective SSM). The authors pretrained different instances on a variety of tasks including generating tokens from&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">The Pile</a>&nbsp;(a collection of text from the web) and predicting DNA base pairs in&nbsp;<a href="https://www.nature.com/articles/s41592-021-01252-x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HG38</a>&nbsp;(a single human genome) in sequences up to 1 million tokens long.&nbsp;</p><ul><li>In each block, the authors replaced three of the S4’s four fixed matrices with learned linear functions of the input. That is, they replaced each of three learned matrices with a learned matrix multiplied by the input. (The authors hypothesized that modifying the fourth matrix would not help, so they didn’t change it.)</li><li>The following layer multiplied the model’s output with a linear projection of the block’s input. This acted as a gate to filter out irrelevant parts of the embedding.</li></ul><p><strong>Results:</strong>&nbsp;Mamba achieved better speed and accuracy than transformers of similar size, including tasks that involved inputs of 1 million tokens.&nbsp;</p><ul><li>Running on an Nvidia A100 GPU with 80GB, a Mamba of 1.4 billion parameters produced 1,446 tokens per second, while a transformer of 1.3 billion parameters produced 344 tokens per second.</li><li>In sizes from 130 million parameters to 2.8 billion parameters, Mamba outperformed the transformer&nbsp;<a href="https://arxiv.org/abs/2304.01373?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Pythia</a>&nbsp;and the S4&nbsp;<a href="https://arxiv.org/abs/2212.14052?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">H3</a>&nbsp;on many tasks. It was better at predicting the next word of The Pile, and it was better at question-answering tasks such as&nbsp;<a href="https://arxiv.org/abs/1907.10641?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">WinoGrande</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/1905.07830?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HellaSwag</a>. For instance, on WinoGrande, using models of roughly 2.8 billion parameters, Mamba achieved 63.5 percent accuracy, Pythia 59.7 percent accuracy, and H3 61.4 percent accuracy.&nbsp;</li><li>After fine-tuning on Great Apes DNA Classification (classifying DNA segments up to 1 million tokens long as belonging to one of five species of great ape), using models of 1.4 million parameters, Mamba achieved 70 percent accuracy, while&nbsp;<a href="https://arxiv.org/abs/2306.15794?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Hyena DNA</a>&nbsp;achieved 55 percent accuracy.</li></ul><p><strong>Yes, but:</strong>&nbsp;The authors tested model sizes much smaller than current state-of-the-art large language models.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Google’s transformer-based Gemini 1.5 Pro offers context lengths up to 1 million tokens, but methods for building such models aren’t yet widely known. Mamba provides an alternative architecture that can accommodate very long input sequences while processing them more efficiently. Whether it delivers compelling benefits over large transformers and variations that provide higher efficiency and larger context is a question for further research</p><p><strong>We're thinking:</strong>&nbsp;Research on Mamba is gaining momentum. Other teams are probing the architecture in projects like&nbsp;<a href="https://arxiv.org/abs/2403.07487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Motion Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.09417?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Vision Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.04081?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MoE-Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.13660?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MambaByte</a>, and&nbsp;<a href="https://arxiv.org/abs/2403.19887?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Jamba</a>.</p><hr /><h1 id="data-points">Data Points</h1><p>Read <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> to find the latest AI updates of the week, including:&nbsp;</p><p>👉 Advanced new editing tools by DALL·E<br />👉 Command R+, a new LLM by Cohere<br />👉 An update on big tech's hunt for AI training</p><p>And more!&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-244/?ref=dl-staging-website.ghost.io" rel="noreferrer">Check out Data Points now.</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 19:58:19 GMT</pubDate>
</item>
</channel>
</rss>